<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java并发编程学习笔记（三）锁]]></title>
    <url>%2F2019%2F04%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E9%94%81%2F</url>
    <content type="text"><![CDATA[分类内部锁 / 显式锁内部锁通常指Synchronized锁。 显式锁通常指Lock接口实现的锁，如ReentrantLock。 公平锁 / 非公平锁一种获取锁的策略。 公平锁指按照线程申请锁的顺序获取锁。 非公平锁指不严格按照申请锁的顺序获取锁，如可按优先级获取锁，可能造成饥饿。 Synchronized 是一个典型的非公平锁。 ReentrantLock 可通过构造方法指定是否为公平锁，默认为非公平锁。 可重入锁 / 不可重入锁可重入锁指线程可以进入它已经获取的锁守护的其他代码块。 不可重入锁指当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会因获取不到而被阻塞。 Synchronized和ReentrantLock都是可重入锁。 互斥锁 / 读写锁互斥锁指一次最多只有一个线程能够占有锁，如Synchronized、ReentrantLock。 读写锁指一个资源可以能够被多个读取线程访问，或被一个写入线程访问，二者不能同时进行，如ReentrantReadWriteLock。 乐观锁 / 悲观锁非具体类型的锁，而是理解并发操作的两个角度。 乐观锁认为不加锁的并发操作是可以容忍的，比如原子类，通过CAS实现原子操作。 悲观锁认为不加锁的并发操作一定是不安全的，如使用内部锁或显示锁。 分拆锁 / 分离锁非具体类型的锁，而是一种对于锁的设计。 分拆锁指当一个锁对应多个独立的的独占资源时，可以考虑为每个独占资源分配一个锁。 分离锁指将一个独占资源分为N份，每份分别对应一个独占锁，如JDK1.7中ConcurrentHashMap的锁分离实现，使用了一个包含16个锁的Array，每个锁对应HashMap的1/16。 偏向锁 / 轻量级锁 / 重量级锁表示Synchronized锁的三种状态，Java5为Synchronized锁引入了锁升级策略，提高了Synchronized锁的性能，这三种锁的状态是通过对象监视器在对象头中的字段来表明的。 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁升级为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。 自旋锁自旋锁指申请获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 内部锁内部锁是由JVM管理的，我们可以通过Synchronized关键字使用内部锁。Synchronized关键字可以用来同步方法或代码块，这也分别代表着不同的同步行为。 同步一个对象 同步一个对象分为两种情况： 其一，类中创建一个对象作为锁对象，如下：123456Object lock = new Object();public void f1() &#123; synchronized (lock) &#123; &#125;&#125; 其二，使用this指代当前对象，如下：12345public void f1() &#123; synchronized (this) &#123; &#125;&#125; 在这两种情况下，当多个线程访问同一个对象的f1()方法时锁才会生效。 同步一个方法 123public synchronized void f2() &#123; // Do something&#125; 与同步一个对象作用相同。 同步一个类 12345public void f3() &#123; synchronized (Sync.class) &#123; &#125;&#125; 作用于整个类，当多个线程调用该类的不同对象的f3() 方法时也会进行同步。 同步一个静态方法 123public synchronized static void f4() &#123; &#125; 静态方法为类所属，因此与同步一个类相同。 显示锁java.util.concurrent.locks包中的Lock接口定义了一系列显式锁操作，如下： 1234567891011121314public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 内部锁虽然使用简单，但锁的获取和释放由JVM实现，在无法获得锁时会无限等待，不能进行中断，而显式锁提供了更加灵活的方法，如可响应中断的锁获取方法，可设定超时的锁获取方法等。 显式锁在使用上更加灵活，能够减小锁的粒度，但也特别需要注意将业务处理放在try代码块中，并在finally代码块中释放锁，如下： 1234567891011121314151617181920public void f1() &#123; lock.lock(); try &#123; // Do something &#125; finally &#123; lock.unlock(); &#125;&#125; public void f2() &#123; if (lock.tryLock()) &#123; try &#123; // Do something &#125; finally &#123; lock.unlock(); &#125; &#125; else &#123; &#125;&#125; 总结锁是Java并发编程的基础内容，对锁有一定的了解能够构建更好的并发程序，在权衡使用内部锁或显式锁时，要充分考虑使用锁的场景，内部锁由JVM实现，能满足绝大多数使用场景，但如果需要使用可中断、可定时的特性时可以考虑使用显式锁代替内部锁。 参考资料《Java并发编程实战》]]></content>
      <categories>
        <category>Java - 并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程学习笔记（二）活跃度问题]]></title>
    <url>%2F2019%2F04%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E6%B4%BB%E8%B7%83%E5%BA%A6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在并发编程中，我们经常通过锁来保证线程安全，但使用锁也可能会带来一系列其他的问题，如死锁等问题。我们知道Java虚拟机无法从死锁中恢复，因此了解死锁的发生场景能够让我们在编程过程中尽可能避免死锁的发生。 死锁定义死锁指一组线程中的每个线程都在等待由其他线程占有的因而无法获得的资源，导致线程无法继续推进执行，这里的资源可能是锁，也可能是其他计算机资源，如数据库连接等。 从上面的定义中，我们可以看出死锁的发生有几个必要的条件： 资源独占 不可剥夺 保持申请 循环等待 锁顺序死锁当多个线程试图以不同的顺序获取多个相同的锁时，就可能发生死锁。 考虑A向B转账的业务： 这种是一种很常见的危险情况，比如我们声明如下的一个方法： 1234567public void transfer(Object accountA, Object accountB) &#123; synchronized (accountA) &#123; synchronized (accountB) &#123; // doSomeThing &#125; &#125;&#125; 看起来我们似乎控制了锁的获取顺序，但是由于转账的双方是不确定的，因此依然可能会出现锁顺序引起的死锁，这种情况，可以根据一定策略，动态改变锁的获取顺序，从而保证所有线程获取锁的顺序是一致的，如通过比较对象哈希值，规定加锁顺序，如下： 123456789101112131415public void transfer(Object fromAccount, Object toAccount) &#123; if (fromAccount.hashCode() &gt; toAccount.hashCode()) &#123; synchronized (fromAccount) &#123; synchronized (toAccount) &#123; // doSomeThing &#125; &#125; &#125; else &#123; synchronized (toAccount) &#123; synchronized (fromAccount) &#123; // doSomeThing &#125; &#125; &#125;&#125; 协作对象间的死锁如果一个操作会涉及到多个协作对象，且均需要获取锁，这时就可能导致协作对象间的死锁，一种比较简单的情况即是协作对象间发生锁顺序死锁。 这里指的协作对象可能是不同的功能模块，也有可能是外部方法，当我们持有锁时调用协作对象，就有可能发生死锁。 资源死锁即线程等待的是资源而不是锁，这种情况与获取锁的情况类似，比如申请数据库连接造成死锁。 避免和诊断死锁使用显式锁java.util.concurrent.locks 包中定义了显式锁的接口，提供了比内部锁更灵活的机制，显式锁的接口定义如下： 1234567891011121314public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 通过显式锁，我们能够实现带有定时的锁，在请求一个锁时，如果在一定时间内没有获得到锁则返回获取失败，这样可以避免死锁的发生，具体可参考 ReentrantLock 。 通过线程转储分析死锁我们可以通过良好的程序设计来预防死锁的发生，同时也可以通过 线程转储 来分析运行中的程序是否发生了死锁，以简单的锁顺序死锁为例： 1234567891011121314151617181920212223242526272829303132public class SimpleOrderLockDeadLock &#123; private final Object right = new Object(); private final Object left = new Object(); public void leftRight() &#123; synchronized (left) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (right) &#123; &#125; &#125; &#125; public void rightLeft() &#123; synchronized (right) &#123; synchronized (left) &#123; &#125; &#125; &#125; public static void main(String[] args) &#123; SimpleOrderLockDeadLock deadLock = new SimpleOrderLockDeadLock(); new Thread(() -&gt; deadLock.leftRight()).start(); new Thread(() -&gt; deadLock.rightLeft()).start(); &#125;&#125; 利用编译器的线程转储我们可以看到： Thread-1@625处于阻塞状态，持有对象锁，并等待Thread-0@622释放对象锁 Thread-0@622处于阻塞状态，持有对象锁，并等待Thread-0@622释放对象锁 其他活跃度问题饥饿当线程申请的资源被其他线程永久占用时发生饥饿，比较常见的情况如下： 低优先级线程被饿死，抵制使用线程优先级可以尽可能少的引起饥饿问题 使用SingleThreadExecutor，工作线程执行的任务进入无限期等待，其他的任务永远无法提交到工作线程中而导致被饿死 弱响应性客户端程序通常会在后台线程中处理耗时操作，但后台线程和主线程竞争CPU资源也会影响到程序的响应性。通常情况下，后台线程的优先级要低于主线程。 活锁活锁的情况经常出现在存在重试机制的系统中，当一个任务出现错误时，系统无限进行重试，导致工作线程无法向前推进，可以通过一些策略避免活锁，例如RocketMQ的重试机制。 参考资料《Java并发编程实战》]]></content>
      <categories>
        <category>Java - 并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>活跃度问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程学习笔记（一）基础知识]]></title>
    <url>%2F2019%2F04%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[基本概念并发和并行并发：多个计算任务在同一个CPU内核上进行时间片轮转，从宏观角度来看任务是同时进行的，而实际上多个任务是交替执行的。 并行：多个计算任务在不同的CPU内核上执行，是真正的同时执行。 进程和线程进程：具有一定独立功能的程序关于一个数据集合的一次运行活动，是一个动态概念。进程是并发执行的程序在执行过程中资源分配的基本单位。 线程：线程是进程的一部分，在一个进程中可以同时运行着多个线程，线程是CPU调度的基本单位。 线程状态转换 （1）新建状态（New）：新创建了一个线程对象，尚未启动。 （2）就绪状态（Runnable）：调用了start()方法。该状态的线程位于可运行线程池中，等待获取CPU的使用权。 （3）运行状态（Running）：获取了CPU，执行程序代码。 （4）同步阻塞状态（Blocked）：运行中的线程请求一个由其他线程占有的排他锁，则当前线程进入同步阻塞状态 （5）无限等待阻塞状态（Waiting）：运行中的线程调用wait()方法，进入无限等待阻塞状态。 （6）有限等待阻塞状态（Timed Waiting）：运行中的线程调用sleep()或join()方法，或者发出了I/O请求时，则线程进入有限等待阻塞状态。 （7）死亡状态（Terminated）：线程执行完毕或者因产生异常而结束。 线程的使用继承Thread类123456789public class CustomThread extends Thread &#123; @Override public void run() &#123; // so something &#125;&#125;CustomThread thread = new CustomThread();thread.start(); 实现Runnable接口123456789public class CustomRunnable implements Runnable &#123; @Override public void run() &#123; // so something &#125;&#125;Thread thread = new Thread(new CustomRunnable());thread.start(); 实现Callable接口12345678910111213141516public class CustomCallable implements Callable &#123; @Override public Object call() throws Exception &#123; return null; &#125;&#125;ExecutorService executorService = Executors.newCachedThreadPool();Future future = executorService.submit(new CustomCallable());try &#123; Object o = future.get();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125; 线程池java.util.concurrent包中为我们提供了多钟内置线程池，我们可以通过Executors的静态工厂方法创建线程池，下面一起来看看Java内置的线程池。 FixedThreadPool1ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5); 创建一个定长的线程池，每当提交一个任务就会创建一个线程，直到线程数量达到池的上限。当池中所有线程都处于工作状态，此时提交一个新的任务，则该任务会添加到任务队列中，等待池中的线程可用。 池中的线程会一直存在，如果某一线程由于出现异常而结束，则线程池会补充一个新的线程。 适用于负载较重或可预知工作线程数量的场景。 CachedThreadPool1ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); 创建一个可缓存的线程池，不对池的长度进行任何限制。 线程默认60s未使用则被回收，当提交新任务时首先考虑复用未被回收的空闲线程，其次考虑新增线程。 适用于负载较轻或短耗时异步任务的场景。 SingleThreadPool1ExecutorService singleThreadPool = Executors.newSingleThreadExecutor(); 创建一个单线程化的线程池，池中仅有一个的工作线程来执行任务，如果该线程由于出现异常而结束，则会创建一个新的线程。 工作线程根据任务队列规定的顺序（FIFO，LIFO，Priority）来执行任务。 适用于需要严格保证任务执行顺序的场景。 ScheduledThreadPool1ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); 创建一个定长的线程池，可以设定任务执行的延迟时间，周期性执行任务。 适用于线程周期性执行任务的场景。 WorkStealingPool1ExecutorService workStealingPool = Executors.newWorkStealingPool(); WorkStealingPool底层使用了ForkJoinPool，默认使用当前可以用CPU数，可将大任务分解为多个小任务，提高CPU的利用率。 适用于耗时较长的计算任务，可将任务进行分解，并行计算。 任务队列回到Executors的工厂方法中，我们可以看到线程池的构造方法，例如： 12345678910111213141516171819202122public class Executors &#123; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; &#125; FixedThreadPool和SingleThreadPool默认使用的是一个无限的LinkedBlockingQueue，当频繁提交任务时，任务数大于工作线程数，这时任务就会进入任务队列中，无限的任务队列会跟随任务的提交而增长，这样就有可能导致资源耗尽，可以使用ArrayBockingQueue、有限LinkedBlockingQueue、PriorityBlockingQueue防止资源耗尽。 对于CachedThreadPool，使用了SynchronousQueue绕开队列，将任务直接交给工作线程，SynchronousQueue不是一个队列，而是一种在线程之间交换信息的机制，由于CachedThreadPool是一个无限的线程池，每提交一个任务都会复用或新建一个线程来执行任务，因此使用SynchronousQueue可以减少任务在队列中维护时放入和取出的性能消耗。 饱和策略使用有界阻塞任务队列可能会出现任务队列满的情况，当新提交的任务不能进入任务队列时就需要一种饱和策略对任务进行管理，如下： 12ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(11));threadPoolExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy()); 可以通过ThreadPoolExecutor的setRejectedExecutionHandler接口设置饱和策略。Java中提供了四种饱和策略: （1）AbortPolicy：当新任务不能进入等待队列时，会抛出RejectedExecutionExecption异常，可由调用者捕获，进行相应的处理。 （2）DiscardPolicy：当新任务不能进入等待队列时，会放弃这个任务。 （3）DiscardOldestPolicy：当新任务不能进入等待队列时，会放弃接下来将要执行的任务，如果队列通过优先级排序，则会放弃优先级最高的任务，因此该策略不能同优先级队列同时使用。 （4）CallerRunsPolicy：当新任务不能进入等待队列时，会将一些任务推回给调用者，也就是让调用者线程来执行新任务，这样就使得池线程能够追赶进度，调用者线程在执行新任务时便不会再接受其他的新任务，防止过载时急剧劣化。 ThreadPoolExecutor的默认饱和策略为AbortPolicy。 总结并发编程是Java中经常使用的关键技术，其中，线程池的使用尤为重要，线程池的使用也有一些需要特别注意的问题，如： （1）只有当任务彼此相互独立时，使用有限线程池或有限任务队列才是合理的；当任务相互依赖时，可以使用无限的线程池来防止线程饥饿和死锁。 （2）需要特别注意在线程池中使用ThreadLocal管理数据，因为可能存在线程的复用。 参考资料《Java并发编程实战》 五种线程池的对比与使用]]></content>
      <categories>
        <category>Java - 并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于用户的协同过滤算法在显式、隐式反馈数据中的评估比较]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%E5%9C%A8%E6%98%BE%E5%BC%8F%E3%80%81%E9%9A%90%E5%BC%8F%E5%8F%8D%E9%A6%88%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[问题描述实现基于用户的协同过滤（UserCF）算法，以TopN的推荐方式，分别在显式和隐式反馈数据集中进行评估和比较。 实验采用Grouplens团队提供的公开数据集Movielens-latest-small，包括671个用户对9125部电影的100004条评分，并将数据以6比2的比例随机分为训练集和测试集。 隐式反馈只考虑用户是否看过电影，显式反馈考虑用户对电影的评分。 算法描述UserCF算法是一种基于统计学的方法，目标是通过分析用户的历史行为，为用户推荐和他相似的用户喜欢的物品，因此算法中的一个重要内容便是计算用户的相似度。 UserCF算法中相似度的计算是一种近邻模型，中心思想是通过寻找k个近邻用户来模拟主体的行为（KNN），寻找近邻用户需要一个指标来衡量用户间近邻程度，简易的计算方法如下（给定用户u和用户v，N(u)表示用户u喜欢的物品集合，N(v)表示用户v喜欢的物品集合）： 杰卡德相似度 余弦相似度 算法步骤： 1.读取数据，建立用户 – 物品数据结构，如下图所示： 用户A喜欢物品a、b、c，用户B喜欢物品a、c，以此类推。 2.建立物品 – 用户倒排表，如下图所示。目的是在计算相似度时排除那些 |N(u) ∩ N(v)|= 0的数据，只需要扫描倒排表就可以计算出|N(u) ∩ N(v)|≠ 0的用户组合。 3.利用余弦相似度构建相似度矩阵，如用户A和用户B的相似度计算如下： 4.寻找K近邻相似用户。 5.计算用户评分，w表示用户相似度，r表示用户的反馈评分。 6.得出TopN推荐列表。 评价指标通过计算选取不同近邻用户K值时的准确率、召回率和F1值对算法进行评估。 准确率、召回率和F1值的定义请参考 推荐系统发展综述 - 4.推荐方式和效果评估 实验结果实验结果中TopN的N值为选取的用户相似度较大的N个用户作为近邻用户，非最终推荐列表的TopN。 1.隐式反馈 从图中可以看到，当N取18时，F1值最大为0.15，此时召回率为0.23，准确率为0.1，可以看出仅考虑隐式反馈时，通过UserCF算法得到的推荐列表结果并不是很理想。 2.显式反馈 当N取16时，F1值最大为0.2，此时召回率为0.27，准确率为0.17，相比较隐式反馈结果有所提升。 随着N的增大，显式和隐式反馈数据推荐结果的召回率逐渐上升，这是因为所选择的近邻用户越多，为用户推荐的物品就越多，因此召回率会大大增加，而相反，准确率则会逐渐下降。 总结UserCF算法是通过统计学的方法来挖掘用户历史行为数据的规律，隐式反馈数据中所体现的用户行为规律较为粗糙，不利于发现和挖掘，而显示反馈数据能够对用户的行为进行一定的偏好划分，更具有代表性。 因此协同过滤算法通常考虑显式反馈数据，最直观的显式反馈数据是评分数据，常用在音乐、视频服务推荐中。电商平台中的浏览、收藏、加入购物车、购买等行为也可以体现出不同层面的用户偏好，比如购买代表的偏好程度最高，浏览代表的最低，以此分级也可作为显式反馈数据。 参考：项亮. 推荐系统实践[M]. 北京: 人民邮电出版社, 2012.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>协同过滤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统综述：初识推荐系统]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0%EF%BC%9A%E5%88%9D%E8%AF%86%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[引言随着信息技术和互联网技术的发展，人们从信息匮乏时代步入了信息过载时代，在这种时代背景下，人们越来越难从大量的信息中找到自身感兴趣的信息，信息也越来越难展示给可能对它感兴趣的用户，而推荐系统的任务就是连接用户和信息，创造价值。 设想用户想买一本《Recommender Systems An Introduction》，用户只需要走进一家书店，寻找这本书即可。通过互联网，用户可以打开当当，在搜索框中输入书名，然后就可以找到用户想要购买的书籍，这两种方式都需要用户有明确的目的，如购买《Recommender Systems An Introduction》或某一类别的书籍。 但是，当用户没有明确目标时，比如寻找感兴趣的音乐，用户只能通过一些预先设定的类别或标签去寻找他可能感兴趣的音乐，但面对如此之多音乐，用户很难在短时间内找出真正感兴趣的音乐。这时就需要一个自动化的工具，来分析用户曾经收听的音乐，进而寻找出用户可能感兴趣的音乐推荐给用户，这就是个性化推荐系统的工作。 作为一种信息过滤系统，推荐系统具有以下两个最显著的特性： （1）主动化。从用户角度考虑，门户网站和搜索引擎都是解决信息过载的有效方式，但它们都需要用户提供明确需求，当用户无法准确描述自己的需求时，这两种方式就无法为用户提供精确的服务了。而推荐系统不需要用户提供明确的需求，而是通过分析用户和物品的数据，对用户和物品进行建模，从而主动为用户推荐他们感兴趣的信息。 （2）个性化。推荐系统能够更好的发掘长尾信息，即将冷门物品推荐给用户。热门物品通常代表绝大多数用户的兴趣，而冷门物品往往代表一小部分用户的个性化需求，在电商平台火热的时代，由冷门物品带来的营业额甚至超过热门物品，发掘长尾信息是推荐系统的重要研究方向。 目前，推荐系统已广泛应用于诸多领域，其中最典型的便是电子商务领域。同时，伴随着机器学习、深度学习的发展，工业界和学术界对推荐系统的研究热情更加高涨，形成了一门独立的学科。 发展历史推荐系统是互联网时代的一种信息检索工具，自上世纪90年代起，人们便认识到了推荐系统的价值，经过了二十多年的积累和沉淀，推荐系统逐渐成为一门独立的学科在学术研究和业界应用中都取得了很多成果。 1994 年明尼苏达大学GroupLens研究组推出第一个自动化推荐系统 GroupLens[1]。提出了将协同过滤作为推荐系统的重要技术，这也是最早的自动化协同过滤推荐系统之一。 1997 年 Resnick 等人[2]首次提出推荐系统（recommendersystem，RS）一词，自此，推荐系统一词被广泛引用，并且推荐系统开始成为一个重要的研究领域。 1998年亚马逊（Amazon.com）上线了基于物品的协同过滤算法，将推荐系统推向服务千万级用户和处理百万级商品的规模，并能产生质量良好的推荐。 2003年亚马逊的Linden等人发表论文，公布了基于物品的协同过滤算法[3]，据统计推荐系统的贡献率在20%~30%之间[4]。 2005年Adomavicius 等人的综述论文[5] 将推荐系统分为3个主要类别，即基于内容的推荐、基于协同过滤的推荐和混合推荐的方法，并提出了未来可能的主要研究方向。 2006 年10月，北美在线视频服务提供商 Netflix 宣布了一项竞赛，任何人只要能够将它现有电影推荐算法 Cinematch 的预测准确度提高10%，就能获得100万美元的奖金。该比赛在学术界和工业界引起了较大的关注，参赛者提出了若干推荐算法，提高推荐准确度，极大地推动了推荐系统的发展。 2007年第一届ACM 推荐系统大会在美国举行，到2017年已经是第11届。这是推荐系统领域的顶级会议，提供了一个重要的国际论坛来展示推荐系统在不同领域的最近研究成果、系统和方法。 2016年，YouTube发表论文[6]，将深度神经网络应用推荐系统中，实现了从大规模可选的推荐内容中找到最有可能的推荐结果。 近年来，推荐系统被广泛的应用于电子商务推荐、个性化广告推荐、新闻推荐等诸多领域，如人们经常使用的淘宝、今日头条、豆瓣影评等产品。 研究现状经过二十多年的积累和沉淀，推荐系统成功应用到了诸多领域，RecSys会议上最常提及的应用落地场景为：在线视频、社交网络、在线音乐、电子商务、互联网广告等，这些领域是推荐系统大展身手的舞台，也是近年来业界研究和应用推荐系统的重要实验场景。 伴随着推荐系统的发展，人们不仅仅满足于分析用户的历史行为对用户进行建模，转而研究混合推荐模型，致力于通过不同的推荐方法来解决冷启动、数据极度稀疏等问题，国内知名新闻客户端今日头条采用了内容分析、用户标签、评估分析等方法打造了拥有上亿用户的推荐引擎。 移动互联网的崛起为推荐系统提供了更多的数据，如移动电商数据[6]、移动社交数据、地理数据[7]等，成为了社交推荐的新的尝试。 随着推荐系统的成功应用，人们越来越多的关注推荐系统的效果评估和算法的健壮性、安全性等问题。2015年，Alan Said 等人在RecSys会议上发表论[8]，阐述了一种清晰明了的推荐结果评价方式，同年，FrankHopfgartner等人发表论文[9]，讨论了基于流式数据的离线评价方式和对照试验，掀起了推荐算法评估的研究热潮。 近年来，机器学习和深度学习等领域的发展，为推荐系统提供了方法指导。RecSys会议自2016年起开始举办定期的推荐系统深度学习研讨会，旨在促进研究和鼓励基于深度学习的推荐系统的应用。 2017年AlexandrosKaratzoglou等人在论文[10]中介绍了深度学习在推荐系统中的应用，描述了基于深度学习的内容推荐和协同过滤推荐方法，深度学习成为当前推荐系统研究的热点。 推荐方式和效果评估推荐系统在为用户推荐物品时通常有两种方式： 评分预测此方法一般通过学习用户对物品的历史评分，预测用户可能会为他没有进行评分的物品打多少分，通常用于在线视频、音乐等服务的推荐。 评分预测的效果评估一般通过均方根误差（RMSE）和平均绝对误差（MAE）计算。对于测试集T中的一个用户u和物品i，令rui是用户u对物品i的实际评分，而ȓui是推荐系统给出的预测评分，则RMSE定义为： MAE定义为： TopN推荐此方法一般不考虑评分，而是为用户提供一个个性化推荐列表，通过预测用户对物品的兴趣度对列表进行排序，选取其中前N个物品推荐给用户，通常用于电子商务、社交网络、互联网广告推荐。 TopN推荐一般通过准确率（precision）、召回率（recall）和F1值（平衡分数）度量。令R(u)是为用户推荐的物品列表，T(u)是用户在测试集上的行为列表。 召回率定义为： 准确率定义为： F1值定义为： 推荐算法根据推荐系统使用数据的不同，推荐算法可分为基于用户行为推荐、基于内容推荐、基于社交网络推荐等。 主流的推荐系统算法可以分为协同过滤推荐（Collaborative Filtering Recommendation）、基于内容推荐（Content-basedRecommendation）和混合推荐三种。 基于用户行为推荐用户行为蕴藏着很多模式，著名的“啤酒和尿布”的故事就是用户行为模式的良好体现。基于用户行为推荐的主要思想是利用已有用户的历史行为数据（显式反馈或隐式反馈），预测当前用户可能感兴趣的物品，其中显式反馈主要为用户评分，隐式反馈主要包括浏览、搜索等。 基于用户行为的推荐算法也称为协同过滤算法（Collaborative Filtering Recommendation），是推荐领域应用最广泛的算法，该算法不需要预先获得用户或物品的特征数据，仅依赖于用户的历史行为数据对用户进行建模，从而为用户进行推荐。协同过滤算法主要包括基于用户的协同过滤（User-Based CF）、基于物品的协同过滤（Item-Based CF）、隐语义模型（Latent Factor Model）等。其中基于用户和物品的协同过滤是通过统计学方法对数据进行分析的，因此也称为基于内存的协同过滤或基于邻域的协同过滤；隐语义模型是采用机器学习等算法，通过学习数据得出模型，然后根据模型进行预测和推荐，是基于模型的协同过滤。 基于用户的协同过滤（User-Based CF）基于用户的协同过滤（下文简称UserCF）的基本思想为：给用户推荐和他兴趣相似的用户感兴趣的物品。当需要为一个用户A（下文称A）进行推荐时，首先，找到和A兴趣相似的用户集合（用U表示），然后，把集合U中用户感兴趣而A没有听说过（未进行过操作）的物品推荐给A。算法分为两个步骤：首先，计算用户之间的相似度，选取最相似的N个用户，然后，根据相似度计算用户评分。 （1）用户相似度 用户相似度计算基于用户的协同过滤算法的重要内容，主要可以通过余弦相似度、杰卡德系数等方式进行计算。 假设：给定用户u和v，令N(u)表示用户u有过正反馈的物品集合，令N(v)为用户v有过正反馈的物品集合，则用户u和v之间的相似度可以通过如下方式计算： 余弦相似度： 杰卡德系数： （2）用户评分 得到用户相似度后，可以根据如下公式计算用户评分： 其中r(u, i)代表用户u对物品i的评分，S(u)为与用户u最相似的N个用户，N(i)为对物品i进行过操作的用户集合， 为用户u与用户v的相似度， 为用户v对物品i的评分。 UserCF的推荐结果反映了用户所在的一个兴趣群体中的热门物品，更加社会化但缺乏个性化， 能够满足物品的时效性，在新闻推荐领域能够发挥很大的作用。用户的兴趣在一段时间内是相对固定的，因此用户相似度矩阵不会实时进行更新，存在新用户的冷启动问题。 基于物品的协同过滤（Item-Based CF）基于物品的协同过滤（下文简称ItemCF）是目前应用最为广泛的算法，该算法的基本思想为：给用户推荐和他们以前喜欢的物品相似的物品，这里所说的相似并非从物品的内容角度出发，而是基于一种假设：喜欢物品A的用户大多也喜欢物品B代表着物品A和物品B相似。基于物品的协同过滤算法能够为推荐结果做出合理的解释，比如电子商务网站中的“购买该物品的用户还购买了…”。ItemCF的计算步骤和UserCF大致相同：首先，计算物品相似度，选出最相似的N个物品，然后根据相似度计算用户评分。 （1）物品相似度 假设：N(i)为喜欢物品i的用户结合，N(j)为喜欢物品j的用户集合，则物品相似度计算公式可以定义为： 上述公式将物品i和物品j的相似度定义为：同时喜欢物品i、j的用户数占只喜欢物品i用户数的比例，但如果物品j十分热门，大部分用户都很喜欢，那么就会造成所有物品都和j有较高的相似度，因此可以对计算公式进行如下改进： 改进后的相似度计算公式惩罚了物品j的热门度，在一定程度上减少了热门物品为相似度带来的影响。 （2）用户评分 得到物品相似度后，可以根据如下公式计算用户评分： 其中r(u, i)代表用户u对物品i的评分，S(i)代表和物品i最相似的N个物品，N(u)为用户u曾经感兴趣的物品集合， 为物品i和物品j的相似度， 为用户u对物品i的评分。 ItemCF的推荐结果更加个性化，反映了用户的个人兴趣，对挖掘长尾物品有很大帮助，被广泛应用于电子商务系统。在物品数较多时，物品相似度计算效率较差，因此通常以一定的时间间隔离线进行计算，然后将物品相似度数据缓存在内存中，这样一来，便可以根据用户的新行为实时向用户做出推荐。ItemCF同样存在新用户冷启动问题。 隐语义模型（Latent Factor Model）隐语义模型方法是目前应用最为广泛的协同过滤算法之一，在显式反馈（如评分）推荐系统中，能够达到很好的精度。它的基本思想是通过机器学习方法从用户-物品评分矩阵中分解为两个低阶矩阵，表示对用户兴趣和物品的隐含分类特征，通过隐含特征预测用户评分。训练过程中通常采用随机梯度下降（SGD）算法最小化损失函数，最后通过模型预测用户评分。矩阵分解（Matrix Factorization）是隐语义模型最成功的一种实现，假设训练数据为M个用户对N个物品的评分矩阵Rm,n，早期矩阵分解算法BasicSvd步骤如下： （1）给定假设函数 其中k表示矩阵分解的隐含特征数，p和q是两个矩阵，作为模型的参数，分别表示用户、物品与k个隐含特征之间的关系。 （2）最小化损失函数 其中u为用户，i为物品，R为训练数据评分矩阵，H为预测评分矩阵，通过随机梯度下降最小化cost函数，得到矩阵p和q。在最小化的过程中，还需要添加正则项防止过度拟合。 （3）通过用户、物品和隐含特征的关系矩阵p、q预测用户评分 在算法的演进过程中，还出现了FunkSVD[11]、SVD++等矩阵分解算法，它们在隐含特征的基础上考虑了用户评分习惯、历史访问等多种因素，在一些场景中取得了更为精确的结果。 矩阵分解算法采用机器学习的最优化方法训练模型，计算的空间复杂度较小，在评分预测推荐中的精度较高，能够自动挖掘用户和物品的特征，有非常好的扩展性，可以灵活地考虑额外因素。矩阵分解的训练过程需要扫描整个评分矩阵，在用户量和物品数很大的情况下比较费时，但可以离线进行训练，在线进行评分预测，达到推荐的实时性。 基于内容推荐基于内容推荐的基本思想是为用户推荐与他感兴趣的内容相似的物品，比如用户喜欢励志类电影，那么系统会直接为他推荐《阿甘正传》这部电影，这个过程综合考虑了用户兴趣和电影内容，因此不需要提供用户的历史行为数据，这能够很好地解决新用户的冷启动问题。基于内容推荐的关键问题是对用户兴趣特征和物品特征进行建模，主要方法由向量空间模型、线性分类、线性回归等。 基于内容推荐需要预先提供用户和物品的特征数据，比如电影推荐系统，需要提供用户感兴趣的电影类别、演员、导演等数据作为用户特征，还需要提供电影的内容属性、演员、导演、时长等数据作为电影的特征，这些需要进行预处理的数据在实际应用中往往有很大的困难，尤其是多媒体数据（视频、音频、图像等），在预处理过程中很难对物品的内容进行准确的分类和描述，且在数据量很大的情况下，预处理效率会很低下。针对以上不足，[25]提出了基于标签的推荐方法，可以由专家或用户为物品打标签，实现对物品的分类。 基于内容产生的推荐往往和用户已经处理的物品具有很大的相似度，不利于用户在推荐系统中获得惊喜，这也是推荐系统的一个重要研究方向。 混合推荐推荐算法虽然都可以为用户进行推荐，但每一种算法在应用中都有不同的效果。UserCF的推荐结果能够很好的在广泛的兴趣范围中推荐出热门的物品，但却缺少个性化；ItemCF能够在用户个人的兴趣领域发掘出长尾物品，但却缺乏多样性；基于内容推荐依赖于用户特征和物品特征，但能够很好的解决用户行为数据稀疏和新用户的冷启动问题；矩阵分解能够自动挖掘用户特征和物品特征，但却缺乏对推荐结果的解释，因此，每种推荐方法都各有利弊，相辅相成。 实际应用的推荐系统通常都会使用多种推荐算法，比如使用基于内容或标签的推荐算法来解决新用户的冷启动问题和行为数据稀疏问题，在拥有了一定的用户行为数据后，根据业务场景的需要综合使用UserCF、ItemCF、矩阵分解或其他推荐算法进行离线计算和模型训练，通过采集用户的社交网络数据、时间相关数据、地理数据等综合考虑进行推荐，保证推荐引擎的个性化，提高推荐引擎的健壮性、实时性、多样性和新颖性。让推荐系统更好地为用户服务。 总结和展望本文首先回顾了推荐系统发展的历史，并分析了当前推荐系统的研究现状，其次阐述了主要的推荐方式和推荐结果的评估指标，最后分析了主流的推荐算法以及它们各自的优缺点。 推荐系统的发展一方面精确的匹配了用户与信息，降低了人们在信息过载时代获取信息的成本，但由推荐系统主导的内容分发，如新闻推荐等，也为用户带来了消极影响。2017年9月19日，人民日报点名批评国内知名内容分发平台今日头条，强调别以技术之名糊弄网民和群众，可见推荐系统的发展不仅需要满足用户多元化、个性化的需求，而且需要对信息进行严格的监管和过滤，提高推荐系统的健壮性。近年来，RecSys会议上越来越多地收录了关于用户隐私、推荐引擎健壮性、信息过滤等方面的论文，这是未来推荐系统发展的一个重要研究方向。 目前，深度神经网络发展迅速，为推荐系统提供了新的特征提取、排序方法，越来越多的推荐引擎将深度神经网络与传统的推荐算法进行了结合，用于解决数据稀疏、推荐排序等问题，深度神经网络和推荐系统的结合将是推荐系统未来的主要研究方向。 综上所述，推荐系统是一个庞大的信息系统，它不仅仅只依赖于推荐引擎的工作，而且依赖于业务系统、日志系统等诸多方面，并结合了网络安全、数据挖掘等多个研究领域，能够为企业和用户带来价值，是一个值得深入研究的领域。 参考文献[1] Resnick P,Iacovou N, Suchak M, et al. GroupLens: an open architecture for collaborativefiltering of netnews[C] Proceedings of the 1994 ACM Conference on ComputerSupported Cooperative Work, Oct 22-26, 1994. New York, NY, USA: ACM, 1994:175-186. [2] Resnick P, Varian H R. Recommender systems[J].Communications of the ACM, 1997, 40(3): 56-58. [3] G. Linden, B. Smith, and J. York, “Amazon.comRecommendations: Item-to-Item Collaborative Filtering,” IEEE InternetComputing, vol. 7, no. 1, 2003, pp. 76–80. [4] Linden G, Smith B, York J. Amazon.comrecommendations: item-to-item collaborative filtering[J]. IEEE Internet Computing,2003, 7(1): 76-80. [5] Adomavicius G, Tuzhilin A. Toward the nextgeneration of recommender systems: a survey of the state-of-the-art and possibleextensions[J]. IEEE Transactions on Knowledge and Data Engineering, 2005,17(6): 734-749. [6] Cremonesi P, Tripodi A, Turrin R. Cross-DomainRecommender Systems.[C] IEEE, International Conference on Data MiningWorkshops. IEEE, 2012:496-503. [7] Huiji Gao, Jiliang Tang, Huan Liu. Personalizedlocation recommendation on location-based social networks[J]. 2014:399-400. [8] Said A. Replicable Evaluation of RecommenderSystems[C] ACM Conference on Recommender Systems. ACM, 2015:363-364. [9] Hopfgartner F, Kille B, Heintz T, et al.Real-time Recommendation of Streamed Data[C] ACM Conference on RecommenderSystems. ACM, 2015:361-362. [10] Karatzoglou A, Hidasi B. Deep Learning forRecommender Systems[C] the Eleventh ACM Conference. ACM, 2017:396-397. [11] Simon Funk. Funk-SVD [EB/OL]. http://sifter.org/~simon/journal/20061211.html,2006-12-11 [12] 朱扬勇, 孙婧. 推荐系统研究进展[J]. 计算机科学与探索, 2015, 9(5):513-525. [13] 杨阳, 向阳, 熊磊. 基于矩阵分解与用户近邻模型的协同过滤推荐算法[J]. 计算机应用, 2012,32(2):395-398. [14] 项亮. 推荐系统实践[M]. 北京: 人民邮电出版社, 2012.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>综述</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow卷积神经网络（CNN）手写数字识别示例学习]]></title>
    <url>%2F2019%2F04%2F10%2FTensorflow%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[问题描述利用卷积神经网络将MNIST数据集的28×28像素的灰度手写数字图片识别为相应的数字。 数据描述MNIST数据集是28×28像素的灰度手写数字图片，其中数字的范围从0到9 具体如下所示（参考自Tensorflow官方文档）： 文件 内容 train-images-idx3-ubyte.gz 训练集图片，55000张训练图片, 5000张验证图片 train-labels-idx1-ubyte.gz 训练集图片对应的数字标签 t10k-images-idx3-ubyte.gz 测试集图片，10000张图片 t10k-labels-idx1-ubyte.gz 测试集图片对应的数字标签 网络结构卷积神经网络一般包含以下几层： 输入层：用于将数据输入到神经网络中 卷积层：使用卷积核提取特征 激励层：对卷积操作的线性运算进行非线性映射 池化层：卷积得到的特征图进行稀疏处理，减少数据量 全连接层：在网络的末端进行重新拟合，恢复特征，减少特征的损失 输出层：输出结果 输入层卷积神经网络中输入层的结构可以是多维的，例如MNIST数据集中是28×28像素的灰度图片，因此输入为28×28的的二维矩阵。 卷积层卷积层是使用卷积核提取特征，在卷积层中需要理解局部感受野和共享权值。 局部感受野：类似于一个滑动窗口，以窗口的范围去提取对应范围的神经元携带的特征。 共享权值：根据局部感受野提取特征，原始数据中的一部分神经元与卷积层中的一个神经元相连接，每一条线对应一个权重，而在卷积层中，对于同一个卷积核，权重是相同的。 上图为卷积操作示意图（图片来源于网络，侵删），其中Image表示图片数据矩阵，游走的窗口为卷积核矩阵，x0、x1表示的是权重，一个N×N的图像经过M×M的卷积核卷积后将得到（N-M+1）×（N-M+1）的输出。 卷积后输出的矩阵数据成为特征映射图，一个卷积核输出一个特征映射图，卷积操作是一种线性计算，因此通常在卷积后进行一次非线性映射。 池化层池化层是将卷积得到的特征映射图进行稀疏处理，减少数据量，操作与卷积基本相似，不同的是卷积操作是一种线性计算，而池化的计算方法更多样化，一般有如下计算方式： 最大池化：取样池中的最大值作为池化结果 均值池化：取样池中的平均值作为池化结果 还有重叠池化、均方池化、归一化池化等方法。 全连接层在网络的末端对提取后的特征进行恢复，重新拟合，减少因为特征提取而造成的特征丢失。全连接层的神经元数需要根据经验和实验结果进行反复调参。 输出层输出层用于将最终的结果输出，针对不同的问题，输出层的结构也不相同，例如MNIST数据集识别问题中，输出层为有10个神经元的向量。 示例网络结构示例模型包括输入层、两个卷积层、两个池化层、全连接层和输出层，其中卷积和池化操作的特征图输出大小计算公式为： ImageWidth：图片宽度 Padding：边缘补齐像素数 KernelSize：卷积核宽度 Stride：移动步长 具体模型结构如下所示： 程序解读Tensorflow中使用图来表示计算任务，在会话(Session)中执行图，使用 tensor 表示数据.通过变量(Variable)维护状态，使用 feed 和 fetch 可以为任意的操作赋值或者从其中获取数据. 加载MNIST数据集1mnist =input_data.read_data_sets(&quot;MNIST_data&quot;, one_hot=True) 命令会自动下载MNIST数据集，存放在”MNIST_data”目录下，也可以手动下载数据集后放入此目录下。执行read_data_sets()函数后将会返回一个DataSet实例，其中包含训练数据、验证数据和测试数据。 创建Session和占位符123sess =tf.InteractiveSession()x =tf.placeholder(&quot;float&quot;, shape=[None, 784])y_ =tf.placeholder(&quot;float&quot;, shape=[None, 10]) x和y_都是tensor，其中x表示输入数据，由于是28×28像素的灰度图片，因此输入为784维的向量。y_表示模型输出，为0-9的数字，因此是10维的向量。 定义卷积层1的权重和偏置量12w_conv1 = tf.Variable(tf.truncated_normal([5,5, 1, 32], stddev=0.1))b_conv1 =tf.Variable(tf.constant(0.1, shape=[32])) 卷积操作的计算公式为：W × X + b [5, 5, 1,32]表示卷积核的大小为5×5，输出为32，即共有32个卷积核，卷积操作会产生32个特征映射图。 其中w_conv1表示权重W，由正太分布截取得出。b_conv1表示偏置量，初始值均为0.1，由于卷积操作会输出32个特征图，因此偏置量的维度为32。 卷积层11x_image =tf.reshape(x, [-1,28,28,1]) 将输入tensor x 调整成为28×28矩阵形式。12r_conv1 = tf.nn.conv2d(x_image,w_conv1, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;) + b_conv1h_conv1 = tf.nn.relu(r_conv1) 进行卷积操作W × X + b，得到线性变化的结果r_conv1，再利用Tensorflow的relu规则进行非线性映射，出的卷积的结果h_conv1。 池化层11h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;) 采用了最大池化方法，其中ksize表示取样池的大小，strides表示步长，padding表示边缘补齐方法，SAME方式会在图片边缘补0，补齐边缘像素为1，最终得出池化结果h_pool1。 定义卷积层2的权重和偏置量12w_conv2 =tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))b_conv2 =tf.Variable(tf.constant(0.1, shape=[64])) 卷积层2的输入为32张特征映射图，有64个卷积核，最终将输出64个特征映射图。 卷积层2和池化层2123r_conv2 = tf.nn.conv2d(h_pool1,w_conv2, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;) + b_conv1h_conv2 =tf.nn.relu(r_conv2)h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;) 经过卷积层2和池化层2后，得到64张7×7的特征映射图。 全连接层12W_fc1 =tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))b_fc1 =tf.Variable(tf.constant(0.1, shape=[1024])) 全连接层设有1024个神经元，本层的神经元数需要根据经验和实验结果进行反复调参确定。12h_pool2_flat= tf.reshape(h_pool2, [-1, 7*7*64])h_fc1 =tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) 将第二层池化后的数据调整为7×7×64的向量，与全连接层的权重进行矩阵相乘，然后进行非线性映射得到1024维的向量。 输出层123W_fc2 = tf.Variable(tf.truncated_normal([1024,10], stddev=0.1))b_fc2 = tf.Variable(tf.constant(0.1,shape=[10]))y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2) 输出层为10维的向量，通过softmax函数输出。 参考资料深度学习（四）卷积神经网络入门学习(1)深度学习之卷积神经网络CNN及tensorflow代码实现示例TensorFlow 官方文档 源码地址：Tensorflow卷积神经网络（CNN）手写数字识别]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>卷积神经网络</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遗传算法求解TSP问题]]></title>
    <url>%2F2019%2F04%2F10%2F%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E6%B1%82%E8%A7%A3TSP%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述旅行商问题是图论中的一个经典问题。 假设有一个旅行商人要拜访N个城市，要求他从一个城市出发，每个城市最多拜访一次，最后要回到出发的城市，保证所选择的路径长度最短。 算法描述算法简介遗传算法（GeneticAlgorithm）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，通过模拟自然进化过程搜索最优解。遗传算法是从代表问题可能潜在的解集的一个种群（population）开始的，初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。这个过程将导致种群像自然进化一样的后生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解。（摘自百度百科）。 遗传算子遗传算法中有选择算子、交叉算子和变异算子。 选择算子用于在父代种群中选择进入下一代的个体。 交叉算子用于对种群中的个体两两进行交叉，有Partial-Mapped Crossover、Order Crossover、Position-based Crossover等交叉算子。 变异算子用于对种群中的个体进行突变。 算法步骤遗传算法的基本运算过程如下： 初始化：设置进化代数计数器t=0、设置最大进化代数T、交叉概率、变异概率、随机生成M个个体作为初始种群P 个体评价：计算种群P中各个个体的适应度 选择运算：将选择算子作用于群体。以个体适应度为基础，选择最优个体直接遗传到下一代或通过配对交叉产生新的个体再遗传到下一代 交叉运算：在交叉概率的控制下，对群体中的个体两两进行交叉 变异运算：在变异概率的控制下，对群体中的个体两两进行变异，即对某一个体的基因进行随机调整 经过选择、交叉、变异运算之后得到下一代群体P1。 重复以上1-6，直到遗传代数为T，以进化过程中所得到的具有最大适应度个体作为最优解输出，终止计算。 求解说明优化目标给定二维数据int[][]pos用于存储各个城市的坐标，采用欧式距离代表城市之间的距离。利用遗传算法，找到不重复遍历所有城市的路径中，所走距离最短的路径。 选择算子选择算子采用轮盘赌选择，以每个个体的适应度为基础，为每个个体计算累积概率。 个体1、2、3、4的个体适应度如上图所示。 适应度计算规则：染色体代表的路径实际距离作为个体的适应度，如下（distence[x][y]表示城市x到y的距离） 染色体 0 2 1 3，适应度为distence[0][2] + distence[2][1] + distence[1][3] + distence[3][0] qa 表示个体a的累积概率，如上图所示个体1、2、3、4的累积概率分别为0.14、0.53、0.69、1 随机生成一个0到1的浮点数f，若 qa &lt; f &lt;= qb，则个体b被选中。 交叉算子Partial-Mapped Crossover（部分映射交叉）Order Crossover（顺序交叉）Position-based Crossover（基于位置的交叉） 变异算子变异算子随机进行多次，每次在个体基因序列中选择两个位置的基因进行交换。 参考资料用遗传算法求解TSP问题 源码地址：遗传算法求解TSP问题（参考自 基于遗传算法求解TSP问题（JAVA））]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>遗传算法</tag>
        <tag>TSP问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用极小极大搜索和alpha-beta剪枝算法预测五子棋对弈落子]]></title>
    <url>%2F2019%2F04%2F10%2F%E5%88%A9%E7%94%A8%E6%9E%81%E5%B0%8F%E6%9E%81%E5%A4%A7%E6%90%9C%E7%B4%A2%E5%92%8Calpha-beta%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%95%E9%A2%84%E6%B5%8B%E4%BA%94%E5%AD%90%E6%A3%8B%E5%AF%B9%E5%BC%88%E8%90%BD%E5%AD%90%2F</url>
    <content type="text"><![CDATA[问题描述利用极小极大搜索和alpha-beta剪枝算法预测五子棋落子问题，初始棋局如图所示，AI为白子，玩家为黑子，当前由AI落子。 算法描述极小化极大算法极小化极大搜索是一种在有限的深度范围内搜索博弈树的求解方法，程序代表AI方MAX节点，目的是打败玩家，基本原理为： （1）轮到MIN落子时，MAX节点考虑最坏的情况，即评估函数取极小值。 （2）轮到MAX落子时，MAX节点考虑最好的情况，即评估函数取极大值。 （3）搜索到叶子节点进行回溯，代表双方的对抗策略，交替使用（1）（2）规则回溯到root节点即可得到评估值。 123456789101112function minimax(node, depth) // 给定初始状态和搜索深度 if node is a terminal node or depth = 0 return the evaluate value of the node //使用评估函数返回局面得分 if player’s turn // 玩家走棋，是极小节点，选择一个得分最小的走法 let val := +∞ foreach child of node val := min(val, minimax(child, depth-1) else AI’s turn //AI走棋，是极大节点，选择一个得分最大的走法 let val := -∞ foreach child of node val := max(val, minimax(child, depth-1)) return val; Alpha-beta算法极小化极大算法的搜索效率非常低下，而Alpha-beta剪枝算法能够提高搜索效率，基本原理为： （1）alpha剪枝：任何极小层（由MIN落子）的节点的beta值都不大于其前驱节点（MAX节点）的alpha值，即搜索过程中，只要找到一个MIN节点的评估值不大于其前驱MAX节点的评估值，则可舍弃后续的搜索，这表示当前MIN节点落子对MAX是有利的。 （2）beta剪枝：任何极大层（由MAX落子）的节点的alpha值都不小于其前驱节点（MIN节点）的beta值。即搜索过程中，只要找到一个MAX节点的评估值不小于其前驱MIN节点的评估值，则可舍弃后续的搜索，这表示当前MAX节点落子对MAX是有利的。 12345678910111213141516function alphaBeta(node, alpha, beta , depth) if node is a terminal node or depth = 0 return the evaluate value of node //使用评估函数返回局面得分 else if AI’s turn foreach child of node val := alphaBeta(child, alpha, beta, depth-1) if(val &gt; alpha) alpha:= val if(alpha &gt;= beta) break return alpha else player’s turn foreach child of node val := alphaBeta(child, alpha, beta, depth-1) if(val &lt; beta) beta:= val if(alpha &gt;= beta) break return beta 评估函数评估函数用于对博弈树中的叶子节点的状态进行评估，需要考虑五子棋中的基本棋型和特点，对叶子节点的棋局进行评估，给出评估值。 五子棋中的基本棋型（1代表AI落子，2代表玩家落子，0代表空位）： （1）连五：五颗同色棋子连在一起，如11111，22222 （2）活四：有两个点可以形成连五，如011110，022220 （3）冲四：有一个点可以形成连五，如011112，122220 （4）活三：可以形成活四的三点，如001110，002220 （5）眠三：只能形成冲四的三点，如001112，002221 （6）活二：能够形成活三的二点，如000110，000220 （7）眠二：能够形成眠三的二点，如000112，000221 在程序中可以某一坐标为中心，将改坐标点横竖撇捺四个方向的状态拼接为字符串，判断字符串是否包含上述的某种棋型作为判断标准。 由于算法是针对AI而言，因此在评估函数中，对玩家方赋予负值，AI方赋予正值。对于棋盘中的落子，从横竖撇捺四个方向判断形成的基本棋型，对不同的棋型赋予不同的权重，如连五代表一方胜利，赋予最大值代表AI胜利，赋予最小值代表玩家胜利。 根据棋型的重要性，划分权重如下（AI权重为正，玩家权重为负）： 棋型 权重 连五 100000000 活四 10000000 冲四 1000000 活三 100000 眠三 10000 活二 1000 眠二 1000 活二 100 仅一 10 无 1 （一）评估函数v1 在评估过程中，计算AI所有落子位置横竖撇捺四个方向形成的棋型，得出评估值作为叶子节点的评估值。 效果：此种评估方式效果很差，仅对AI落子点进行判断过于片面，且会造成急于进攻疏于防守的局面。 （二）评估函数v2 在评估过程中，将棋盘中的所有落子的评估值相加得出最后的评估值。最终得到的评估值实际为AI落子形成的棋局评估值减玩家落子形成的棋局评估值。按此计算的目的是平衡进攻和防守。以叶子节点的评估值进行回溯，进而选择初始状态的下一步落子。 效果：评估结果较好，能够平衡进攻和防守。 参考资料五子棋基本棋型及其特点Alpha-beta剪枝极小极大搜索方法、负值最大算法和Alpha-Beta搜索方法五子棋的核心算法Alpha-Beta搜索最小-最大搜索五子棋AI算法第四篇-启发式搜索函数 源码地址：利用极小极大搜索和alpha-beta剪枝算法预测五子棋对弈落子]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>极小极大搜索</tag>
        <tag>alpha-beta剪枝</tag>
        <tag>博弈树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A*算法求解15数码问题]]></title>
    <url>%2F2019%2F04%2F10%2FA%E6%98%9F%E7%AE%97%E6%B3%95%E6%B1%82%E8%A7%A315%E6%95%B0%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述利用A*算法进行表1到表2的转换，要求空白块移动次数最少。 转换规则为：空白块只可以与上下左右四个方向的相邻数字交换。 算法简介A*算法是一种在图形平面上，有多个节点的路径，求出最低通过成本的算法。该算法综合了Best-First Search和Dijkstra算法的优点：在进行启发式搜索提高算法效率的同时，基于评估函数计算损失，保证找到一条最优路径。 算法能否找到最优解的关键在于评估函数的选择，A*算法的评估函数表示为：f(n) = g(n) + h(n) f(n) 是从初始状态经由状态n到目标状态的代价估计 g(n) 是在状态空间中从初始状态到状态n的实际代价 h(n) 是从状态n到目标状态的最佳路径的估计代价 例如在8数码问题中，g(n) 表示状态空间树中搜索的层数，h(n) 表示状态n与目标状态中元素位置不同的元素个数。 算法步骤设定两个集合，open集，close集 将起始点加入open集（设置父亲节点为空） 在open集中选着一个f(n)值最小的节点作为当前节点 2.1. 将当前节点从open集中移除，添加到close集 2.2. 如果当前节点为终点节点，那么结束搜索 2.3. 处理当前节点的所有邻接节点，规则如下： 如果不在open集中，那么就将其添加到open集，并将该节点的父节点为当前节点 如果已经添加到open集中，重新计算f(n)值，如果f(n)值小于先前的f(n)值，那么就更新open集中相应节点的f(n) 如果该节点不可通过或者已经被添加到close集，那么不予处理 如果open集不为空，那么转到步骤2继续执行。 评估函数f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态不同的元素个数 效果：与8数码问题使用了相同的评估函数，大概跑了30W步无法求出解 评价：效果极差，15数码问题的状态空间树要远复杂于8 数码问题，且15数码问题中空白块的移动更为复杂，此评估函数不适用。 f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态各个位置数字偏差的绝对值 效果：随着搜索的进行，空白块的移动集中在表格上部，表格下部几乎不移动 ，无法求出解 评价：因为下部数字较大，移动后差值较大造成评估值较大，因此搜索集中在了数值较小的部分，效果很差。 f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态各个元素的路径差值（一维数组各元素的距离差之和） 效果：空白块最终移动55步得到目标状态。 评价：效果比较理想，但h(n)还可继续优化。 f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态各个元素的曼哈顿距离 效果：空白块最终移动41步得到目标状态。 评价：效果理想。 实际上，1和2的评估函数效果大致相同，都将搜索局限在了一部分导致无法计算出问题的解。3实际是以一维数组各元素的距离差之和估计状态n到目标状态的曼哈顿距离，但此估计方式和计算平面两点的曼哈顿距离存在较大误差，因此只求解出可行解。 参考资料A*算法详解，看完后全懂了启发式搜索浅谈，解决八数码问题 源码地址：A*算法求解15数码问题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>15数码</tag>
        <tag>A*算法</tag>
      </tags>
  </entry>
</search>
