<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（七）Config配置中心]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89Config%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[概述在微服务架构中，一个系统划分为多个服务，每个服务有各自的配置，Spring Cloud Config提供了集中管理服务配置的功能，并且可以在服务运行时动态调整配置，不需要重启服务。 Spring Cloud Config包括Config Server和Config Client两部分。 Config Server是一个可横向扩展、集中式的配置服务器，默认使用Git存储配置内容，本篇中也将使用Git存储各服务的配置。 Config Client即为各个微服务。在服务启动时，会向Config Server请求所需的配置属性，并缓存在本地使用。 构建Config Server创建Github配置仓库在github创建一个配置仓库 yogurt-config，分别创建user-ms-dev.yml和role-ms-dev.yml，内容分别如下： user-ms-dev.yml： 12345datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/yogurt-user?useUnicode=true&amp;characterEncoding=utf8 username: root password: role-ms-dev.yml： 12345datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/yogurt-role?useUnicode=true&amp;characterEncoding=utf8 username: root password: 可以看到在两个配置文件中分别配置了不同的数据源，当然也可以添加一些其他的配置，这里只是作为一个例子。 创建config-server项目config-server作为配置中心，本身也是一个服务，因此也可以注册到服务注册中心中。在创建config-server项目时，勾选Eureka Discovery和Config Server两个依赖，创建成功的项目中将包括如下依赖： 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写配置文件，添加git仓库的地址和服务注册配置，如下： 123456789101112131415server: port: 8010spring: application: name: config-server cloud: config: server: git: uri: git@github.com:GreedyStar/yogurt-config.git label: mastereureka: client: service-url: defaultZone: http://admin:admin123@127.0.0.1:8000/eureka/ 如果是私有项目的话，还需要在git节点下配置username和password。 修改config-server启动类，添加@EnableConfigServer和@EnableEurekaClient注解，如下： 12345678@SpringBootApplication@EnableConfigServer@EnableEurekaClientpublic class ConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigServerApplication.class, args); &#125;&#125; 这样，config-server配置中心就构建完成了。 测试访问配置数据我们可以在config-server通过http请求访问git仓库的配置数据，访问规则如下： /{name}/{profile}[/{label}] /{name}-{profile}.yml /{label}/{name}-{profile}.yml /{name}-{profile}.properties /{label}/{name}-{profile}.properties name：表示服务名称，如user-ms、role-ms profile：表示config-client配置的profile，如dev、test、prod等 label：表示git仓库的分支 例如我们可以通过访问 http://localhost:8010/user-ms/dev/master 来获取github仓库中user-ms-dev.yml的配置内容，如下： 构建Config Client添加依赖以user-ms为例，配置Config Client。 首先，为user-ms工程添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 配置bootstrap.ymlbootstrap.yml用于配置config数据的拉取，在resources目录下新建bootstrap.yml，之所以使用bootstrap.yml而不是application.yml，是因为我们的配置数据大多是用来配置IOC容器的，而bootstrap.yml会在IOC容器启动前加载，以此可以实现配置数据的远端加载，bootstrap.yml内容如下： 123456789101112131415spring: application: name: user-ms cloud: config: profile: dev label: master# uri: http://localhost:8010/ # 在不将config-server注册到eureka-server时需要用到 discovery: enabled: true service-id: config-servereureka: client: service-url: defaultZone: http://admin:admin123@127.0.0.1:8000/eureka/ 这里有一点需要注意，前面的内容中，我们将config-server注册到了eureka-server，因此我们可以从eureka-server来发现config-server服务，然后拉取配置数据。如果没有将config-server注册到eureka-server，则可以直接在uri节点指定config-server的地址。 修改application.yml在前面的章节中，我们在application.yml中为user-ms添加了Druid数据源的相关配置，现在这些配置已经放在了Github仓库中，我们需要修改user-ms的配置文件，修改后的application.yml内容如下： 1234567server: port: 8800mybatis: mapper-locations: classpath:mappers/*Mapper.xmlfeign: hystrix: enabled: true 可以看到，在application.yml中已经移除了Druid数据源的相关配置。 创建配置类首先，创建一个DruidProperty类，用于接收从config-server拉取的配置数据，如下所示： 123456789101112131415161718192021222324252627@Componentpublic class DruidProperty &#123; @Value("$&#123;datasource.driver-class-name&#125;") private String driverClassName; @Value("$&#123;datasource.url&#125;") private String url; @Value("$&#123;datasource.username&#125;") private String username; @Value("$&#123;datasource.password&#125;") private String password; public String getDriverClassName() &#123; return driverClassName; &#125; public String getUrl() &#123; return url; &#125; public String getUsername() &#123; return username; &#125; public String getPassword() &#123; return password; &#125;&#125; @Value注解中的Key对应Github配置仓库中配置文件中的key。 然后，创建DruidDataSource的配置类，并引用上面的DruidProperty类，如下： 12345678910111213141516@Configurationpublic class DruidConfig &#123; @Autowired private DruidProperty druidProperty; @Bean public DataSource druidDataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(druidProperty.getDriverClassName()); dataSource.setUrl(druidProperty.getUrl()); dataSource.setUsername(druidProperty.getUsername()); dataSource.setPassword(druidProperty.getPassword()); return dataSource; &#125; &#125; 这样，我们就实现了从config-server拉取Druid数据源的配置，并应用于user-ms服务中。 测试配置数据拉取按顺序启动 eureka-server、config-server、user-ms，可以看到user-ms在启动时会向config-server拉取配置信息，并且可以正常访问yogurt-user数据库，如下： 动态配置更新在一些情况下，我们可能需要对线上的服务进行配置修改，但我们在Git仓库修改配置信息后，config-server可以读取到新的配置，而config-client（各微服务）由于在本地缓存了配置而无法动态更新配置信息，我们可以借助Actuator实现在不重启服务的情况下更新服务的配置，下面对user-ms进行一些改造，让它支持动态配置更新。 配置ActuatorActuator可以帮助我们监控和管理Spring Boot应用，并通过一些HTTP端点来进行健康检查、统计等操作。 为user-ms添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 修改application.yml，添加如下配置： 12345management: endpoints: web: exposure: include: refresh,health 上面的配置表示向外部暴露/actuator/refresh和/actuator/health接口，我们可以通过/actuator/refresh来通知client更新配置。 添加@RefreshScope注解@RefreshScope注解是实现动态配置更新的重要注解。 当我们调用/actuator/refresh时，springboot会用新配置创建一个新的IOC容器，然后与原IOC容器的配置进行比较，找出那些修改了的配置，然后使用新配置重新创建由@RefreshScope注解的Bean。 修改DruidProperty类和DruidDataSource类，如下： 1234567891011121314@RefreshScope@Componentpublic class DruidProperty &#123; @Value("$&#123;datasource.driver-class-name&#125;") private String driverClassName; @Value("$&#123;datasource.url&#125;") private String url; @Value("$&#123;datasource.username&#125;") private String username; @Value("$&#123;datasource.password&#125;") private String password; // 省略部分代码&#125; 1234567891011121314151617@Configurationpublic class DruidConfig &#123; @Autowired private DruidProperty druidProperty; @RefreshScope @Bean public DataSource druidDataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(druidProperty.getDriverClassName()); dataSource.setUrl(druidProperty.getUrl()); dataSource.setUsername(druidProperty.getUsername()); dataSource.setPassword(druidProperty.getPassword()); return dataSource; &#125; &#125; 这里有一点需要注意，@RefreshScope注解不应与@Configuration注解同时使用，官方给出的说明是同时使用会出现意想不到的情况，@RefreshScope应当标注在那些需要重新创建的Bean上。 OK，到这里，动态配置更新就完成了，下面简单测试一下。 测试配置更新首先，我们请求config-server看一下user-ms目前的配置： 然后，请求user-ms看一下数据库yogurt-user中的数据： 再然后，我们将Github中user-ms-dev.yml文件的数据库名由yogurt-user修改为yogurt-user-backup，如下： 12345datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/yogurt-user-backup?useUnicode=true&amp;characterEncoding=utf8 username: root password: yogurt-user中有三条数据，yogurt-user-backup数据库中只有一条数据。 请求请求config-server看一下修改后的配置，可以看到配置信息已经修改了： 再请求user-ms可以看到user-ms依然是yogurt-user数据库中的数据： 访问user-ms的/actuator/refresh接口，通知user-ms刷新配置，从返回结果中可以看到，修改的数据是datasouce.url： 再次访问user-ms，可以看到只有一条数据了，即数据库切换至了yogurt-user-backup： 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringConfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（六）Zuul服务网关]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89Zuul%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[概述Zuul是Netflix开源的微服务网关，SpringCloud进行了集成，能够非常方便地与Eureka、Ribbon等组件集成。 本篇拟采用Zuul搭建一个简单的微服务网关。 构建Zuul服务网关构建gateway项目因为我们要将gateway注册到服务中心，因此构建项目时，选择Eureka Client和Zuul依赖，如下所示： 创建成功后，pom.xml会包含如下两个选择的依赖： 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写application.yml配置文件，如下： 1234567891011121314151617server: port: 8020spring: application: name: gatewayeureka: client: service-url: defaultZone: http://admin:admin123@127.0.0.1:8000/eureka/zuul: routes: user-ms: path: /user/** strip-prefix: false role-ms: path: /role/** strip-prefix: false 上面zuul.routes节点的配置中，星号代表通配符，表示将 /user/ 开头的请求路由至user-ms微服务，将 /role/ 开头的请求路由至role-ms微服务。 路由配置示例Zuul支持多种方式的路由配置，如下所示（参考自：《Spring Cloud与Docker微服务架构实战》）： 定义指定服务的访问路径 1234zuul: routes: user-ms: /u/** role-ms: /r/** 忽略指定的服务 12zuul: ignored-services: serviceA,ServiceB 忽略所有服务 12zuul: ignored-services: '*' 指定服务的serviceId和路径 12345zuul: routes: user: # 服务别名，可任意起名 service-id: user-ms path: /u/** 指定url和路径 12345zuul: routes: github: path: /github/** url: https://github.com/GreedyStar 路由前缀 12345zuul: routes: user-ms: path: /user/** strip-prefix: false 访问Zuul的 /user/1 路径，请求会转发至user-ms的/user/1 这是很常用的一种方式，在user-ms的Controller中，我们将所有请求映射至/user/路径下，在不配置strip-prefix时，我们需要请求user-ms/user/user/list 才能正确请求到user-ms的接口。 测试我们可以通过gateway来访问到指定的微服务，本篇中建立的路由规则为： Path MicroService /user/** user-ms localhost:8800 /role/** role-ms localhost:8801 结果如下： 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（五）Hystrix断路器]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89Hystrix%E6%96%AD%E8%B7%AF%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述微服务架构的系统中通常会包含很多个服务，服务间采用HTTP通信，当某个微服务不可用时，很容易导致级联故障，即雪崩效应，因此在服务间进行调用时，需要一定的容错机制，Hystrix就是一个实现了调用超时和断路器的容错组件。 Feign中已经集成了Hystrix，本篇以user-ms为例，添加对role-ms调用的熔断处理。 Hystrix配置修改user-ms配置文件，添加如下配置，启用feign下的hystrix： 123feign: hystrix: enabled: true 添加回退处理创建一个熔断后退处理类，其需要实现feign接口，如下所示： 123456789101112@Componentpublic class RoleFeignClientFallback implements RoleFeignClient &#123; @Override public Object list() &#123; return "list:Service Unavailable"; &#125; @Override public String insert(Role role) &#123; return "insert:Service Unavailable"; &#125;&#125; 修改FeignClient接口，添加fallback配置，如下所示： 12345678910@FeignClient(name = "role-ms", fallback = RoleFeignClientFallback.class)public interface RoleFeignClient &#123; @RequestMapping(value = &#123;"/role/list"&#125;, method = RequestMethod.GET) Object list(); @RequestMapping(value = "/role/insert", method = RequestMethod.POST) String insert(@RequestBody Role role); &#125; 至此，熔断回退处理就添加完成了，在不启动role-ms（role-ms崩溃）的情况下，user-ms调用role-ms服务，则会返回Fallback类中的数据。 检查回退原因创建一个熔断后退处理工厂类，其需要实现FallbackFactory接口，如下所示： 123456789101112131415161718@Componentpublic class RoleFeignClientFallbackFactory implements FallbackFactory&lt;RoleFeignClient&gt; &#123; @Override public RoleFeignClient create(Throwable throwable) &#123; RoleFeignClient roleFeignClient = new RoleFeignClient() &#123; @Override public Object list() &#123; return throwable.getMessage(); &#125; @Override public String insert(Role role) &#123; return throwable.getMessage(); &#125; &#125;; return roleFeignClient; &#125;&#125; 修改FeignClient接口，添加fallbackFactory配置，如下所示： 12345678910@FeignClient(name = "role-ms", fallbackFactory = RoleFeignClientFallbackFactory.class)public interface RoleFeignClient &#123; @RequestMapping(value = &#123;"/role/list"&#125;, method = RequestMethod.GET) Object list(); @RequestMapping(value = "/role/insert", method = RequestMethod.POST) String insert(@RequestBody Role role); &#125; 在不启动role-ms（role-ms崩溃）的情况下，user-ms调用role-ms服务，则会返回 com.netflix.client.ClientException: Load balancer does not have available server for client: role-ms，这样使用FallbackFactory可以更灵活的控制返回数据。 注意：当fallback和fallbackFactory同时配置时，会优先使用fallback。 本篇的配置和测试都比较简单，这里就不贴测试结果了。 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（二）Eureka服务注册中心]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89Eureka%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[概述Eureka是一个服务注册中心，分为Eureka Server和Eureka Client，Server和Client均是SpringBoot应用程序，其中Client即为各个微服务，其需要向Server进行注册，并发送心跳来维护活跃，下面开始构建一个简单的Eureka服务注册环境。 Eureka Server构建Server项目通过IDEA的Spring Initializr创建一个包含Eureka Server组件依赖的SpringBoot项目，如下图所示勾选Eureka Server依赖，填写项目的相关信息一路next到finish。 本例创建了一个名为eureka-server的SpringBoot项目，创建成功后，IDEA会自动为我们添加Eureka Server依赖，如下： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 下面，对项目进行一些配置，启用Eureka Server的功能。 首先，编写 application.yml 配置文件，内容如下： 12345678910server: port: 8000eureka: instance: hostname: 127.0.0.1 # 服务注册中心IP地址 client: registerWithEureka: false # 向服务注册中心注册自己 fetchRegistry: false # 检索服务 service-url: # 指定服务注册中心的位置 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 由于配置的是server，不需要将server本身注册到服务中心，因此需要关闭一些默认为true的配置，最终的eureka注册地址为：http://127.0.0.1:8000/eureka，这也是client进行服务注册的请求地址。 然后，修改启动类，添加 @EnableEurekaServer 注解，如下： 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 至此，一个单点的Eureka Server就搭建完成了，在浏览器输入localhost:8000，可以看到如下界面： 但是我们会发现，后台界面不需要任何认证即可访问，接下来，我们来为Server添加Spring Security认证 添加Spring Security认证在pom.xml添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 修改 application.yml 配置文件，启用Spring Security，如下： 123456789101112131415server: port: 8000spring: security: user: name: admin password: admin123eureka: instance: hostname: 127.0.0.1 # 服务注册中心IP地址 client: registerWithEureka: false # 是否向服务注册中心注册自己 fetchRegistry: false # 是否检索服务 service-url: # 服务注册中心的配置内容，指定服务注册中心的位置 defaultZone: http://$&#123;spring.security.user.name&#125;:$&#123;spring.security.user.password&#125;@$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 需要注意的是，添加Security认证后，注册位置变成 http://admin:admin123@127.0.0.1:8000/eureka 修改启动类，添加@EnableWebSecurity注解，如下： 12345678@SpringBootApplication@EnableEurekaServer@EnableWebSecuritypublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 网上很多的教程均是通过此种方式进行配置的，但这种方式存在一个问题：Client无法向Server注册服务，错误信息为 Cannot execute request on any known server，具体可以参考SpringCloud下的ISSUE spring boot 2.0,eureka registration failed with spring security 原因为：SpringBoot 2.0版本起，Security中默认启用了CSRF保护，需要关闭CSRF保护。 新建Security配置类，如下： 1234567891011121314@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity httpSecurity) throws Exception &#123; httpSecurity .csrf().disable() .authorizeRequests() .anyRequest().fullyAuthenticated() .and() .httpBasic(); &#125;&#125; 这里需要注意的是，如果直接通过 http.csrf().disable(); 关闭SCRF保护（网上很多方案均是如此），那么也将关闭其他请求的认证，因此需要为其他的请求配置需要认证。 OK，到这里，Server的配置就完成了，再次访问后台界面时，浏览器就会弹出登录认证了。 Eureka Client构建Client项目通过IDEA的Spring Initializr创建一个包含Eureka Discovery组件依赖的SpringBoot项目，勾选如下图所示的Eureka Discovery依赖。Eureka Client即为各个微服务，本例拟构建两个微服务，分别为用户微服务user-ms和角色微服务role-ms，下面的配置均以role-ms为例。 创建成功后，pom.xml依赖如下： 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; user-ms还需要mybatis、mysql驱动、druid等依赖，这里就不贴出来，具体可以参考博客中SpringBoot下的相关文章。 编写 application.yml 配置文件如下： 123456789101112131415161718server: port: 8800spring: application: name: user-ms datasource: type: com.alibaba.druid.pool.DruidDataSource druid: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/yogurt-user?useUnicode=true&amp;characterEncoding=utf8 username: root password: mybatis: mapper-locations: classpath:mappers/*Mapper.xmleureka: client: service-url: defaultZone: http://admin:admin123@127.0.0.1:8000/eureka/ 修改启动类，添加@EnableEurekaClient注解，表示这是一个Eureka Client应用，如下所示： 1234567@SpringBootApplication@EnableEurekaClientpublic class UserMsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserMsApplication.class, args); &#125;&#125; 测试 启动 eureka-server 项目 启动 user-ms 和 role-ms 项目 服务注册中心后台如下图所示： 从图中可以看到，role-ms 和 user-ms 两个微服务已经注册到了 Server 中。 Eureka Server 集群上面构建的 Eureka Server 是一个单点部署的服务注册中心，这种方式在服务注册中心崩溃时会导致整个系统的瘫痪，通常hi使用集群化部署的方式来避免这个问题。 Eureka Server 集群的配置与单点配置大致相同，唯一的不同之处在于需要在每个 Server 的配置中指定集群中其他 Server 节点的地址，如下所示： Server1配置： 12345678910server: port: 8000eureka: instance: hostname: server1 client: registerWithEureka: false fetchRegistry: false service-url: defaultZone: http://server2:8001/eureka/,http://server3:8002/eureka/ Server2配置： 12345678910server: port: 8001eureka: instance: hostname: server2 client: registerWithEureka: false fetchRegistry: false service-url: defaultZone: http://server1:8000/eureka/,http://server3:8002/eureka/ Server3配置： 12345678910server: port: 8002eureka: instance: hostname: server2 client: registerWithEureka: false fetchRegistry: false service-url: defaultZone: http://server1:8000/eureka/,http://server2:8001/eureka/ 按照如上配置，分别启动多个eureka-server实例即可启动集群化部署。 Client 在指定 Server 注册地址时，可以指定一个或多个地址，多个地址间用”,”分隔。 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（四）Ribbon客户端负载均衡器]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89Ribbon%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述在微服务架构的系统中，为防止单点故障，一个微服务通常会有多个实例，当服务间进行调用时，需要在多个服务实例间进行负载均衡，Ribbon即为一个常用的客户端负载均衡组件。 Ribbon提供了多种负载均衡规则，如： RoundRobinRule：轮询规则，默认规则 AvailabilityFilteringRule：排除处于断路和并发连接数过大的服务，其余服务采用轮询规则 WeightedResponseTimeRule：根据平均响应时间计算权重 RetryRule：服务调用失败则进行重试，获得可用的服务 BestAvailableRule：选择可用且并发连接数最小的服务 RandomRule：随机选取服务 Feign中默认集成了Ribbon，上一篇中我们已经为user-ms集成了Feign，这一篇中，我们来对Ribbon进行一些简单的配置。 本篇中，拟采用一个user-ms实例作为服务调用者，两个role-ms实例作为服务提供者，在user-ms设置Ribbon负载均衡规则。 配置RibbonRibbon的配置有多种方式，分别对应不同粒度的配置。 配置文件在user-ms的application.yml配置文件中添加如下配置： 123role-ms: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 表示 user-ms 在调用 role-ms 提供的服务时，使用随机均衡的规则。 全局配置类在 SpringBoot 所在的包路径下创建一个 Ribbon 的配置类，如下： 1234567@Configurationpublic class RibbonConfig &#123; @Bean public IRule ribbonRule() &#123; return new RandomRule(); // 负载均衡规则改为随机 &#125;&#125; user-ms启动时，SpringBoot会扫描到这个配置类，将RandomRule规则作为user-ms的全局负载均衡规则，无论user-ms访问哪个服务提供者都，都使用该负载均衡规则。 服务级配置类定义@ExcludeComponent注解，用于标注那些不希望SpringBoot扫描的类，如下： 123public @interface ExcludeComponent &#123; &#125; 修改BibbonConfig配置类，添加@ExcludeComponent注解，如下： 12345678@Configuration@ExcludeComponentpublic class RibbonConfig &#123; @Bean public IRule ribbonRule() &#123; return new RandomRule(); // 负载均衡规则改为随机 &#125;&#125; 定义RibbonClient配置类，为特定的微服务指定Ribbon配置，如下所示，为role-ms指定RibbonConfig配置类： 12345@Configuration@RibbonClient(name = "role-ms", configuration = RibbonConfig.class)public class RoleMSConfig &#123; &#125; 修改SpringBoot启动类，排除对@ExcludeComponent注解类的扫描，如下： 123456789@SpringBootApplication@EnableEurekaClient@EnableFeignClients@ComponentScan(excludeFilters = @ComponentScan.Filter(type = FilterType.ANNOTATION, value = &#123;ExcludeComponent.class&#125;))public class UserMsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserMsApplication.class, args); &#125;&#125; 这样，服务级的配置类就完成了，当然我们也可以自定义Ribbon的负载均衡规则，对不同的服务采用不同的规则。 测试启动role-ms:8801和role-ms:8802两个服务实例，通过user-ms访问role-ms服务，服务注册中心如下图所示： 在user-ms访问12次，负载均衡结果如下： 可见服务调用请求已经随机均衡至role-ms:8801和role-ms:8802两个实例中。 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（一）概述]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[正如 Spring官网 中所表示的，SpringCloud为我们集成了许多开箱即用的优质服务框架，并依托SpringBoot的便利性，为开发者提供了快速构建微服务的环境。SpringCloud包括的服务框架主要有： Spring Cloud Eureka：服务注册中心 Spring Cloud Ribbon：客户端负载均衡器 Spring Cloud Feign：声明式REST调用 Spring Cloud Hystrix：断路器 Spring Cloud Config：分布式配置中心 Spring Cloud Zuul：服务网关 Spring Cloud Bus：消息总线 关于各组件的介绍网上已经有很多资料了，大家可以参考：Spring Cloud全家桶主要组件及简要介绍 本系列博客的目的是采用常用的SpringCloud服务组件，搭建一个简易的微服务环境，主要以实践内容为主，不会过多涉及各服务组件的介绍。由于精力有限，文中出现的错误还请各位同学指正，博客索引如下： SpringCloud 入门笔记（二）Eureka服务注册中心 SpringCloud 入门笔记（三）Feign声明式HTTP调用 SpringCloud 入门笔记（四）Ribbon客户端负载均衡器 SpringCloud 入门笔记（五）Hystrix断路器 SpringCloud 入门笔记（六）Zuul服务网关 SpringCloud 入门笔记（七）Config配置中心 开发环境： 工具 版本 IntelliJ IDEA 2017.2.5 SpringBoot 2.1.3.RELEASE SpringCloud Greenwich.SR1 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 入门笔记（三）Feign声明式HTTP调用]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%2FSpringCloud%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89Feign%E5%A3%B0%E6%98%8E%E5%BC%8FHTTP%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概述在SpringCloud中，每个微服务即是服务提供者也是服务消费者，各个微服务之间经常需要互相调用。通常，服务会向外部提供一些REST接口，供外部服务调用，Feign就是提供服务间声明式HTTP调用的组件。通过Feign，我们可以使用SpringMVC注解创建访问其他服务接口的HTTP客户端。 本篇以前面构建的 user-ms 和 role-ms 微服务为例，配置Feign组件。 配置Feign组件在pom.xml中添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 在启动类添加@EnableFeignClients注解，如下： 12345678@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class UserMsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserMsApplication.class, args); &#125;&#125; 在user-ms中创建一个FeignClient接口，作为Feign客户端，通过SpringMVC注解访问role-ms微服务，如下所示： 12345678910@FeignClient(name = "role-ms")public interface RoleFeignClient &#123; @RequestMapping(value = &#123;"/role/list"&#125;, method = RequestMethod.GET) Object list(); @RequestMapping(value = "/role/insert", method = RequestMethod.POST) String insert(@RequestBody Role role); &#125; 在UserController中定义访问role-ms的接口，如下： 12345678910111213141516171819202122232425262728293031323334@RestController@RequestMapping(value = "/user")public class UserController &#123; @Autowired private UserService userService; @Autowired private RoleFeignClient roleFeignClient; @RequestMapping(value = &#123;"/list", ""&#125;, method = RequestMethod.GET) public Object list() &#123; List&lt;User&gt; users = userService.findAllList(); return users; &#125; /** * 访问role-ms微服务，获取角色列表 * @return 角色列表 */ @RequestMapping(value = &#123;"/role/list"&#125;, method = RequestMethod.GET) public Object roleList() &#123; return roleFeignClient.list(); &#125; /** * 访问role-ms微服务，保存角色数据 * @param role 待保存的角色数据 * @return 数据保存结果 */ @RequestMapping(value = &#123;"/role/insert"&#125;, method = RequestMethod.POST) public Object roleInsert(@RequestBody Role role) &#123; return roleFeignClient.insert(role); &#125; &#125; 测试通过postman测试服务，结果如下： 源码地址：https://github.com/GreedyStar/yogurt 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【八】SpringMVC（二）HandlerMapping]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E5%85%AB%E3%80%91SpringMVC%EF%BC%88%E4%BA%8C%EF%BC%89HandlerMapping%2F</url>
    <content type="text"><![CDATA[前言在前一篇中我们分析了DispatcherServlet的实现，在处理客户请求的doDispatch方法中提到了HandlerMapping，这是SpringMVC中请求控制的重要组件，用于将URL映射到Controller中。 首先，回忆一下平时使用的SpringMVC配置文件，通常会包括如下配置： 12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd "&gt; &lt;!-- 静态资源访问 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 启动注解 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 把标记了@Controller注解的类注册到IOC容器中 --&gt; &lt;context:component-scan base-package="com.greedystar.controller"&gt; &lt;/context:component-scan&gt; &lt;!-- ViewResolver Servlet、JSP视图解析--&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="prefix" value="/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!-- 登录状态验证拦截器 --&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/search"/&gt; &lt;bean class="com.greedystar.interceptor.LoadInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt;&lt;/beans&gt; 参考上一篇 Spring源码学习【八】SpringMVC之DispatcherServlet （一）初始化阶段 -&gt; init() ，我们能够知道如下与HandlerMapping相关的内容： DispatcherServlet初始化时会创建一个IOC容器，并将配置文件中配置的Bean注册到IOC容器中。 DispatcherServlet初始化时会初始化一系列Servlet需要的策略，如：initHandlerMappings、initHandlerAdapters 等。 DispatcherServlet处理客户请求时会通过HandlerMapping取得HandlerExecutionChain。 下面，让我们顺着这个思路看一看HandlerMapping的实现。 源码学习注册BeanDispatcherServlet初始化过程中会创建一个IOC容器，作为Spring 根IOC容器的子容器，并将配置文件中配置的Bean注册到容器中，代码可参考 Spring源码学习【八】SpringMVC之DispatcherServlet （一）初始化阶段 -&gt; init() 熟悉SpringMVC的同学对上面的配置文件肯定很熟悉，但有两点需要特别注意： 1.&lt;mvc:default-servlet-handler/&gt;会自动注册用于静态资源访问的Bean，如下： 1&lt;bean class="org.springframework.web.servlet.resource.DefaultServletHttpRequestHandler"&gt;&lt;/bean&gt; 2.&lt;mvc:annotation-driven/&gt;会自动注册多个Bean，这些Bean是在使用SpringMVC注解（如@RequestMapping）时必须要的Bean（低版本的一些类已经在高版本中移除了，这里注册的是用于替代低版本过时类的Bean）： 12345&lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping"&gt;&lt;/bean&gt; &lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter​​​​​​​"&gt;&lt;/bean&gt; &lt;bean class="org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver​​​​​​​"&gt;&lt;/bean&gt; 这里只列举了一部分，关于这部分大家可以参考&lt;mvc:annotation-driven/&gt;标签的解析器的实现，即： 1org.springframework.web.servlet.config.AnnotationDrivenBeanDefinitionParser 初始化策略回到DispatcherServlet中看一下策略初始化的实现，代码如下： 1234567891011121314151617181920212223242526272829303132public class DispatcherServlet extends FrameworkServlet &#123; private void initHandlerMappings(ApplicationContext context) &#123; this.handlerMappings = null; if (this.detectAllHandlerMappings) &#123; // 从所有IOC容器中获取HandlerMapping，包括父容器 Map&lt;String, HandlerMapping&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerMappings = new ArrayList&lt;&gt;(matchingBeans.values()); // 将HandlerMappings排序，如上述中的RequestMappingHandlerMapping排在0位 AnnotationAwareOrderComparator.sort(this.handlerMappings); &#125; &#125; else &#123; // 从当前容器中获取HandlerMappings try &#123; HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class); this.handlerMappings = Collections.singletonList(hm); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we'll add a default HandlerMapping later. &#125; &#125; // 未找到配置的HandlerMapping，设置默认策略 if (this.handlerMappings == null) &#123; this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class); if (logger.isDebugEnabled()) &#123; logger.debug("No HandlerMappings found in servlet '" + getServletName() + "': using default"); &#125; &#125; &#125; &#125; 上面的代码中，从IOC容器中获取了配置的HandlerMapping Bean，由DispatcherServlet持有，并在未配置策略时使用默认策略，其余如HandlerAdapter的初始化过程大体一样就不在贴代码了。 到了这里我们发现DispatcherServlet已经持有了HandlerMapping，下一步就是在处理客户请求时调用了。 处理客户请求回到DispatcherServlet中的doDispatch方法中，有如下代码： 1mappedHandler = getHandler(processedRequest); 这句代码通过HandlerMapping获取请求匹配的处理器：一个HandlerExecutionChain类的实例，这个处理器中包含一个请求处理器和多个拦截器，下面来看一看这个过程： 1234567891011121314151617181920public class DispatcherServlet extends FrameworkServlet &#123; @Nullable protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; if (this.handlerMappings != null) &#123; // 遍历所有HandlerMappings for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Testing handler map [" + hm + "] in DispatcherServlet with name '" + getServletName() + "'"); &#125; // 取得一个处理器执行链 HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; &#125; return null; &#125;&#125; 上面的代码比较简单，就是遍历DispatcherServlet中的所有HandlerMapping，取得一个处理器后直接返回，我们需要重点关注一下这里是如何根据请求获取到匹配的处理器的： HandlerMapping是一个接口，其中定义了getHandler方法，用于取得一个处理器，下面我们直接看一看这个方法的具体实现，在AbstractHandlerMapping中，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public abstract class AbstractHandlerMapping extends WebApplicationObjectSupport implements HandlerMapping, Ordered &#123; @Override @Nullable public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 尝试从http request中取得处理器，这里是一个模板方法，交由子类实现 // 如AbstractUrlHandlerMapping中根据request的路径获取处理器 Object handler = getHandlerInternal(request); if (handler == null) &#123; // 使用默认处理器 handler = getDefaultHandler(); &#125; if (handler == null) &#123; return null; &#125; // 取得的是一个Bean name if (handler instanceof String) &#123; String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); &#125; // 取得HandlerExecutionChain对象 HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.globalCorsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain; &#125; protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler)); // 取得request路径 String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); // 添加拦截器 for (HandlerInterceptor interceptor : this.adaptedInterceptors) &#123; if (interceptor instanceof MappedInterceptor) &#123; MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor; if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; else &#123; chain.addInterceptor(interceptor); &#125; &#125; return chain; &#125; &#125; 到这里，就获取了一个匹配的处理器，接下来DispatcherServlet就可以通过这个处理器进行客户请求的处理了，客户请求的具体处理过程已经在上一篇中分析过了这里就不多赘述了。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>SpringMVC</tag>
        <tag>HandlerMapping</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【八】SpringMVC（一）DispatcherServlet]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E5%85%AB%E3%80%91SpringMVC%EF%BC%88%E4%B8%80%EF%BC%89DispatcherServlet%2F</url>
    <content type="text"><![CDATA[前言Web环境是Spring框架的重要应用场景，而SpringMVC又是Web开发中一个常用的框架，因此我们有必要学习一下SpringMVC的实现原理。 回到Web项目的配置文件web.xml中，在使用SpringMVC时我们需要进行如下的配置： 12345678910111213&lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/springMVC.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 熟悉Spring的同学对以上的配置肯定不陌生，这里配置了一个DispatcherServlet，这个Servlet是由Spring实现的，是SpringMVC最核心的部分，如上配置的这个Servlet会接收所有的请求，最终将请求分发至对应的Controller进行处理，下面我们就从DsipatcherServlet入手，学习SpringMVC的实现。 源码学习首先，来看一看DsipatcherServlet的类继承关系（省略了部分接口）： 从上图中可以看到，DispatcherServlet间接继承了HttpServlet，可用于处理Http请求。 既然DispatcherServlet也是Servlet家族中的一员，那么它肯定要遵循Servlet的生命周期，即： 初始化阶段，调用init()方法 响应客户请求阶段，调用service()方法 销毁阶段，调用destroy()方法 有了这些了解，我们就可以顺着DispatcherServlet的生命周期来学习SpringMVC的实现了。 初始化阶段 -&gt; init()首先，定位到初始化阶段，在这个阶段会调用init()方法，这个方法定义在Serlvet接口中，我们可以发现这个方法的最终实现在DispatcherServlet的父类HttpServletBean中，这个方法被定义为final方法，不可被子类覆盖，代码如下： 1234567891011121314151617181920212223242526272829303132public abstract class HttpServletBean extends HttpServlet implements EnvironmentCapable, EnvironmentAware &#123; @Override public final void init() throws ServletException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Initializing servlet '" + getServletName() + "'"); &#125; // 获取配置的 init parameters，设置Bean的属性 PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; if (logger.isErrorEnabled()) &#123; logger.error("Failed to set bean properties on servlet '" + getServletName() + "'", ex); &#125; throw ex; &#125; &#125; // 这个方法是一个模板方法，默认实现为空，交由其子类FrameworkServlet实现 initServletBean(); if (logger.isDebugEnabled()) &#123; logger.debug("Servlet '" + getServletName() + "' configured successfully"); &#125; &#125; &#125; 在上面的代码中，首先获取了init parameters，也就是web.xml中的节点，并将init parameters设置为这个Servlet Bean的属性，然后调用了子类FrameworkServlet的initServletBean()方法，进行额外的初始化处理，FrameworkServlet代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; @Override protected final void initServletBean() throws ServletException &#123; getServletContext().log("Initializing Spring FrameworkServlet '" + getServletName() + "'"); if (this.logger.isInfoEnabled()) &#123; this.logger.info("FrameworkServlet '" + getServletName() + "': initialization started"); &#125; long startTime = System.currentTimeMillis(); try &#123; // 初始化应用上下文 this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException | RuntimeException ex) &#123; this.logger.error("Context initialization failed", ex); throw ex; &#125; if (this.logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info("FrameworkServlet '" + getServletName() + "': initialization completed in " + elapsedTime + " ms"); &#125; &#125; protected WebApplicationContext initWebApplicationContext() &#123; // 首先从ServletContext中取得根应用上下文，也就是上一篇中在ContextLoader中创建的IOC容器 WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // 若在构造Servlet时已经注入应用上下文，则直接使用 wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; if (cwac.getParent() == null) &#123; // 设置根应用上下文 cwac.setParent(rootContext); &#125; // 配置并刷新应用上下文 configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; // 构造Servlet时未注入应用上下文，则到ServletContext中获取 wac = findWebApplicationContext(); &#125; if (wac == null) &#123; // ServletContext中未获取到，则创建一个应用上下文 // 这里创建应用上下文的处理与上一篇中的处理类似，不同之处在于创建完成后即进行了应用上下文的配置和刷新 wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; // 触发初始化刷新，这里指的不是应用上下文的刷新 // 这个方法是一个模板方法，默认实现为空，交由子类DisispatcherServlet实现 onRefresh(wac); &#125; if (this.publishContext) &#123; // 将当前的应用上下文发布到ServletContext中，key为：FrameworkServlet.class.getName() + ".CONTEXT." + servletName String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Published WebApplicationContext of servlet '" + getServletName() + "' as ServletContext attribute with name [" + attrName + "]"); &#125; &#125; return wac; &#125; &#125; 上面的代码中，取得了一个应用上下文，作为了根IOC容器的子容器，这样，DispatcherServlet中的IOC容器就建立起来了，细心的同学会发现，在返回应用上下文之前调用了onRefresh(wac)方法，这个方法由其子类DispatcherServlet实现，用于初始化Web层需要的策略，下面让我们一起来看一看这部分的源码： 1234567891011121314151617181920public class DispatcherServlet extends FrameworkServlet &#123; @Override protected void onRefresh(ApplicationContext context) &#123; initStrategies(context); &#125; protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); initHandlerMappings(context); initHandlerAdapters(context); initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context); &#125; &#125; 从上面的代码中可以看到，在获取应用上下文的过程中初始化了DispatcherServlet中需要的各种解析器，其中包括文件解析器、区域解析器、主题解析器等。 解析器的初始化过程大体相同，都是从应用上下文中取得相应的Bean，若不存在则使用默认解析器策略。 具体关于各解析器的介绍大家可以参考一篇博客：SpringMVC解析器 到这里，DispatcherServlet的初始化阶段就完成了，在这个过程中，一方面创建了DispatcherServlet的IOC容器，并将这个IOC容器作为根IOC容器的子容器，另一方面，初始化了DispatcherServlet需要的各种解析策略，接下来，DispatcherServlet将会在处理HTTP请求时发挥重要的作用。 响应客户请求 -&gt; service()我们知道Servlet在接收到客户请求后会调用service()方法，根据请求类型执行doGet、doPost等一系列方法，在DispatcherServlet的继承体系中，由DispatcherServlet的父类FrameworkServlet重写了HttpServlet中的service()方法以及doGet()、doPost() 等一系列方法，下面以常用的HTTP请求方法来看一看FrameworkServlet的主要实现代码： 123456789101112131415161718192021222324252627282930313233343536public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; @Override protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; HttpMethod httpMethod = HttpMethod.resolve(request.getMethod()); // 这里添加了对patch请求的支持 if (httpMethod == HttpMethod.PATCH || httpMethod == null) &#123; processRequest(request, response); &#125; else &#123; // 这里调用HttpServlet的service方法，根据请求类型调用该类中重写的doGet、doPost等方法 super.service(request, response); &#125; &#125; @Override protected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response); &#125; @Override protected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response); &#125; @Override protected final void doPut(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response); &#125; @Override protected final void doDelete(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response); &#125; &#125; 从上面的代码中可以看到， DispatcherServlet接收到用户请求后，会调用父类FrameworkServlet中的service()方法，最终根据请求类型调用FrameworkServlet中重写的doGet、doPost等方法，这些方法都调用了processRequest()方法，下面让我们看一下processRequest()的具体实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; long startTime = System.currentTimeMillis(); Throwable failureCause = null; // 获取LocaleContext(语言环境), 用作备份 LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); // 根据当前request创建LocaleContext LocaleContext localeContext = buildLocaleContext(request); // 获取RequestAttributes，用作备份 RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); // 根据当前request、response创建ServletRequestAttributes ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); // 为当前请求注册一个拦截器，用于在请求执行前后异步初始化和重置FrameworkServlet的LocaleContextHolder和RequestContextHolder WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor()); // 根据当前request初始化ContextHolders initContextHolders(request, localeContext, requestAttributes); try &#123; // 具体处理请求，是一个模板方法，由子类DispatcherServlet实现 doService(request, response); &#125; catch (ServletException | IOException ex) &#123; failureCause = ex; throw ex; &#125; catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException("Request processing failed", ex); &#125; finally &#123; // 使用备份重置ContextHolders resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) &#123; requestAttributes.requestCompleted(); &#125; if (logger.isDebugEnabled()) &#123; if (failureCause != null) &#123; this.logger.debug("Could not complete request", failureCause); &#125; else &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; logger.debug("Leaving response open for concurrent processing"); &#125; else &#123; this.logger.debug("Successfully completed request"); &#125; &#125; &#125; // 向该应用注册的所有监听器发布RequestHandledEvent事件 // 监听器可以通过实现ApplicationListener接口来实现 publishRequestHandledEvent(request, response, startTime, failureCause); &#125; &#125; &#125; 在上面的代码中我们可以看到一个用于处理请求的核心方法：doService(request, response)，这个方法是一个模板方法，由其子类DispatcherServlet实现，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class DispatcherServlet extends FrameworkServlet &#123; @Override protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (logger.isDebugEnabled()) &#123; String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? " resumed" : ""; logger.debug("DispatcherServlet with name '" + getServletName() + "'" + resumed + " processing " + request.getMethod() + " request for [" + getRequestUri(request) + "]"); &#125; // 对于include请求，首先保存request属性快照，用于请求后恢复属性 Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // 为request设置一些必要的属性 request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); // 应用上下文 request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); // 语言环境解析器 request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); // 主题解析器 request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); // 主题源，默认将应用上下文作为主题源 if (this.flashMapManager != null) &#123; FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); &#125; try &#123; // 分发请求 doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; // 恢复include请求属性 restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125; &#125; &#125; doService方法比较简单，主要是为request设置一些必要的属性，接下来调用了doDispatch方法进行请求的分发，这是SpringMVC中的核心功能，doDispatch方法中主要进行了如下的处理： 处理拦截 处理请求 解析View 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class DispatcherServlet extends FrameworkServlet &#123; protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // 判断是否为文件上传请求，这里会尝试将request转换为文件上传请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 通过HandlerMapping获取请求匹配的处理器：一个HandlerExecutionChain类的实例 // 这个处理器中包含一个请求处理器和多个拦截器 mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; // 未找到匹配的处理器，返回404错误 noHandlerFound(processedRequest, response); return; &#125; // 根据匹配的请求处理器获取支持该处理器的适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug("Last-Modified value for [" + getRequestUri(request) + "] is: " + lastModified); &#125; // 对于get请求，如果从上次修改后未进行修改则不再对请求进行处理 if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // 执行拦截器 -&gt; preHandle if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 执行处理器处理请求，返回ModelAndView对象 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; // 若ModelAndView无视图名，则为其设置默认视图名 applyDefaultViewName(processedRequest, mv); // 执行拦截器 -&gt; postHandle mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; dispatchException = new NestedServletException("Handler dispatch failed", err); &#125; // 处理异常，解析View processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; // 触发拦截器的afterCompletion方法 triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; // 触发拦截器的afterCompletion方法 triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException("Handler processing failed", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // 清除文件上传请求使用的资源 if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; &#125; &#125; 到这里，客户的请求就相应完成了。在这个过程中，首先处理匹配的处理器中的拦截器，然后通过处理器处理客户的请求，最后通过视图解析器解析和渲染视图，这里还有许多细节未深入分析，我们将在后续继续学习。 销毁阶段 -&gt; destroy()Servlet的销毁阶段会调用destroy()方法，这个方法的实现在FrameworkServlet中，实现比较简单，就是将Servlet中的IOC容器关闭，代码如下： 1234567891011public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; @Override public void destroy() &#123; getServletContext().log("Destroying Spring FrameworkServlet '" + getServletName() + "'"); // Only call close() on WebApplicationContext if locally managed... if (this.webApplicationContext instanceof ConfigurableApplicationContext &amp;&amp; !this.webApplicationContextInjected) &#123; ((ConfigurableApplicationContext) this.webApplicationContext).close(); &#125; &#125;&#125; 总结本篇中，顺着Servlet的生命周期大致分析了SpringMVC的核心类DispatcherServlet的实现，对SpringMVC的请求控制有了一定的了解，但在DispatcherServlet处理客户请求的部分有许多内容未深入分析，需要进一步学习。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>SpringMVC</tag>
        <tag>DispatcherServlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【七】Web环境中启动和关闭IOC容器]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%B8%83%E3%80%91Web%E7%8E%AF%E5%A2%83%E4%B8%AD%E5%90%AF%E5%8A%A8%E5%92%8C%E5%85%B3%E9%97%ADIOC%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言前面的几章中学习了Spring IOC容器和AOP的实现，对这两个核心功能有了一定了解后，让我们一起学习一下IOC容器在常用的Web环境中是如何使用的，这也是Spring框架在Web环境中的重要应用场景。 回忆一下在Web项目中配置Spring的过程，首先，我们需要在web.xml中进行如下配置： 123456789&lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt;&lt;/listener&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/spring.xml&lt;/param-value&gt;&lt;/context-param&gt; 这里的ContextLoaderListener就是在Web应用中启动IOC容器的入口，下面从源码的角度看一看ContextLoaderListener的实现。 源码学习首先，看一下ContextLoaderListener的类继承关系，如下： 从图中可以看到，ContextLoaderListener实现了ServletContextListener接口，这个接口是Servlet API提供的用于监听Web应用生命周期的接口。这个接口中定义了Web应用启动和销毁的回调方法，代码如下： 123456789101112public interface ServletContextListener extends EventListener &#123; /* * Web应用启动后调用该方法 */ void contextInitialized(ServletContextEvent event); /* * Web应用销毁后调用该方法 */ void contextDestroyed(ServletContextEvent event);&#125; 可以看到ServletContextListener接口中定义了两个方法，分别在Web应用启动和销毁后调用，这样就可以通过这个接口来实现对Web应用生命周期的监听了。 ContextLoaderListener实现了ServletContextListener接口，代码如下： 123456789101112131415161718192021222324252627public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public ContextLoaderListener() &#123; &#125; public ContextLoaderListener(WebApplicationContext context) &#123; super(context); &#125; /** * 初始化根应用上下文 */ @Override public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext()); &#125; /** * 关闭根应用上下文 */ @Override public void contextDestroyed(ServletContextEvent event) &#123; closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125; &#125; ContextLoaderListener中的代码比较简单，主要就是在Web应用启动和销毁时对IOC容器进行相应的处理，处理方法定义在其父类ContextLoader中。 首先，在Web应用启动后，创建和初始化应用上下文，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ContextLoader &#123; /* * 初始化根应用上下文 */ public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; // 在servletContext中查找是否已经存在根应用上下文 if(servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException("Cannot initialize context because there is already a root application context present - " + "check whether you have multiple ContextLoader* definitions in your web.xml!"); &#125; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log("Initializing Spring root WebApplicationContext"); if (logger.isInfoEnabled()) &#123; logger.info("Root WebApplicationContext: initialization started"); &#125; long startTime = System.currentTimeMillis(); try &#123; if (this.context == null) &#123; // 创建一个应用上下文 this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; // 应用上下文（IOC容器）还未被刷新,refresh是IOC容器初始化的入口 if (!cwac.isActive()) &#123; if (cwac.getParent() == null) &#123; // 加载父容器，这里的loadParentContext是一个模板方法，默认返回null // 目的是留给子类实现 ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; // 配置并刷新应用上下文 // 这里会找到web.xml中配置的contextConfigLocation属性，作为应用上下文的配置路径 // 最后会调用ApplicationContext的refresh()方法初始化应用上下文 configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; // 将当前的应用上下文缓存在servletContext中 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Published root WebApplicationContext as ServletContext attribute with name [" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + "]"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info("Root WebApplicationContext: initialization completed in " + elapsedTime + " ms"); &#125; // 返回应用上下文 return this.context; &#125; catch (RuntimeException ex) &#123; logger.error("Context initialization failed", ex); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; logger.error("Context initialization failed", err); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125; &#125; &#125; 经过以上代码的处理，就在Web应用环境中创建了一个根应用上下文，调用了refresh()方法对应用上下文进行了初始化，并将该应用上下文缓存在ServletContext中。 其次，在Web应用销毁后，关闭应用上下文，销毁ServletContext中的Spring框架属性，代码如下： 123456789101112131415161718192021222324252627public class ContextLoader &#123; /* * 关闭应用上下文 */ public void closeWebApplicationContext(ServletContext servletContext) &#123; servletContext.log("Closing Spring root WebApplicationContext"); try &#123; if (this.context instanceof ConfigurableWebApplicationContext) &#123; // 关闭IOC容器 ((ConfigurableWebApplicationContext) this.context).close(); &#125; &#125; finally &#123; ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = null; &#125; else if (ccl != null) &#123; currentContextPerThread.remove(ccl); &#125; // 移除缓存 servletContext.removeAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE); &#125; &#125; &#125; 1234567891011121314151617181920212223public class ContextCleanupListener implements ServletContextListener &#123; static void cleanupAttributes(ServletContext sc) &#123; // 获取ServletContext中的属性名集 Enumeration&lt;String&gt; attrNames = sc.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = attrNames.nextElement(); if (attrName.startsWith("org.springframework.")) &#123; Object attrValue = sc.getAttribute(attrName); // 销毁相应的Bean if (attrValue instanceof DisposableBean) &#123; try &#123; ((DisposableBean) attrValue).destroy(); &#125; catch (Throwable ex) &#123; logger.error("Couldn't invoke destroy method of attribute with name '" + attrName + "'", ex); &#125; &#125; &#125; &#125; &#125; &#125; 到这里，我们对IOC容器在Web环境中的启动和关闭就有了一定的了解了，这个过程虽然不复杂，但是需要依托对IOC容器初始化过程的了解，也就是refresh()触发的IOC容器初始化过程。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【六】AOP原理解析（二）拦截器链]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E5%85%AD%E3%80%91AOP%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89%E6%8B%A6%E6%88%AA%E5%99%A8%E9%93%BE%2F</url>
    <content type="text"><![CDATA[前言通过上一篇 Spring源码学习【六】AOP原理解析（一）代理对象的生成 的学习，我们知道了Spring是通过后置处理器来生成代理对象的，且获取到代理对象后会阻止原Bean的默认实例化行为，从而将代理对象提供给用户使用，并通过代理对象实现对目标对象的增强，有了这些知识储备，我们继续以JdkDynamicAopProxy为例，学习一下代理对象是如何对目标对象进行增强的。 源码学习回到上一篇JdkDynamicAopProxy类中，我们可以发现JdkDynamicAopProxy类实现了InvocationHandler接口，在利用Java反射机制创建代理对象的同时将传入了this对象引用，代码如下： 123456789final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; @Override public Object getProxy(@Nullable ClassLoader classLoader) &#123; ... return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &#125; &#125; 这里的InvocationHandler接口是代理对象需要实现的接口，其中定义了Invoke方法，用于以回调的方式拦截目标对象方法的调用，我们可以以JdkDynamicAopProxy为例学习invoke的实现，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; @Override @Nullable public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // 目标对象未实现equals方法 return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // 目标对象未实现hashCode方法 return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // 装饰模式代理 return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // 获取目标对象 target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 获取要执行的方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); // 拦截器链空，则直接执行目标对象方法 retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // 调用拦截器 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); retVal = invocation.proceed(); &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException("Null return value from advice does not match primitive return type for: " + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; &#125; 上面的代码中我们需要关注两个方面：其一，目标对象targer的方法调用；其二，拦截器的调用。 首先，看一看目标对象方法的调用，使用了Java的反射机制，具体实现在AopUtils类中，代码如下： 123456789101112131415161718192021public abstract class AopUtils &#123; @Nullable public static Object invokeJoinpointUsingReflection(@Nullable Object target, Method method, Object[] args) throws Throwable &#123; // 通过反射调用方法 try &#123; ReflectionUtils.makeAccessible(method); return method.invoke(target, args); &#125; catch (InvocationTargetException ex) &#123; throw ex.getTargetException(); &#125; catch (IllegalArgumentException ex) &#123; throw new AopInvocationException("AOP configuration seems to be invalid: tried calling method [" + method + "] on target [" + target + "]", ex); &#125; catch (IllegalAccessException ex) &#123; throw new AopInvocationException("Could not access method [" + method + "]", ex); &#125; &#125; &#125; 然后，看一看拦截器的调用，具体实现在ReflectiveMethodInvocation类中，代码如下： 12345678910111213141516171819202122232425262728293031323334353637public class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable &#123; @Override @Nullable public Object proceed() throws Throwable &#123; // index由-1开始调用拦截器，当所有拦截器调用完毕后再调用目标对象的方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 从interceptorsAndDynamicMethodMatchers中获取一个对象 // 这个对象可能是一个匹配器或是一个拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // 取得匹配器则需要对目标方法进行匹配 InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; // 匹配成功，调用拦截器 return dm.interceptor.invoke(this); &#125; else &#123; // 匹配失败，跳过该拦截器，进行递归 return proceed(); &#125; &#125; else &#123; // 直接取得了一个拦截器，那么无需匹配直接调用 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; @Nullable protected Object invokeJoinpoint() throws Throwable &#123; // 调用目标对象的方法 return AopUtils.invokeJoinpointUsingReflection(this.target, this.method, this.arguments); &#125; &#125; 到这里，我们就大体了解了拦截器链和目标方法的调用过程，在我们调用代理对象的目标方法时，会回调到代理对象的invode方法中，在这个方法中调用拦截器链，最终调用目标方法。在这个过程中，我们发现最终调用的拦截器链是由ReflectiveMethodInvocation持有的，拦截器链在构造方法中进行了初始化，如下所示： 1234567891011121314151617181920protected final List&lt;?&gt; interceptorsAndDynamicMethodMatchers; /** * @param proxy 代理对象 * @param target 目标对象 * @param method 目标方法 * @param arguments 目标方法参数 * @param targetClass 目标类 * @param interceptorsAndDynamicMethodMatchers 拦截器链 */protected ReflectiveMethodInvocation(Object proxy, @Nullable Object target, Method method, @Nullable Object[] arguments, @Nullable Class&lt;?&gt; targetClass, List&lt;Object&gt; interceptorsAndDynamicMethodMatchers) &#123; this.proxy = proxy; this.target = target; this.targetClass = targetClass; this.method = BridgeMethodResolver.findBridgedMethod(method); this.arguments = AopProxyUtils.adaptArgumentsIfNecessary(method, arguments); this.interceptorsAndDynamicMethodMatchers = interceptorsAndDynamicMethodMatchers;&#125; 经过上一篇的分析，我们知道ReflectiveMethodInvocation是在JdkDynamicAopProxy的invoke方法中构造的，在构造ReflectiveMethodInvocation对象前，先获取了目标方法的拦截器链，代码如下： 12List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); 上面的这句代码十分重要，现在我们知道Spring是通过生成代理类来实现对目标对象的增强的，在执行目标对象的目标方法前，会首先执行代理对象中配置的一系列拦截器，这里便是获取了所有拦截器，接下来看一看具体的代码： 1234567891011121314151617public class AdvisedSupport extends ProxyConfig implements Advised &#123; /** * 获取拦截器链，可以看到这里使用了缓存，最终拦截器链的获取由AdvisorChainFactory接口的实现类 * DefaultAdvisorChainFactory实现 */ public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object&gt; cached = this.methodCache.get(cacheKey); if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice(this, method, targetClass); this.methodCache.put(cacheKey, cached); &#125; return cached; &#125; &#125; DefaultAdvisorChainFactory用于为目标方法创建拦截器链，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class DefaultAdvisorChainFactory implements AdvisorChainFactory, Serializable &#123; /** * 创建拦截器链 * */ @Override public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; // 这里的config实际上之前创建的ProxyFactory，ProxyFactory间接实现了Advised接口 List&lt;Object&gt; interceptorList = new ArrayList&lt;&gt;(config.getAdvisors().length); Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); // 取得一个registry，这里使用了单例模式，用于注册通知适配器 AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); for (Advisor advisor : config.getAdvisors()) &#123; // 处理切入点通知，方法级别增强 if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; // 通过registry取得拦截器 MethodInterceptor[] interceptors = registry.getInterceptors(advisor); MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &#123; if (mm.isRuntime()) &#123; for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; // 处理引介通知，类级别增强 else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; // 通过registry取得拦截器 Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; // 通过registry取得拦截器 Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125;&#125; 上面的代码中最终返回了一个方法拦截器的列表，在这个过程中，多次调用了AdvisorAdapterRegistry的getInterceptors(advisor)方法，下面深入到AdvisorAdapterRegistry接口的实现类DefaultAdvisorAdapterRegistry中看一看具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry, Serializable &#123; private final List&lt;AdvisorAdapter&gt; adapters = new ArrayList&lt;&gt;(3); public DefaultAdvisorAdapterRegistry() &#123; registerAdvisorAdapter(new MethodBeforeAdviceAdapter()); registerAdvisorAdapter(new AfterReturningAdviceAdapter()); registerAdvisorAdapter(new ThrowsAdviceAdapter()); &#125; @Override public Advisor wrap(Object adviceObject) throws UnknownAdviceTypeException &#123; if (adviceObject instanceof Advisor) &#123; return (Advisor) adviceObject; &#125; if (!(adviceObject instanceof Advice)) &#123; throw new UnknownAdviceTypeException(adviceObject); &#125; Advice advice = (Advice) adviceObject; if (advice instanceof MethodInterceptor) &#123; return new DefaultPointcutAdvisor(advice); &#125; for (AdvisorAdapter adapter : this.adapters) &#123; if (adapter.supportsAdvice(advice)) &#123; return new DefaultPointcutAdvisor(advice); &#125; &#125; throw new UnknownAdviceTypeException(advice); &#125; /** * 获取拦截器 */ @Override public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList&lt;&gt;(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor) advice); &#125; for (AdvisorAdapter adapter : this.adapters) &#123; // 判断通知是否可被适配器理解 // 实际上是对advice类型的判断，如AfterReturningAdvice等 if (adapter.supportsAdvice(advice)) &#123; interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; return interceptors.toArray(new MethodInterceptor[0]); &#125; /** * 注册通知适配器 */ @Override public void registerAdvisorAdapter(AdvisorAdapter adapter) &#123; this.adapters.add(adapter); &#125; &#125; 到这里，拦截器链就构造完成了，在这个过程中，通过适配器的支持，构造了不同的拦截器，在JdkDynamicAopProxy进行回调时则会根据配置的通知执行相应的拦截器链，从而达到增强目标对象的功能。 Spring的AOP模块是一个复杂的模块，这里仅仅简要分析了通过代理对象增强目标对象的原理和过程，还有更多的知识需要在实践中不断学习。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【六】AOP原理解析（一）代理对象的生成]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E5%85%AD%E3%80%91AOP%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[前言AOP（Aspect Oriented Programming 面向切面编程）是Spring框架的核心功能之一，关于AOP中一些概念的理解可以参考 SpringAOP概念及其使用 ，下面以一个简单的例子作为Spring AOP源码学习的起点。 首先，定义一个切面类CustomAspect，如下所示： 1234567891011public class CustomAspect &#123; public void before() &#123; System.out.println("Before custom operation"); &#125; public void after() &#123; System.out.println("After custom operation"); &#125; &#125; 然后，在配置文件中定义Bean、切面、切入点、通知等，如下所示： 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd"&gt; &lt;bean id="a" class="greedystar.entity.A" lazy-init="true"&gt; &lt;property name="name" value="Alvin"/&gt; &lt;property name="id" value="123"/&gt; &lt;property name="roles"&gt; &lt;list&gt; &lt;value&gt;USER&lt;/value&gt; &lt;value&gt;ADMIN&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 定义切面bean --&gt; &lt;bean id="aspect" class="greedystar.entity.CustomAspect"/&gt; &lt;aop:config proxy-target-class="true"&gt; &lt;!-- 引入切面 --&gt; &lt;aop:aspect id="aspect" ref="aspect"&gt; &lt;!-- 定义切点 --&gt; &lt;aop:pointcut id="say" expression="execution(* greedystar.entity.A.say(..))"/&gt; &lt;!-- 定义通知 --&gt; &lt;aop:before method="before" pointcut-ref="say"/&gt; &lt;aop:after method="after" pointcut-ref="say"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; &lt;/beans&gt; 最后，通过如下代码获取到IOC容器中名为 a 的Bean： 123ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext("beans.xml");A a = (A) applicationContext.getBean("a");a.say(); 运行结果如下： 123Before custom operation123 Alvin [USER, ADMIN]After custom operation 从上面的例子中可以看到，say方法在执行前后分别执行了CustomAspect中的before和after方法，于是我们就需要思考一个问题：Spring是在什么地方对Bean进行了改造的？ 经过上一章的分析，我们知道getBean方法作为调用起点，完成了Bean的创建和依赖注入，构造了一个完整的Bean返回给用户使用，那么AOP对Bean的改造应当是在依赖注入之后，返回给用户之前，下面带着这个疑问，回到源码中继续学习。 源码分析在AbstractAutowireCapableBeanFactory类的doCreateBean方法中，我们可以发现如下代码： 123456789101112131415161718192021222324252627282930public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; /** * 真正开始创建Bean */ protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; ...... // 初始化bean Object exposedObject = bean; try &#123; // 这里开始进行依赖注入 populateBean(beanName, mbd, instanceWrapper); // 初始化bean，执行Initialization BeanPostProcessor exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; ...... // 返回Bean实例，这里已经完成了依赖注入 return exposedObject; &#125;&#125; 在这里，我们发现在依赖注入之后，返回给用户之前，调用了initializeBean方法，下面一起看看这个方法的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 在初始化前调用Initialization后置处理器before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 调用Bean配置的init-method invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, "Invocation of init method failed", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // 在初始化后调用Initialization后置处理器after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean; &#125; /** * 调用Initialization后置处理器postProcessBeforeInitialization方法 */ @Override public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; Object current = beanProcessor.postProcessBeforeInitialization(result, beanName); if (current == null) &#123; return result; &#125; result = current; &#125; return result; &#125; /** * 调用Initialization后置处理器postProcessAfterInitialization方法 */ @Override public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; Object current = beanProcessor.postProcessAfterInitialization(result, beanName); if (current == null) &#123; return result; &#125; result = current; &#125; return result; &#125; &#125; 在上面的代码中我们发现最终调用了BeanPostProcessor接口的相关方法，我们以接口的实现类AspectJAwareAdvisorAutoProxyCreator为例看看后置处理器的实现，首先来看一下AspectJAwareAdvisorAutoProxyCreator的类继承图（省略了部分接口）： 从图中可以看到AspectJAwareAdvisorAutoProxyCreator间接实现了BeanPostProcessor接口，接口方法的实现在其父类AbstractAutoProxyCreator中，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; ... /** * before初始化 */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) &#123; return bean; &#125; /** * after初始化 */ @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125; protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 处理不需要生成代理的情况 if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 获取通知数组 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; /** * 创建代理 */ protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; // 代理工厂，提供了非配置方式的编程式使用方式 ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); // proxyFactory.isProxyTargetClass() 默认为false if (!proxyFactory.isProxyTargetClass()) &#123; // 是否代理目标类，也就是对&lt;aop:config&gt;节点的proxy-target-class属性进行判断 // 为true时表示通过CGLIB进行代理 if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; // 为false时表示通过JDK进行代理，需要实现接口 else &#123; evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; // 创建通知数组 Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; // 创建并返回代理对象 // 根据配置或由Spring自动决定使用JDK或CGLIB方式生成代理对象 // 最终实现在DefaultAopProxyFactory类中 return proxyFactory.getProxy(getProxyClassLoader()); &#125; &#125; 这段代码返回了一个代理对象，从而阻止了Bean默认的实例化操作，代理对象的创建由ProxyFactory完成，下面让我们来看一看ProxyFactory的具体实现，代码如下： 12345678public class ProxyFactory extends ProxyCreatorSupport &#123; public Object getProxy(@Nullable ClassLoader classLoader) &#123; // 这里的createAopProxy()方法定义在父类ProxyCreatorSupport中 return createAopProxy().getProxy(classLoader); &#125; &#125; ProxyCreatorSupport代码如下： 1234567891011public class ProxyCreatorSupport extends AdvisedSupport &#123; protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; // 这里的getAopProxyFactory默认返回一个DefaultAopProxyFactory对象 return getAopProxyFactory().createAopProxy(this); &#125; &#125; DefaultAopProxyFactory代码如下： 12345678910111213141516171819202122public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; /** * 根据配置或由Spring自动优化决定使用JDK动态代理还是CGLIB生成代理对象 */ @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException("TargetSource cannot determine target class: " + "Either an interface or a target is required for proxy creation."); &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125; &#125;&#125; 从上面的代理中可以看到，最终调用了JdkDynamicAopProxy或ObjnesisCglibAopProxy的getProxy方法获得了一个代理对象，这里以JdkDynamicAopProxy为例看一看具体实现： 12345678910111213final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; @Override public Object getProxy(@Nullable ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating JDK dynamic proxy: target source is " + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &#125; &#125; 可以看到最终通过Java的反射机制创建了代理对象并返回给了用户，至此AOP代理对象的创建过程就完成了。 特别说明对BeanDefinition解析比较了解的同学可能记得解析工作是委托给BeanDefinitionParserDelegate完成的，在这个类的parseCustomElement方法中，会根据&lt;&gt;元素标签的命名空间取得相应的NamespaceHandler，并通过Handler的parse方法来解析元素，比如对于aop:config标签，则会使用AopNamespaceHandler进行解析。 在AopNamespaceHanlder中定义了一系列的BeanDefinitionParser，当解析aop:config时，会调用ConfigBeanDefinitionParser的parse方法，在这个方法中有如下代码： 12345configureAutoProxyCreator(parserContext, element); private void configureAutoProxyCreator(ParserContext parserContext, Element element) &#123; AopNamespaceUtils.registerAspectJAutoProxyCreatorIfNecessary(parserContext, element);&#125; 这部分代码表示Spring默认提供了一个AspectJ的代理生成器，这就是为什么上文中以AspectJAwareAdvisorAutoProxyCreator为例分析代理对象的生成过程。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【五】填坑篇之PropertyValue解析]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%BA%94%E3%80%91%E5%A1%AB%E5%9D%91%E7%AF%87%E4%B9%8BPropertyValue%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[经过上一篇文章 Spring源码学习【四】依赖注入过程 对Spring依赖注入过程的分析，我们知道了在注入Property时会创建一个深拷贝副本，将这个副本持有的Property注入到Bean中，在创建的过程中会使用BeanDefinitionValueResolver解析PropertyValue，代码如下： 12BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter);Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); 这里调用了BeanDefinitionValueResolver的resolveValueIfNecessary方法，在这个方法中，将BeanDefinition中定义的Property解析为真正的对象，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110class BeanDefinitionValueResolver &#123; ... @Nullable public Object resolveValueIfNecessary(Object argName, @Nullable Object value) &#123; // 解析Bean引用 if (value instanceof RuntimeBeanReference) &#123; RuntimeBeanReference ref = (RuntimeBeanReference) value; return resolveReference(argName, ref); &#125; // 解析Bean name引用 else if (value instanceof RuntimeBeanNameReference) &#123; String refName = ((RuntimeBeanNameReference) value).getBeanName(); refName = String.valueOf(doEvaluate(refName)); if (!this.beanFactory.containsBean(refName)) &#123; throw new BeanDefinitionStoreException("Invalid bean name '" + refName + "' in bean reference for " + argName); &#125; return refName; &#125; // 解析BeanDefinition，包含Bean name、aliases等 else if (value instanceof BeanDefinitionHolder) &#123; BeanDefinitionHolder bdHolder = (BeanDefinitionHolder) value; return resolveInnerBean(argName, bdHolder.getBeanName(), bdHolder.getBeanDefinition()); &#125; // 解析原始BeanDefinition else if (value instanceof BeanDefinition) &#123; BeanDefinition bd = (BeanDefinition) value; String innerBeanName = "(inner bean)" + BeanFactoryUtils.GENERATED_BEAN_NAME_SEPARATOR + ObjectUtils.getIdentityHexString(bd); return resolveInnerBean(argName, innerBeanName, bd); &#125; // 解析Array else if (value instanceof ManagedArray) &#123; ManagedArray array = (ManagedArray) value; Class&lt;?&gt; elementType = array.resolvedElementType; // 如果未指定列表元素类型，则通过元素类型名获取元素类型或认为是Object类型 if (elementType == null) &#123; String elementTypeName = array.getElementTypeName(); if (StringUtils.hasText(elementTypeName)) &#123; try &#123; elementType = ClassUtils.forName(elementTypeName, this.beanFactory.getBeanClassLoader()); array.resolvedElementType = elementType; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(this.beanDefinition.getResourceDescription(), this.beanName, "Error resolving array type for " + argName, ex); &#125; &#125; else &#123; elementType = Object.class; &#125; &#125; return resolveManagedArray(argName, (List&lt;?&gt;) value, elementType); &#125; // 解析List else if (value instanceof ManagedList) &#123; return resolveManagedList(argName, (List&lt;?&gt;) value); &#125; // 解析Set else if (value instanceof ManagedSet) &#123; // May need to resolve contained runtime references. return resolveManagedSet(argName, (Set&lt;?&gt;) value); &#125; // 解析Map else if (value instanceof ManagedMap) &#123; // May need to resolve contained runtime references. return resolveManagedMap(argName, (Map&lt;?, ?&gt;) value); &#125; // 解析Properties else if (value instanceof ManagedProperties) &#123; Properties original = (Properties) value; Properties copy = new Properties(); original.forEach((propKey, propValue) -&gt; &#123; if (propKey instanceof TypedStringValue) &#123; propKey = evaluate((TypedStringValue) propKey); &#125; if (propValue instanceof TypedStringValue) &#123; propValue = evaluate((TypedStringValue) propValue); &#125; if (propKey == null || propValue == null) &#123; throw new BeanCreationException(this.beanDefinition.getResourceDescription(), this.beanName, "Error converting Properties key/value pair for " + argName + ": resolved to null"); &#125; copy.put(propKey, propValue); &#125;); return copy; &#125; // 解析带有目标类型的字符串 else if (value instanceof TypedStringValue) &#123; TypedStringValue typedStringValue = (TypedStringValue) value; Object valueObject = evaluate(typedStringValue); try &#123; Class&lt;?&gt; resolvedTargetType = resolveTargetType(typedStringValue); if (resolvedTargetType != null) &#123; return this.typeConverter.convertIfNecessary(valueObject, resolvedTargetType); &#125; else &#123; return valueObject; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(this.beanDefinition.getResourceDescription(), this.beanName, "Error converting typed String value for " + argName, ex); &#125; &#125; else if (value instanceof NullBean) &#123; return null; &#125; else &#123; return evaluate(value); &#125; &#125;&#125; 从上面的代码中可以看到，最终会返回一个解析好的真实对象，我们仍然以集合类型Property看一下具体的解析方法，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class BeanDefinitionValueResolver &#123; ... /** * 解析ManagedArray，可能存在Bean引用的情况 */ private Object resolveManagedArray(Object argName, List&lt;?&gt; ml, Class&lt;?&gt; elementType) &#123; Object resolved = Array.newInstance(elementType, ml.size()); for (int i = 0; i &lt; ml.size(); i++) &#123; Array.set(resolved, i,resolveValueIfNecessary(new KeyedArgName(argName, i), ml.get(i))); &#125; return resolved; &#125; /** * 解析ManagedList */ private List&lt;?&gt; resolveManagedList(Object argName, List&lt;?&gt; ml) &#123; List&lt;Object&gt; resolved = new ArrayList&lt;&gt;(ml.size()); for (int i = 0; i &lt; ml.size(); i++) &#123; resolved.add(resolveValueIfNecessary(new KeyedArgName(argName, i), ml.get(i))); &#125; return resolved; &#125; /** * 解析ManagedSet */ private Set&lt;?&gt; resolveManagedSet(Object argName, Set&lt;?&gt; ms) &#123; Set&lt;Object&gt; resolved = new LinkedHashSet&lt;&gt;(ms.size()); int i = 0; for (Object m : ms) &#123; resolved.add(resolveValueIfNecessary(new KeyedArgName(argName, i), m)); i++; &#125; return resolved; &#125; /** * 解析ManagedMap */ private Map&lt;?, ?&gt; resolveManagedMap(Object argName, Map&lt;?, ?&gt; mm) &#123; Map&lt;Object, Object&gt; resolved = new LinkedHashMap&lt;&gt;(mm.size()); mm.forEach((key, value) -&gt; &#123; Object resolvedKey = resolveValueIfNecessary(argName, key); Object resolvedValue = resolveValueIfNecessary(new KeyedArgName(argName, key), value); resolved.put(resolvedKey, resolvedValue); &#125;); return resolved; &#125; &#125; 从上面的代码中我们看到，最终创建了相应的集合数据结构，并将集合元素添加到了集合中，这样BeanDefinition中定义的Property就解析为一个真正的对象了，下面就可以进行依赖的注入了。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【四】依赖注入过程]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E5%9B%9B%E3%80%91%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[总览通过前面的分析，我们知道了IOC容器在初始化过程中建立了BeanDefinition的数据结构，接下来就需要进行依赖注入，处理Bean之间的依赖关系。 通常，我们可以通过lazy-init属性控制Bean的实例化（依赖注入）时机。 当lazy-init=true时，依赖注入会发生在第一次向容器获取Bean时（getBean）；当lazy-init=false时，会在容器初始化的过程中将所有的singleton bean提前进行实例化和依赖注入，因此singleton bean的依赖注入是容器初始化过程的一部分，这也是我们常用的ApplicationContext的默认配置。 源码分析getBean触发依赖注入getBeangetBean方法定义在BeanFactory接口中，以DefaultListableBeanFactory为例，其基类AbstractBeanFactory中实现了getBean方法，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150public abstract class AbstractBeanFactory extends FactoryBeanRegistrySupport implements ConfigurableBeanFactory &#123; ... /** * 向容器索要Bean，触发Bean的依赖注入 */ @Override public Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false); &#125; protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // 首先检查是否存在缓存的singleton bean // 这里会涉及到单例缓存、提前曝光单例缓存和单例工厂缓存，后续会进一步解析这部分 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; // 如果sharedInstance是FactoryBean，则返回其生产的Bean // 否则返回NullBean或sharedInstance本身 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // 如果bean正在创建中则获取失败 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // 检查当前BeanFactory中是否存在以beanName为名的BeanDefinition // 如果当前BeanFactory中没有，则会顺着其父BeanFactory查找 BeanFactory parentBeanFactory = getParentBeanFactory(); // 这里的containsBeanDefinition是一个模板方法，由DefaultListableBeanFactory实现 // 即在存储BeanDefinition的Map中查找是否存在 if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // 当前BeanFactory未找到，开始在父BeanFactory中查找 String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean(nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; // 根据beanName获取BeanFactory中的BeanDefinition // 这里的RootBeanDefinition代表着在继承关系下创建的BeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 获得当前Bean依赖的所有Bean，通过 depends-on="xxx" 属性指定 // 表示初始化当前Bean需要先初始化其依赖的xxx String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; registerDependentBean(dep, beanName); try &#123; // 递归，直到取到没有depends-on的Bean getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", ex); &#125; &#125; &#125; // 创建bean实例 if (mbd.isSingleton()) &#123; // 创建singleton作用域Bean实例 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // 创建prototype作用域Bean实例 Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; // 创建其他作用域Bean：request、session、global session String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // end of else // 类型检查 if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; // 类型转换 T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; // 返回类型转换后的bean实例 return convertedBean; &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean; &#125;&#125; createBean在前面的分析中，我们可以看到多处调用了createBean方法，这个方法是用来创建Bean实例的，并进行了一些其他处理。 createBean方法是一个模板方法，由其子类AbstractAutowireCapableBeanFactory实现，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; ... /** * 创建Bean */ @Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // 根据class属性或className解析beanClass Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // 对override属性（lookup-method、replace-method）进行处理 // 会检测当前beanDefinition的class中是否是否包含相应方法，并将override方法标记为覆盖，防止进行重载参数检查 try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // 调用InstantiationAwareBeanPostProcessor // 允许在实例化前后进行处理 // 如果返回值不为空，表示配置了InstantiationAwareBeanPostProcessor，并且修改了bean // 则返回一个代理，而不是bean实例 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; try &#123; // 创建bean实例 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, "Unexpected exception during bean creation", ex); &#125; &#125; /** * 真正开始创建Bean */ protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // 实例化bean BeanWrapper instanceWrapper = null; // 如果是单例bean，则先清除缓存 if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; // 若不存在缓存，则创建bean实例 if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // 通过post-processors合并继承关系下的beanDefinition synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // 提前曝光bean（利用缓存），用于支持循环bean的循环依赖 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; // 通过匿名内部类添加单例工厂到缓存 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // 初始化bean Object exposedObject = bean; try &#123; // 这里开始进行依赖注入 populateBean(beanName, mbd, instanceWrapper); // 初始化bean，执行init-method和后置处理器 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; // 检查在提前曝光时，注入的bean是否为最终版本 if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // 给Bean注册一些必要的销毁操作，当容器shutdown时执行 try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; // 返回Bean实例，这里已经完成了依赖注入 return exposedObject; &#125; &#125; 到这里，我们就已经得到依赖注入后的Bean实例了，这个过程看起来十分简单，但实际上有两个要点需要我们格外关注：其一，创建Bean实例（createBeanInstance）；其二，进行依赖注入（populateBean），下面让我们继续分析。 createBeanInstancecreateBeanInstance通过适当的实例化策略来创建一个Bean实例，这里需要注意Spring5.0的新特性：通过设置Bean创建回调来覆盖工厂方法和构造函数。 在这个过程中，通过默认构造方法（无参构造）是基本的实例化策略，这个策略Spring的实现中提供了两种创建Bean的方式：其一，通过JVM反射创建Bean实例；其二，通过cgLib动态代理创建Bean实例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; ... /** * 创建Bean实例 */ protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; // 确保Bean类可以实例化 Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Bean class isn't public, and non-public access not allowed: " + beanClass.getName()); &#125; // 5.0的新特性 // doc注释：用作创建Bean的回调，设置该回调后会覆盖掉创建Bean的工厂方法和构造函数， // 但不影响依赖注入过程 Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return obtainFromSupplier(instanceSupplier, beanName); &#125; // 使用工厂方法实例化Bean if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // 创建Bean时需要根据beanClass解析构造方法，并缓存在RootBeanDefinition中 // 这里通过缓存直接进行处理，在创建相同Bean时不需要重复解析构造方法 boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; // 已解析构造方法 if (resolved) &#123; if (autowireNecessary) &#123; return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; return instantiateBean(beanName, mbd); &#125; &#125; // 使用构造函数实例化Bean Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; // 有参构造函数 return autowireConstructor(beanName, mbd, ctors, args); &#125; // 默认构造函数 // 这里共有两种方式创建Bean：其一，通过JVM反射；其二，通过cgLib的动态代理机制 return instantiateBean(beanName, mbd); &#125; &#125; populateBean这里就是依赖注入的核心了，在这里，首先由InstantiationAwareBeanPostProcessors进行依赖注入前的处理，判断是否对Bean的Property进行注入，接下来先处理autowire的注入，这里的autowire指的是在配置文件中通过autowire=”byName”或者autowire=”byType”等属性配置的bean，最后处理Property属性注入，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; ... /** * 依赖处理 */ protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; if (mbd.hasPropertyValues()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // 不处理为空的Bean实例的依赖 return; &#125; &#125; // 交由InstantiationAwareBeanPostProcessors处理是否对Bean实例进行依赖注入 boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; return; &#125; PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); // 首先处理autowire依赖注入，根据Bean的名字或类型进行注入 // 我们可以在配置文件中指定注入方式：autowire="byName" if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 按变量名注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // 按类型注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); // 在为Bean注入依赖前进行后置处理，比如检查@Required是否满足，添加或移除Property if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; // 进行依赖检查 if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; // 对属性进行注入 if (pvs != null) &#123; applyPropertyValues(beanName, mbd, bw, pvs); &#125; &#125; /** * 注入Property */ protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &#123; if (pvs.isEmpty()) &#123; return; &#125; if (System.getSecurityManager() != null &amp;&amp; bw instanceof BeanWrapperImpl) &#123; ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); &#125; // 注入的Property MutablePropertyValues mpvs = null; List&lt;PropertyValue&gt; original; // pvs是MutablePropertyValues实例，且可强制类型转换，则可以直接设置为注入的Property if (pvs instanceof MutablePropertyValues) &#123; mpvs = (MutablePropertyValues) pvs; if (mpvs.isConverted()) &#123; try &#123; bw.setPropertyValues(mpvs); return; &#125; catch (BeansException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125; &#125; original = mpvs.getPropertyValueList(); &#125; else &#123; original = Arrays.asList(pvs.getPropertyValues()); &#125; TypeConverter converter = getCustomTypeConverter(); if (converter == null) &#123; converter = bw; &#125; // valueResolver用于解析BeanDefinition中的Property BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // 创建一个深拷贝副本，这个副本持有的Property会被注入到Bean中 List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;&gt;(original.size()); boolean resolveNecessary = false; for (PropertyValue pv : original) &#123; if (pv.isConverted()) &#123; deepCopy.add(pv); &#125; else &#123; String propertyName = pv.getName(); Object originalValue = pv.getValue(); // 利用valueResolver解析PropertyValue // TODO 具体的解析待后续分析 Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &#123; convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &#125; if (resolvedValue == originalValue) &#123; if (convertible) &#123; pv.setConvertedValue(convertedValue); &#125; deepCopy.add(pv); &#125; else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123; pv.setConvertedValue(convertedValue); deepCopy.add(pv); &#125; else &#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &#125; &#125; &#125; if (mpvs != null &amp;&amp; !resolveNecessary) &#123; mpvs.setConverted(); &#125; // 将拷贝副本中的PropertyValues注入到Bean中 try &#123; bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &#125; catch (BeansException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125; &#125; &#125; 到这里，我们发现最终的依赖注入实际上调用了BeanWrapper接口的setPropertyValues方法，这个方法由AbstractPropertyAccessor实现，在这个方法中，取得了所有的属性，对每一个属性进行注入，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public abstract class AbstractPropertyAccessor extends TypeConverterSupport implements ConfigurablePropertyAccessor &#123; ... @Override public void setPropertyValues(PropertyValues pvs) throws BeansException &#123; setPropertyValues(pvs, false, false); &#125; @Override public void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown, boolean ignoreInvalid) throws BeansException &#123; List&lt;PropertyAccessException&gt; propertyAccessExceptions = null; // 取得属性 List&lt;PropertyValue&gt; propertyValues = (pvs instanceof MutablePropertyValues ? ((MutablePropertyValues) pvs).getPropertyValueList() : Arrays.asList(pvs.getPropertyValues())); for (PropertyValue pv : propertyValues) &#123; try &#123; // 注入属性 setPropertyValue(pv); &#125; catch (NotWritablePropertyException ex) &#123; if (!ignoreUnknown) &#123; throw ex; &#125; &#125; catch (NullValueInNestedPathException ex) &#123; if (!ignoreInvalid) &#123; throw ex; &#125; &#125; catch (PropertyAccessException ex) &#123; if (propertyAccessExceptions == null) &#123; propertyAccessExceptions = new LinkedList&lt;&gt;(); &#125; propertyAccessExceptions.add(ex); &#125; &#125; if (propertyAccessExceptions != null) &#123; PropertyAccessException[] paeArray = propertyAccessExceptions.toArray(new PropertyAccessException[0]); throw new PropertyBatchUpdateException(paeArray); &#125; &#125; @Override public void setPropertyValue(PropertyValue pv) throws BeansException &#123; setPropertyValue(pv.getName(), pv.getValue()); &#125; @Override public abstract void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException; &#125; 这里的setPropertyValue(String, Object)是一个模板方法，具体的实现在其子类AbstractNestablePropertyAccessor中，这是4.2版本加入的新特性，在更早的版本中，setProperty(String，Object)方法是由BeanWrapperImpl实现的，在新版本的实现中，BeanWrapperImpl继承了AbstractNestablePropertyAccessor，但具体的实现原理还是一样的，AbstractNestablePropertyAccessor代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public abstract class AbstractNestablePropertyAccessor extends AbstractPropertyAccessor &#123; ... @Override public void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException &#123; AbstractNestablePropertyAccessor nestedPa; try &#123; // 取得属性访问器 nestedPa = getPropertyAccessorForPropertyPath(propertyName); &#125; catch (NotReadablePropertyException ex) &#123; throw new NotWritablePropertyException(getRootClass(), this.nestedPath + propertyName, "Nested property in path '" + propertyName + "' does not exist", ex); &#125; // 将propertyName解析为PropertyTokenHolder，根据keys是否为空分为集合和非集合类型 PropertyTokenHolder tokens = getPropertyNameTokens(getFinalPath(nestedPa, propertyName)); nestedPa.setPropertyValue(tokens, new PropertyValue(propertyName, value)); &#125; /** * 通过递归返回一个嵌套属性路径的属性访问器 */ protected AbstractNestablePropertyAccessor getPropertyAccessorForPropertyPath(String propertyPath) &#123; // 查找第一个嵌套属性路径分隔符，即"."，的位置 int pos = PropertyAccessorUtils.getFirstNestedPropertySeparatorIndex(propertyPath); // 包含分隔符 if (pos &gt; -1) &#123; String nestedProperty = propertyPath.substring(0, pos); String nestedPath = propertyPath.substring(pos + 1); AbstractNestablePropertyAccessor nestedPa = getNestedPropertyAccessor(nestedProperty); // 递归 return nestedPa.getPropertyAccessorForPropertyPath(nestedPath); &#125; // 不包含分隔符，即找到了嵌套属性路径中最底层的属性 // 比如嵌套的a.b，则会找到b这一个属性访问器 else &#123; return this; &#125; &#125; /** * 解析propertyName */ private PropertyTokenHolder getPropertyNameTokens(String propertyName) &#123; String actualName = null; List&lt;String&gt; keys = new ArrayList&lt;&gt;(2); int searchIndex = 0; while (searchIndex != -1) &#123; // 查找"["位置 int keyStart = propertyName.indexOf(PROPERTY_KEY_PREFIX, searchIndex); searchIndex = -1; if (keyStart != -1) &#123; // 查找"]"位置 int keyEnd = propertyName.indexOf(PROPERTY_KEY_SUFFIX, keyStart + PROPERTY_KEY_PREFIX.length()); if (keyEnd != -1) &#123; if (actualName == null) &#123; // 截取属性名 actualName = propertyName.substring(0, keyStart); &#125; // 这里的key是"["和"]"之间的内容，比如a[3]，那么key就是3 String key = propertyName.substring(keyStart + PROPERTY_KEY_PREFIX.length(), keyEnd); // 去掉key前后的单引号or双引号 if (key.length() &gt; 1 &amp;&amp; (key.startsWith("'") &amp;&amp; key.endsWith("'")) || (key.startsWith("\"") &amp;&amp; key.endsWith("\""))) &#123; key = key.substring(1, key.length() - 1); &#125; keys.add(key); searchIndex = keyEnd + PROPERTY_KEY_SUFFIX.length(); &#125; &#125; &#125; // 根据属性名创建PropertyTokenHolder PropertyTokenHolder tokens = new PropertyTokenHolder(actualName != null ? actualName : propertyName); if (!keys.isEmpty()) &#123; tokens.canonicalName += PROPERTY_KEY_PREFIX + StringUtils.collectionToDelimitedString(keys, PROPERTY_KEY_SUFFIX + PROPERTY_KEY_PREFIX) + PROPERTY_KEY_SUFFIX; tokens.keys = StringUtils.toStringArray(keys); &#125; return tokens; &#125; &#125; 这段代码里我们可以看到，首先在嵌套属性中取得嵌套最底层的属性的访问器，然后将对属性名进行解析，将解析结果封装在PropertyTokenHolder中。 这里需要对嵌套属性和PropertyTokenHolder做一个解释，在刚开始看源码的时候就卡在了这里，一直没有搞懂这种解析发生在什么情况下，下面我们来对这两个概念做一下简单的解析： 首先，嵌套属性，例如我们在Spring配置文件中有如下配置： 1234567891011&lt;beans&gt; &lt;bean id="a" class="greedystar.entity.A" lazy-init="true"&gt; &lt;property name="name" value="Alvin"/&gt; &lt;property name="id" value="123"/&gt; &lt;/bean&gt; &lt;bean id="b" class="greedystar.entity.B" lazy-init="true"&gt; &lt;property name="a" ref="a"/&gt; &lt;property name="a.name" value="李四"/&gt; &lt;/bean&gt;&lt;/beans&gt; 这里的 就是嵌套属性，代码中通过递归取得嵌套最底层的属性的访问器，也就是a.name中name属性的访问器。 其次，PropertyTokenHolder，例如我们在Spring配置文件中有如下配置： 12345678910111213141516171819&lt;beans&gt; &lt;bean id="a" class="greedystar.entity.A" lazy-init="true"&gt; &lt;property name="name" value="Alvin"/&gt; &lt;property name="id" value="123"/&gt; &lt;property name="roles"&gt; &lt;list&gt; &lt;value&gt;USER&lt;/value&gt; &lt;value&gt;ADMIN&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="b" class="greedystar.entity.B" lazy-init="true"&gt; &lt;property name="a" ref="a"/&gt; &lt;property name="a.name" value="李四"/&gt; &lt;property name="a.roles[0]" value="USER1"/&gt; &lt;property name="a.roles[1]" value="ADMIN1"/&gt; &lt;/bean&gt;&lt;/beans&gt; 当解析到a.roles[0]这个属性时，会把这个属性名解析到PropertyTokenHolder对象中，这个对象的属性值如下： 可以看到，这里的keys对应的就是访问集合属性时的索引值，当keys不为空时认为这个属性为集合取值属性，为空则不为集合取值取值属性，集合取值属性这个名字是我为了区别于普通的注入集合属性而随意写下的，各位对这里有所区别就好。 OK，对嵌套属性和集合取值属性有所了解后，我们继续回到AbstractNestablePropertyAccessor这个类中，通过上面的分析，我们已经取得了PropertyTokenHolder对象，下面将通过该对象进行属性的注入，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141public abstract class AbstractNestablePropertyAccessor extends AbstractPropertyAccessor &#123; ... protected void setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv) throws BeansException &#123; if (tokens.keys != null) &#123; // 集合取值属性，key的值代表取值的索引 processKeyedProperty(tokens, pv); &#125; else &#123; // 非集合取值属性 processLocalProperty(tokens, pv); &#125; &#125; /** * 集合取值属性注入 */ private void processKeyedProperty(PropertyTokenHolder tokens, PropertyValue pv) &#123; // 根据属性名取得要注入的属性，这里使用了Java的内省机制，也就是通过setter和getter存取属性 Object propValue = getPropertyHoldingValue(tokens); // 这里的PropertyHandler是对PropertyDescriptor的封装，具体的实现在BeanWrapperImpl中 PropertyHandler ph = getLocalPropertyHandler(tokens.actualName); if (ph == null) &#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.actualName, "No property handler found"); &#125; Assert.state(tokens.keys != null, "No token keys"); // 取得要访问集合属性值的索引 String lastKey = tokens.keys[tokens.keys.length - 1]; //这里处理数组类型的集合取值属性 if (propValue.getClass().isArray()) &#123; Class&lt;?&gt; requiredType = propValue.getClass().getComponentType(); int arrayIndex = Integer.parseInt(lastKey); Object oldValue = null; try &#123; if (isExtractOldValueForEditor() &amp;&amp; arrayIndex &lt; Array.getLength(propValue)) &#123; // 取得旧的值，比如上文分析中的“张三” oldValue = Array.get(propValue, arrayIndex); &#125; // 将旧值转换为当前的实际值，比如上文中的“李四” Object convertedValue = convertIfNecessary(tokens.canonicalName, oldValue, pv.getValue(), requiredType, ph.nested(tokens.keys.length)); int length = Array.getLength(propValue); if (arrayIndex &gt;= length &amp;&amp; arrayIndex &lt; this.autoGrowCollectionLimit) &#123; Class&lt;?&gt; componentType = propValue.getClass().getComponentType(); Object newArray = Array.newInstance(componentType, arrayIndex + 1); System.arraycopy(propValue, 0, newArray, 0, length); setPropertyValue(tokens.actualName, newArray); propValue = getPropertyValue(tokens.actualName); &#125; // 将转换后的值set到索引指定的位置 Array.set(propValue, arrayIndex, convertedValue); &#125; catch (IndexOutOfBoundsException ex) &#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, "Invalid array index in property path '" + tokens.canonicalName + "'", ex); &#125; &#125; // 下面处理LIST和MAP，基本属于同一个套路，这里就不把代码贴出来了 else if (propValue instanceof List) &#123; &#125; else if (propValue instanceof Map) &#123; &#125; else &#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, "Property referenced in indexed property path '" + tokens.canonicalName + "' is neither an array nor a List nor a Map; returned value was [" + propValue + "]"); &#125; &#125; /** * 非集合取值属性注入 */ private void processLocalProperty(PropertyTokenHolder tokens, PropertyValue pv) &#123; // 取得PropertyHandler，用于后续使用内省机制 PropertyHandler ph = getLocalPropertyHandler(tokens.actualName); if (ph == null || !ph.isWritable()) &#123; if (pv.isOptional()) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Ignoring optional value for property '" + tokens.actualName + "' - property not found on bean class [" + getRootClass().getName() + "]"); &#125; return; &#125; else &#123; throw createNotWritablePropertyException(tokens.canonicalName); &#125; &#125; Object oldValue = null; try &#123; // 取得属性旧值 Object originalValue = pv.getValue(); Object valueToApply = originalValue; if (!Boolean.FALSE.equals(pv.conversionNecessary)) &#123; if (pv.isConverted()) &#123; // 取得已转换过的新值 valueToApply = pv.getConvertedValue(); &#125; else &#123; if (isExtractOldValueForEditor() &amp;&amp; ph.isReadable()) &#123; try &#123; oldValue = ph.getValue(); &#125; catch (Exception ex) &#123; if (ex instanceof PrivilegedActionException) &#123; ex = ((PrivilegedActionException) ex).getException(); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Could not read previous value of property '" + this.nestedPath + tokens.canonicalName + "'", ex); &#125; &#125; &#125; // 将旧值转换为实际的新值 valueToApply = convertForProperty(tokens.canonicalName, oldValue, originalValue, ph.toTypeDescriptor()); &#125; pv.getOriginalPropertyValue().conversionNecessary = (valueToApply != originalValue); &#125; // 通过Java内省机制set新的属性值，setValue方法的具体实现在BeanWrapperImpl中 ph.setValue(valueToApply); &#125; catch (TypeMismatchException ex) &#123; throw ex; &#125; catch (InvocationTargetException ex) &#123; PropertyChangeEvent propertyChangeEvent = new PropertyChangeEvent(getRootInstance(), this.nestedPath + tokens.canonicalName, oldValue, pv.getValue()); if (ex.getTargetException() instanceof ClassCastException) &#123; throw new TypeMismatchException(propertyChangeEvent, ph.getPropertyType(), ex.getTargetException()); &#125; else &#123; Throwable cause = ex.getTargetException(); if (cause instanceof UndeclaredThrowableException) &#123; // May happen e.g. with Groovy-generated methods cause = cause.getCause(); &#125; throw new MethodInvocationException(propertyChangeEvent, cause); &#125; &#125; catch (Exception ex) &#123; PropertyChangeEvent pce = new PropertyChangeEvent(getRootInstance(), this.nestedPath + tokens.canonicalName, oldValue, pv.getValue()); throw new MethodInvocationException(pce, ex); &#125; &#125; &#125; 到这里，我们发现最终调用了BeanWrapperImpl的setValue方法，通过Java的内省机制将Bean所依赖的属性注入到Bean中，这样Bean之间的依赖关系就处理完成了，接下来这些Bean就可以被我们直接使用了。 Bean的预实例化我们知道当为Bean配置了lazy-init=false属性时，IOC容器会在初始化的时候对Bean进行预实例化，这时将会提前触发Bean的依赖注入过程，我们回到AbstractApplicationContext的refresh方法中，这里是IOC容器初始化的入口，在这个方法中我们可以看到调用了finishBeanFactoryInitialization方法，这个方法将会对非延迟加载的单例Bean进行预实例化，代码如下： 1234567891011121314151617181920212223public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; @Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; ... // 预实例化非延迟加载的单例Bean finishBeanFactoryInitialization(beanFactory); ... &#125; &#125; protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; ... // 预实例化非延迟加载的单例Bean beanFactory.preInstantiateSingletons(); &#125; &#125; 这里调用了ConfigurableListableBeanFactory接口的preInstantiateSingletons()方法，具体由DefaultListableBeanFactory实现，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; ... @Override public void preInstantiateSingletons() throws BeansException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Pre-instantiating singletons in " + this); &#125; // 所有Bean的名称 List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); // 将非延迟加载的单例Bean预实例化 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; // 触发依赖注入 getBean(beanName); &#125; &#125; &#125; else &#123; // 触发依赖注入 getBean(beanName); &#125; &#125; &#125; // 触发单例实例化后的回调方法 for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125; &#125; &#125; 分析到这里我们发现，在预实例化的过程中调用了getBean方法来触发Bean的依赖注入，后续的处理就与前面分析的过程一样了，通过一系列的处理，Bean的预实例化过程就完成了。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>DI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【三】填坑篇之BeanDefinition的解析]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%B8%89%E3%80%91%E5%A1%AB%E5%9D%91%E7%AF%87%E4%B9%8BBeanDefinition%E7%9A%84%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在 Spring源码学习【二】IOC容器的初始化（二）BeanDefinition载入 中，我们分析了BeanDefinition的载入过程，同时也留下了这样一句注释： 12// TODO：待深入学习AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, con-tainingBean); 下面来填上这里挖下的坑，这句代码实际上是将XML的Element元素解析为具体BeanDefinition的入口，让我们回到BeanDefinitionParserDelegate类的这个方法中，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class BeanDefinitionParserDelegate &#123; ... public AbstractBeanDefinition parseBeanDefinitionElement(Element ele, String beanName, @Nullable BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); // 获得class属性 String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; // 获得parent属性 String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; try &#123; // 创建一个具体的BeanDefinition AbstractBeanDefinition bd = createBeanDefinition(className, parent); // 解析BeanDefinition属性 // 比如：singleton、scope、abstract、lazy-init、autowire等 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); // 解析&lt;meta/&gt;元素 parseMetaElements(ele, bd); // 解析&lt;lookup-method/&gt;元素 parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); // 解析&lt;replace-method/&gt;元素 parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); // 解析&lt;contructor-args/&gt;元素 parseConstructorArgElements(ele, bd); // 重点关注一下解析&lt;property/&gt;元素 parsePropertyElements(ele, bd); // 解析&lt;qualifier/&gt;元素 parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error("Bean class [" + className + "] not found", ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error("Class that bean class [" + className + "] depends on not found", ele, err); &#125; catch (Throwable ex) &#123; error("Unexpected failure during bean definition parsing", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null; &#125; &#125; 在上面的代码中可以看到，创建了一个BeanDefinition，然后根据XML资源中的配置解析相关的属性配置，并设置到BeanDefinition，这里理解起来是比较简单的，我们需要重点关注parsePropertyElements这个方法，这个方法中实现了解析元素下的元素，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154public class BeanDefinitionParserDelegate &#123; ... public void parsePropertyElements(Element beanEle, BeanDefinition bd) &#123; // 获得bean元素下的子节点 NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); // 解析property属性 if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, PROPERTY_ELEMENT)) &#123; parsePropertyElement((Element) node, bd); &#125; &#125; &#125; public void parsePropertyElement(Element ele, BeanDefinition bd) &#123; ... // 重点关注这里 Object val = parsePropertyValue(ele, bd, propertyName); PropertyValue pv = new PropertyValue(propertyName, val); parseMetaElements(ele, pv); pv.setSource(extractSource(ele)); // 将解析后的property添加到BeanDefinition中 bd.getPropertyValues().addPropertyValue(pv); ... &#125; @Nullable public Object parsePropertyValue(Element ele, BeanDefinition bd, @Nullable String propertyName) &#123; String elementName = (propertyName != null) ? "&lt;property&gt; element for property '" + propertyName + "'" : "&lt;constructor-arg&gt; element"; // &lt;property&gt;下仅允许一个子元素 NodeList nl = ele.getChildNodes(); Element subElement = null; for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element &amp;&amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT) &amp;&amp; !nodeNameEquals(node, META_ELEMENT)) &#123; // Child element is what we're looking for. if (subElement != null) &#123; error(elementName + " must not contain more than one sub-element", ele); &#125; else &#123; subElement = (Element) node; &#125; &#125; &#125; boolean hasRefAttribute = ele.hasAttribute(REF_ATTRIBUTE); boolean hasValueAttribute = ele.hasAttribute(VALUE_ATTRIBUTE); if ((hasRefAttribute &amp;&amp; hasValueAttribute) || ((hasRefAttribute || hasValueAttribute) &amp;&amp; subElement != null)) &#123; error(elementName + " is only allowed to contain either 'ref' attribute OR 'value' attribute OR sub-element", ele); &#125; // 有ref属性，即引用其他bean if (hasRefAttribute) &#123; String refName = ele.getAttribute(REF_ATTRIBUTE); if (!StringUtils.hasText(refName)) &#123; error(elementName + " contains empty 'ref' attribute", ele); &#125; RuntimeBeanReference ref = new RuntimeBeanReference(refName); ref.setSource(extractSource(ele)); return ref; &#125; // 有value属性，即普通字符串 else if (hasValueAttribute) &#123; TypedStringValue valueHolder = new TypedStringValue(ele.getAttribute(VALUE_ATTRIBUTE)); valueHolder.setSource(extractSource(ele)); return valueHolder; &#125; // 有子元素标签，如&lt;list&gt;、&lt;array&gt;等 else if (subElement != null) &#123; return parsePropertySubElement(subElement, bd); &#125; else &#123; error(elementName + " must specify a ref or value", ele); return null; &#125; &#125; @Nullable public Object parsePropertySubElement(Element ele, @Nullable BeanDefinition bd, @Nullable String defaultValueType) &#123; // 非默认命名空间 if (!isDefaultNamespace(ele)) &#123; return parseNestedCustomElement(ele, bd); &#125; // bean嵌套 else if (nodeNameEquals(ele, BEAN_ELEMENT)) &#123; BeanDefinitionHolder nestedBd = parseBeanDefinitionElement(ele, bd); if (nestedBd != null) &#123; nestedBd = decorateBeanDefinitionIfRequired(ele, nestedBd, bd); &#125; return nestedBd; &#125; // bean引用 else if (nodeNameEquals(ele, REF_ELEMENT)) &#123; String refName = ele.getAttribute(BEAN_REF_ATTRIBUTE); boolean toParent = false; if (!StringUtils.hasLength(refName)) &#123; refName = ele.getAttribute(PARENT_REF_ATTRIBUTE); toParent = true; if (!StringUtils.hasLength(refName)) &#123; error("'bean' or 'parent' is required for &lt;ref&gt; element", ele); return null; &#125; &#125; if (!StringUtils.hasText(refName)) &#123; error("&lt;ref&gt; element contains empty target attribute", ele); return null; &#125; RuntimeBeanReference ref = new RuntimeBeanReference(refName, toParent); ref.setSource(extractSource(ele)); return ref; &#125; // id引用 else if (nodeNameEquals(ele, IDREF_ELEMENT)) &#123; return parseIdRefElement(ele); &#125; // 普通字符串 else if (nodeNameEquals(ele, VALUE_ELEMENT)) &#123; return parseValueElement(ele, defaultValueType); &#125; // NULL else if (nodeNameEquals(ele, NULL_ELEMENT)) &#123; TypedStringValue nullHolder = new TypedStringValue(null); nullHolder.setSource(extractSource(ele)); return nullHolder; &#125; // 数组 else if (nodeNameEquals(ele, ARRAY_ELEMENT)) &#123; return parseArrayElement(ele, bd); &#125; // 列表 else if (nodeNameEquals(ele, LIST_ELEMENT)) &#123; return parseListElement(ele, bd); &#125; // 集合 else if (nodeNameEquals(ele, SET_ELEMENT)) &#123; return parseSetElement(ele, bd); &#125; // Map else if (nodeNameEquals(ele, MAP_ELEMENT)) &#123; return parseMapElement(ele, bd); &#125; else if (nodeNameEquals(ele, PROPS_ELEMENT)) &#123; return parsePropsElement(ele); &#125; else &#123; error("Unknown property sub-element: [" + ele.getNodeName() + "]", ele); return null; &#125; &#125; &#125; 最终，解析处理落在了parseXXElement方法上，这一系列方法实现了对各种元素的解析，我们以集合元素的解析为例看一看具体的解析方式，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class BeanDefinitionParserDelegate &#123; ... /** * 解析Array元素 */ public Object parseArrayElement(Element arrayEle, @Nullable BeanDefinition bd) &#123; String elementType = arrayEle.getAttribute(VALUE_TYPE_ATTRIBUTE); NodeList nl = arrayEle.getChildNodes(); ManagedArray target = new ManagedArray(elementType, nl.getLength()); target.setSource(extractSource(arrayEle)); target.setElementTypeName(elementType); target.setMergeEnabled(parseMergeAttribute(arrayEle)); parseCollectionElements(nl, target, bd, elementType); return target; &#125; /** * 解析List元素 */ public List&lt;Object&gt; parseListElement(Element collectionEle, @Nullable BeanDefinition bd) &#123; String defaultElementType = collectionEle.getAttribute(VALUE_TYPE_ATTRIBUTE); NodeList nl = collectionEle.getChildNodes(); ManagedList&lt;Object&gt; target = new ManagedList&lt;&gt;(nl.getLength()); target.setSource(extractSource(collectionEle)); target.setElementTypeName(defaultElementType); target.setMergeEnabled(parseMergeAttribute(collectionEle)); parseCollectionElements(nl, target, bd, defaultElementType); return target; &#125; /** * 解析子元素并添加到集合中 */ protected void parseCollectionElements(NodeList elementNodes, Collection&lt;Object&gt; target, @Nullable BeanDefinition bd, String defaultElementType) &#123; for (int i = 0; i &lt; elementNodes.getLength(); i++) &#123; Node node = elementNodes.item(i); // 这里会解析子元素，比如我们list的子元素是value，那么最终会添加一个字符串到集合中 if (node instanceof Element &amp;&amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT)) &#123; target.add(parsePropertySubElement((Element) node, bd, defaultElementType)); &#125; &#125; &#125; &#125; 到这里，我们发现最终将集合property解析为ManagedXXX对象，并将其添加到了BeanDefinition中。这里的ManagedXXX是对集合类的进一步封装，我们可以参照ManagedArray的类继承图，如下所示： OK，到这里BeanDefinition的解析就简略分析完了，最终在BeanDefinition以ManagedXXX对象存在的各个Property将会在依赖注入的过程中继续发挥作用。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【二】IOC容器的初始化（三）BeanDefinition注册]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%BA%8C%E3%80%91IOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%88%E4%B8%89%EF%BC%89BeanDefinition%E6%B3%A8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[总览经过以上的分析，我们知道Document中BeanDefinition的解析是在DefaultBeanDefinitionDocumentReader中进行的，让我们回到DefaultBeanDefinitionDocumentReader的processBeanDefinition方法中，继续分析BeanDefinition解析后的注册过程。在processBeanDefinition方法中，我们可以看到这样一句代码： 1BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); 这里的处理就是将解析得到的BeanDefinition注册到bean工厂中，下面我们来看一看具体的源码。 源码分析BeanDefinitionReaderUtils.registerBeanDefinition源码如下所示： 12345678910111213141516public class BeanDefinitionReaderUtils &#123; public static void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // 注册BeanDefinition String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 为bean name注册别名 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125; &#125;&#125; BeanDefinitionRegistry是一个接口，其中定义了一系列与BeanDefinition注册相关的方法，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738public interface BeanDefinitionRegistry extends AliasRegistry &#123; /** * 以beanName注册一个beanDefinition */ void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefini-tionStoreException; /** * 移除beanDefinition */ void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; /** * 获取beanDefinition */ BeanDefinition getBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; /** * 检查是否存在以beanName为名的beanDefinition */ boolean containsBeanDefinition(String beanName); /** * 获取所有beanDefinition的名称 */ String[] getBeanDefinitionNames(); /** * 获取beanDefinition数目 */ int getBeanDefinitionCount(); /** * 检查给定的beanName是否已使用 */ boolean isBeanNameInUse(String beanName); &#125; 在我们之前分析的FileSystemXmlApplicationContext中，实际上就是以DefaultListableBeanFactory作为基本的IOC容器的，DefaultListableBeanFactory实现了BeanDefinitionRegistry接口，registry.registerBeanDefinition实际调用了DefaultListableBeanFactory中实现的registerBeanDefinition方法，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements Con-figurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; /** 持有beanDefinition的HashMap */ private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); /** 以注册顺序保存BeanDefinition名称 */ private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256); /** 以注册顺序保存手动注册的单例名称 */ private volatile Set&lt;String&gt; manualSingletonNames = new LinkedHashSet&lt;&gt;(16); @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, "Bean name must not be empty"); Assert.notNull(beanDefinition, "BeanDefinition must not be null"); // 验证beanDefinition，主要是验证beanDefinition重写的方法 if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Validation of bean definition failed", ex); &#125; &#125; BeanDefinition oldBeanDefinition; oldBeanDefinition = this.beanDefinitionMap.get(beanName); // 已存在beanDefinition if (oldBeanDefinition != null) &#123; // 不允许覆盖则抛出异常 if (!isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Cannot register bean definition [" + beanDefinition + "] for bean '" + beanName + "': There is already [" + oldBeanDefinition + "] bound."); &#125; else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn("Overriding user-defined bean definition for bean '" + beanName + "' with a framework-generated bean definition: replacing [" + oldBeanDefinition + "] with [" + beanDefinition + "]"); &#125; &#125; else if (!beanDefinition.equals(oldBeanDefinition)) &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info("Overriding bean definition for bean '" + beanName + "' with a different definition: replacing [" + oldBeanDefinition + "] with [" + beanDefinition + "]"); &#125; &#125; else &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Overriding bean definition for bean '" + beanName + "' with an equivalent definition: replacing [" + oldBeanDefinition + "] with [" + beanDefinition + "]"); &#125; &#125; // 注册BeanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); &#125; else &#123; // 不存在同名beanDefinition，进行注册 // 判断是否已经开始创建Bean，当getBean时则会开始创建Bean，为保证数据一致，需要进行同步处理 if (hasBeanCreationStarted()) &#123; synchronized (this.beanDefinitionMap) &#123; // 同步锁 this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; // 容器还在启动过程中，未开始创建Bean，直接注册BeanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); &#125; this.frozenBeanDefinitionNames = null; &#125; // 如果当前beanDefinition覆盖了原有的beanDefinition或手动注册的单例 // 则重置给定名称的beanDefinition的缓存和以该bean为双亲的beanDefinition if (oldBeanDefinition != null || containsSingleton(beanName)) &#123; resetBeanDefinition(beanName); &#125; &#125;&#125; 到这里，BeanDefinition的注册就完成了，DefaultListableBeanFactory中通过Map持有BeanDefinition，这样BeanDefinition就在IOC容器中建立了相应的数据结构，但这些BeanDefinition还是相互独立的，下面就需要进行一步重要的处理：依赖注入。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【二】IOC容器的初始化（二）BeanDefinition载入]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%BA%8C%E3%80%91IOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%88%E4%BA%8C%EF%BC%89BeanDefinition%E8%BD%BD%E5%85%A5%2F</url>
    <content type="text"><![CDATA[总览经过前一篇（Spring源码学习【二】IOC容器的初始化（一）Resource定位）的分析，我们对IOC容器的初始化过程已经有了一定的了解。IOC的初始化由refresh()方法启动，最终对Resource的载入是由XmlBeanDefinitionReader处理的。参考上一节中6.loadBeanDefinitions的分析，AbstractBeanDefinitionReader中多处调用了loadBeanDefinitions(Resource)方法，这是一个模板方法，实际由其子类XmlBeanDefinitionReader实现，并完成BeanDefinition载入的过程。 BeanDefinition的载入可以分为两个过程：首先，通过documentLoader获取得到Document对象；然后，根据Spring Bean的规则解析Document得到BeanDefinition，下面从源码的角度对这个过程进行分析。 源码分析获取Document首先， XmlBeanDefinitionReader中重写了父类的loadBeanDefinitions(Resource)方法，这个方法就是加载BeanDefinition的入口，在这个方法中，将Resource封装成带有编码信息的EncodedResource对象。 1234567891011public class XmlBeanDefinitionReader extends AbstractBeanDefinitionReader &#123; …… /** * 根据指定的xml资源文件加载BeanDefinition */ @Override public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; // 这里会为Resource添加编码等信息封装成一个EncodedResource对象 return loadBeanDefinitions(new EncodedResource(resource)); &#125;&#125; 然后，在loadBeanDefinitions(EncodedResource)中处理了Resource的循环加载，并将Resource封装成代表XML实体的InputSource（这里对LocalThread和循环加载存在疑问）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class XmlBeanDefinitionReader extends AbstractBeanDefinitionReader &#123; …… /** * 根据指定的xml资源文件加载BeanDefinition，允许指定解析文件使用的编码方式 */ public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreEx-ception &#123; Assert.notNull(encodedResource, "EncodedResource must not be null"); if (logger.isInfoEnabled()) &#123; logger.info("Loading XML bean definitions from " + encodedResource.getResource()); &#125; // private final ThreadLocal&lt;Set&lt;EncodedResource&gt;&gt; resourcesCurrentlyBeingLoaded = // new NamedThreadLocal&lt;&gt;("XML bean definition resources currently being loaded"); // 这里使用的localThread会为每个线程创建一个Set&lt;EncodedResource&gt;副本，保证线程之间的数据访问不会出现冲突 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; // 我们在配置文件中可以通过&lt;import&gt;标签引用其他资源文件，当出现资源文件之间的循环引用时会抛出异常 if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException("Detected cyclic loading of " + encodedResource + " - check your import definitions!"); &#125; try &#123; // Resource是封装了一系列I/O操作的资源，这里拿到输入流InputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; // 将InputStream封装成一个InputSource，InputSource是xml SAX解析的数据源 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 开始加载BeanDefinition return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException("IOException parsing XML document from " + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125; &#125;&#125; 接下来，调用了 doLoadBeanDefinitions(InputSource, Resource)方法，真正开始从XML资源文件加载BeanDefinition。前面已经提到过，BeanDefinition的载入首先需要获取Document，这里有两个核心方法：其一，doLoadDocument；其二，registerBeanDefinitions。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class XmlBeanDefinitionReader extends AbstractBeanDefinitionReader &#123; …… /** * 真正开始从XML资源文件加载BeanDefinition * 两个核心方法：doLoadDocument和registerBeanDefinitions */ protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource); return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), "Line " + ex.getLineNumber() + " in XML document from " + resource + " is invalid", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), "XML document from " + resource + " is invalid", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "Parser configuration exception parsing XML from " + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "IOException parsing XML document from " + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "Unexpected exception parsing XML document from " + resource, ex); &#125; &#125; /** * 通过DocumentLoader加载XML资源文件，以Document的形式返回，用于后续的XML解析。 * 这里的Document是由w3c定义的一个接口，用于表示整个html或xml文件。 */ protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; // inputSource：SAX解析方式的输入数据 // getEntityResolver：实体解析器，分为ResourceEntityResolver和DelegatingEntityResolver // ResourceEntityResolver通常是对applicationContext的包装 // DelegatingEntityResolver是对dtdResolver和schemaResolver的包装，分别对应关于DTDs和SCHEMAs请参考http://wiki.jikexueyuan.com/project/xml/dtds.html // errorHandler SAX解析的错误错误处理 // getValidationModeForResource：获取xml文件的验证方式（dtd或xsd方式） return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware()); &#125; /** * 根据给定的Resource资源获取XML验证方式 * 如果没有明确指定验证方式，则会根据Resource内容进行判断 */ protected int getValidationModeForResource(Resource resource) &#123; int validationModeToUse = getValidationMode(); if (validationModeToUse != VALIDATION_AUTO) &#123; return validationModeToUse; &#125; // 读取Resource内容判断验证规则 int detectedMode = detectValidationMode(resource); if (detectedMode != VALIDATION_AUTO) &#123; return detectedMode; &#125; // Hmm, we didn't get a clear indication... Let's assume XSD, // since apparently no DTD declaration has been found up until // detection stopped (before finding the document's root tag). return VALIDATION_XSD; &#125; /** * 检测在XML文件上执行的哪种验证 * 如果内容包含DOCTYPE则为DTD验证，否则为XSD验证 */ protected int detectValidationMode(Resource resource) &#123; if (resource.isOpen()) &#123; throw new BeanDefinitionStoreException("Passed-in Resource [" + resource + "] contains an open stream: " + "cannot determine validation mode automatically. Either pass in a Resource " + "that is able to create fresh streams, or explicitly specify the validationMode " + "on your XmlBeanDef-initionReader instance."); &#125; InputStream inputStream; try &#123; inputStream = resource.getInputStream(); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( "Unable to determine validation mode for [" + resource + "]: cannot open InputStream. " + "Did you attempt to load directly from a SAX InputSource without specifying the " + "validationMode on your XmlBeanDefinitionReader instance?", ex); &#125; try &#123; // 进行检测 return this.validationModeDetector.detectValidationMode(inputStream); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException("Unable to determine validation mode for [" + resource + "]: an error occurred whilst reading from the InputStream.", ex); &#125; &#125; /** * 注册DOM document中包含的BeanDefinitions */ public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefini-tionStoreException &#123; // 首先创建一个读取器，这里使用的是读取Spring默认XML格式（DTD和XSD格式）BeanDefinition的读取器 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); // 注册BeanDefinition，是一个模板方法，实际调用的是DefaultBeanDefinitionDocumentReader的registerBeanDefinitions方法 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore; &#125;&#125; 到这里，已经完成了BeanDefinition载入的第一个过程：获取Document对象，用这个对象来表示XML资源文件，下面一步重要的操作就是对Document进行解析了。 解析Document经过以上的分析，我们已经知道，解析Document是在DefaultBeanDefinitionDocumentReader中完成的，下面让我们来看一看DefaultBeanDefinitionDocumentReader的部分代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class DefaultBeanDefinitionDocumentReader implements BeanDefinitionDocumentReader&#123; …… /** * 实现根据Spring bean规则解析BeanDefinition的功能 */ @Override public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug("Loading bean definitions"); // 获取到XML的根元素：&lt;beans/&gt; Element root = doc.getDocumentElement(); // 解析根元素下的BeanDefinition doRegisterBeanDefinitions(root); &#125; /** * 实现根据Spring bean规则解析BeanDefinition的功能 */ protected void doRegisterBeanDefinitions(Element root) &#123; // &lt;beans/&gt; 嵌套时会递归调用该方法，首先记录下当前的委托对象为父对象，然后创建一个新的子委托对象，在本次调用中使用子对象进行处理，目的是为了初始化每个&lt;beans&gt;的default-*属性，比如 &lt;beans de-fault-lazy-init="true" &gt; 等 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); // profile环境处理 if (this.delegate.isDefaultNamespace(root)) &#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDele-gate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Skipped XML bean definition file due to specified profiles [" + profileSpec + "] not matching: " + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; // preProcessXml和postProcessXml都是模板方法，默认实现是空的，留给子类进行扩展，子类中可以处理一些自定义的bean，并把这些bean转换为标准的Spring BeanDefinition preProcessXml(root); // 解析&lt;beans/&gt;下的BeanDefinition parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent; &#125; /** * 解析root元素下的 import、alias、bean */ protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 检查root元素是否为http://www.springframework.org/schema/beans默认命名空间 if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; // 处理beans默认命名空间下的元素标签，&lt;import&gt;、&lt;alias&gt;、&lt;bean&gt;、&lt;beans&gt; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; // 处理非默认命名空间元素标签，如&lt;context:component-scan&gt;、&lt;tx:annotation-driven&gt;等 else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125; &#125; private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate)&#123; // 解析&lt;import&gt;标签，从引用的资源中加载BeanDefinition // 这里的解析可能会抛出资源循环加载的异常 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; // 解析&lt;alias&gt;，向bean工厂注册别名 // 具体是在SimpleAliasRegistry这个类中，以HaspMap持有bean的别名和原名的关系的 // 这里需要注意别名的循环引用 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; // 解析&lt;bean&gt;，并向bean工厂注册bean else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // 这里体现了&lt;beans&gt;嵌套的递归 doRegisterBeanDefinitions(ele); &#125; &#125; /** * 解析&lt;bean&gt;并向bean工厂注册 */ protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 委托BeanDefinitionParserDelegate解析bean元素，这里的BeanDefinitionHolder是对BeanDefinition、BeanName、别名的封装，BeanDefinition中包含了id、class、name等属性。 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; // 解析元素下的自定义标签 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // 向bean 工厂注册BeanDefinition和bean别名 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderCon-text().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error("Failed to register bean definition with name '" + bdHolder.getBeanName() + "'", ele, ex); &#125; getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125; &#125;&#125; 到这里，我们发现真正将Document元素解析为BeanDefinition的过程是委托给BeanDefinitionParserDelegate处理的，在这个类中我们需要关注两个重点：其一，解析bean元素；其二，解析自定义元素。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class BeanDefinitionParserDelegate &#123; …… /** * 解析&lt;bean&gt;元素 */ public BeanDefinitionHolder parseBeanDefinitionElement(Element ele) &#123; return parseBeanDefinitionElement(ele, null); &#125; /** * 解析&lt;bean&gt;元素 */ public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, @Nullable BeanDefinition containingBean) &#123; // 获取元素的id和name属性 String id = ele.getAttribute(ID_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); List&lt;String&gt; aliases = new ArrayList&lt;&gt;(); if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; // 以id或别名作为bean的名称 String beanName = id; if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &#123; logger.debug("No XML 'id' specified - using '" + beanName + "' as bean name and " + aliases + " as aliases"); &#125; &#125; // 检查bean名称和别名是否已经被注册 if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; // 解析element元素，得到具体的BeanDefinition // 这里不会处理beanName和aliases // TODO：待深入学习 AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, con-tainingBean); // 如果beanDefinition没有指定id和name，则为其生成beanName if (beanDefinition != null) &#123; if (!StringUtils.hasText(beanName)) &#123; try &#123; if (containingBean != null) &#123; beanName = BeanDefinitionReaderUtils.generateBeanName(beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp;beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp;!this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Neither XML 'id' nor 'name' specified - " + "using generated bean name [" + beanName + "]"); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); // 最后，返回一个BeanDefinitionHolder对象，这个对象中持有beanDefinition、beanName、beanAliases return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; return null; &#125; /** * 解析自定义元素 */ public BeanDefinition parseCustomElement(Element ele) &#123; return parseCustomElement(ele, null); &#125; /** * 解析自定义元素 */ public BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) &#123; // 获取元素的命名空间 String namespaceUri = getNamespaceURI(ele); if (namespaceUri == null) &#123; return null; &#125; // 获取相应命名空间的Handler，各个命名空间都有对应的Handler，如ContextNamespaceHandler、AopNamespaceHandler等 NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; // 解析元素 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); &#125;&#125; 到这里，Document的解析就完成了。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【二】IOC容器的初始化（一）Resource定位]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%BA%8C%E3%80%91IOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%88%E4%B8%80%EF%BC%89Resource%E5%AE%9A%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[总览在使用IOC容器之前，需要定义一个Resource来定位容器BeanDefinition的资源文件，Resource类继承关系如下图所示，参考使用XmlBeanFactory 和DefaultListableBeanFactory两个IOC容器时，均使用了ClassPathRescource作为BeanDefinition数据源，如下所示： 1ClassPathResource resource = new ClassPathResource("beans.xml"); 我们常用的ApplicationContext容器为我们提供了一系列加载不同Resource的功能，比如FileSystemApplicationContext、ClassPathXmlApplicationContext、XmlWebApplicationContext等，下面我们以FileSytemXmlApplicationContext为例，看一看ApplicationContext的Resource定位过程。 FileSystemApplicationContext继承自AbstractXmlApplicationContext，IOC容器的功能由其父类实现，其主要是扩展了从文件系统读取BeanDefinition配置文件的功能，体现在覆盖了DefaultResourceLoader的getResourceByPath方法。 在FileSystemXmlApplicationContext的构造方法中，调用了refresh()方法来启动IOC容器的初始化，这是整个IOC容器初始化的入口，具体的调用的过程如下图所示，下面从源码的角度对这个过程进行分析。 源码分析1.refreshrefresh()方法在FileSystemXmlApplicationContext的构造方法中调用，这一方法定义在AbstractApplicationContext中，启动了IOC容器的初始化过程，如下所示： 123456789101112public class FileSystemXmlApplicationContext extends AbstractXmlApplicationContext &#123; /** * 创建一个应用上下文，根据应用环境解析路径，并启动refresh()过程 */ public FileSystemXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125; &#125;&#125; 2.obtainFreshBeanFactoryobtainFreshBeanFactory用于通知子类刷新内部的bean factory，其中调用了refreshBeanFactory方法，这一方法在AbstractApplicationContext中未给出具体实现，留给其子类实现，最终调用的为其子类AbstractRefreshableApplicationContext的refreshBeanFactory方法，代码如下： 123456789101112131415161718192021public abstract class AbstractApplicationContext extends DefaultResourceLoader implements Configu-rableApplicationContext &#123; …… public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; …… // 通知子类刷新内部的bean factory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); …… &#125; &#125; protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug("Bean factory for " + getDisplayName() + ": " + beanFactory); &#125; return beanFactory; &#125; protected abstract void refreshBeanFactory() throws BeansException, IllegalStateException;&#125; 3.refreshBeanFactoryrefreshBeanFactory由AbstractRefreshableApplicationContext类实现，且声明为final方法，不可以被覆盖。在这个方法中，首先判断如果已经创建了beanFactory，则销毁bean并关闭beanFactory，然后创建一个新的DefaultListableBeanFactory作为应用上下文的IOC容器并由当前类对象持有这个beanFactory，同时调用loadBeanDefinitions方法载入BeanDefinition。这里的loadBeanDefinitions是一个抽象方法，留给其子类实现。 1234567891011121314151617181920212223242526public abstract class AbstractRefreshableApplicationContext extends AbstractApplicationContext&#123; …… @Override protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; // 若已创建则销毁bean关闭beanFactory destroyBeans(); closeBeanFactory(); &#125; // 创建一个新的DefaultListableBeanFactory作为应用上下文的IOC容器 try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); // 载入BeanDefinition loadBeanDefinitions(beanFactory); // 由当前类对象持有这个beanFactory synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException("I/O error parsing bean definition source for " + getDisplayName(), ex); &#125; &#125; protected abstract void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException;&#125; 4-5.loadBeanDefinitionsloadBeanDefinitions由AbstractXmlApplicationContext实现，在这个方法中，首先创建了一个XmlBeanDefinitionReader对象，并将这个reader回调给由父类创建的DefaultListableBeanFactory对象，然后对reader进行了一系列配置，最后调用了reader的loadBeanDefinitions方法，代码如下所示： 123456789101112131415161718192021222324252627public abstract class AbstractXmlApplicationContext extends AbstractRefreshableConfigApplication-Context &#123; …… @Override protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // 为给定的beanFactory创建一个XmlBeanDefnitionReader XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // 用当前上下文的资源加载环境配置reader beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 初始化reader initBeanDefinitionReader(beanDefinitionReader); // 启动beanDefinition的加载 loadBeanDefinitions(beanDefinitionReader); &#125; protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; Resource[] configResources = getConfigResources(); if (configResources != null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; reader.loadBeanDefinitions(configLocations); &#125; &#125;&#125; 注： 1beanDefinitionReader.setResourceLoader(this); 将这个ApplicationContext对象作为了reader的ResourceLoader，根据之前的分析我们能够知道，AbstractXmlApplicationContext间接继承了DefaultResourceLoader，而DefaultResourceLoader又实现了ResourceLoader接口，所以整个继承关系中的ApplicationContext类均为ResourceLoader类型的实例，在最后调用resourceLoader的getResource方法时实则调用了ApplicationContext的getResourceByPath方法，这就是为什么FileSystemXmlApplicationContext重写了getResourceByPath方法就可以实现从文件系统读取XML格式的配置文件。 6.loadBeanDefinitions这一步调用了XmlBeanDefinitionReader父类AbstractBeanDefinitionReader的loadBeanDefinitions方法，这里有一系列loadBeanDefinitions方法的重载，在最终的调用方法中我们可以看到，对resourceLoader的类型进行了判断，如果resourceLoader是ResourcePatternResolver类型的实例则以通配符模式定义的路径定位资源，否则直接通过路径定位资源。 这里的resourceLoader正是上一步为reader设置的ApplicationContext实例，如下图所示： AbstractAppliactionContext实现了ResourcePatternResolver接口，作为ResourcePatternResolver类型的resourceLoader实例对象使用，并调用了getResources方法来获得Resource资源对象，代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public abstract class AbstractBeanDefinitionReader implements EnvironmentCapable, BeanDefinitionReader &#123; …… @Override public int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException&#123; Assert.notNull(resources, "Resource array must not be null"); int counter = 0; for (Resource resource : resources) &#123; counter += loadBeanDefinitions(resource); &#125; return counter; &#125; @Override public int loadBeanDefinitions(String location) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(location, null); &#125; public int loadBeanDefinitions(String location, @Nullable Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException("Cannot import bean definitions from location [" + location + "]: no ResourceLoader available"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // 通配符模式匹配方式 try &#123; Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Loaded " + loadCount + " bean definitions from location pattern [" + location + "]"); &#125; return loadCount; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException("Could not resolve bean definition resource pattern [" + location + "]", ex); &#125; &#125; else &#123; // 通过绝对路径获取单个资源 Resource resource = resourceLoader.getResource(location); int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Loaded " + loadCount + " bean definitions from location [" + location + "]"); &#125; return loadCount; &#125; &#125; @Override public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, "Location array must not be null"); int counter = 0; for (String location : locations) &#123; counter += loadBeanDefinitions(location); &#125; return counter; &#125;&#125; 这里调用的getResources方法是定义在ResourcePatternResolver接口中的方法，具体由PathMatchingResourcePatternResolver类实现，在AbstractApplicationContext中持有PathMatchingResourcePatternResolver实例，因此这一过程中调用的getResources实际为PathMatchingResourcePatternResolver对象的getResources方法。 7.getResourcesgetResources方法由PathMatchingResourcePatternResolver实现，代码如下： 123456789101112131415161718192021222324252627282930public class PathMatchingResourcePatternResolver implements ResourcePatternResolver &#123; …… @Override public Resource[] getResources(String locationPattern) throws IOException &#123; Assert.notNull(locationPattern, "Location pattern must not be null"); if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) &#123; // 类路径资源，可能有多个资源文件 if(getPathMatcher().isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) &#123; // 获取所有可匹配该包含’?’或’*’的类路径模式的资源 return findPathMatchingResources(locationPattern); &#125; else &#123; // 获取所有给定的类路径资源 return findAllClassPathResources(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length())); &#125; &#125; else &#123; int prefixEnd = (locationPattern.startsWith("war:") ? locationPattern.indexOf("*/") + 1 :locationPattern.indexOf(':') + 1); if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) &#123; // 获取所有可匹配该包含’?’或’*’的类路径模式的资源 return findPathMatchingResources(locationPattern); &#125; else &#123; // 获得给定路径的单个资源 return new Resource[] &#123;getResourceLoader().getResource(locationPattern)&#125;; &#125; &#125; &#125;&#125; 8.getResource最终调用了resourceLoader的getResource方法，并在其中调用了getResourceByPath方法。如下为DefaultResourceLoader的实现，但在FileSystemXmlApplicationContext的实现中，实际上调用了被覆盖的getResourceByPath方法，从而实现了从文件系统读取资源文件的功能。 1234567891011121314151617181920212223242526272829303132333435public class DefaultResourceLoader implements ResourceLoader &#123; …… @Override public Resource getResource(String location) &#123; Assert.notNull(location, "Location must not be null"); for (ProtocolResolver protocolResolver : this.protocolResolvers) &#123; Resource resource = protocolResolver.resolve(location, this); if (resource != null) &#123; return resource; &#125; &#125; if (location.startsWith("/")) &#123; return getResourceByPath(location); &#125; else if (location.startsWith(CLASSPATH_URL_PREFIX)) &#123; return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); &#125; else &#123; try &#123; // 尝试将路径解析为URL路径 URL url = new URL(location); return (ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlRe-source(url)); &#125; catch (MalformedURLException ex) &#123; // 非URL路径，以普通路径形式解析 return getResourceByPath(location); &#125; &#125; &#125; protected Resource getResourceByPath(String path) &#123; return new ClassPathContextResource(path, getClassLoader()); &#125;&#125; 至此，FileSystemXmlApplicationContext就完成了FileSystemResource的定位工作，有了这个Resource，下一步就可以进行BeanDefinition的载入和注册过程了。 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习【一】初识IOC容器]]></title>
    <url>%2F2019%2F08%2F24%2FSpring%E6%BA%90%E7%A0%81%2FSpring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E3%80%90%E4%B8%80%E3%80%91%E5%88%9D%E8%AF%86IOC%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[IOC和DIIOC（Inversion Of Control）：控制反转，是Spring的核心。所谓控制反转，就是将对象的创建和管理交由Spring容器控制，这是一种重要的面向对象设计思想，能够帮助我们设计出低耦合的程序。 DI（Dependency Injection）：依赖注入。在运行期间，动态地为对象注入其所依赖的对象，提高组件的复用，提高程序的灵活性和可扩展性。 控制反转和依赖注入是对同一概念的不同描述，控制反转以容器的角度描述，而依赖注入则是以应用程序的角度描述，这两种说法殊途同归，分离了对象和其所依赖的资源，使得程序更加灵活，为我们提供了重要的面向对象设计思想。 Spring的IOC容器设计Spring中有两个系列的容器： 实现BeanFactory接口的简单IOC容器，这些容器提供了IOC容器的基本功能。 实现ApplicationContext接口的应用上下文，这些应用上下文不仅提供了IOC容器的基本功能，而且提供了一些高级功能，是IOC容器的高级形式。 IOC容器接口设计图如下图所示，Spring设计了如此之多的IOC容器接口，一方面可以通过接口的叠加来扩展IOC容器的功能，另一方面可以方便特定容器的定制实现。 BeanFactory系列容器接口从上图可以看到，BeanFactory是IOC容器接口中最顶层的接口，定义了IOC容器的基本规范。BeanFactory共有三个直接的子类：ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory。 ListableBeanFactory接口表示Bean是可列表化的。 HierarchicalBeanFactory接口表示Bean是有继承关系的，可以管理父IOC容器。 AutowireCapableBeanFactory接口表示Bean是自动装配的。 从上图中可以看到，BeanFactory系列接口中一个主要的继承路径就是从BeanFactory到ConfigurableListableBeanFactory。在HierarchicalBeanFactory接口的基础上，扩展了对BeanFactory的配置功能，如设置父IOC容器、配置Bean后置处理器等。 BeanFactory接口定义了IOC容器最基本的形式，这些功能的定义可以在BeanFactory接口中看到，通过这一系列的接口方法，可以实现不同的IOC容器，接口代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public interface BeanFactory &#123; /** * 转义符号，用于获取FactoryBean本身（即用于生产和管理Bean的Bean） * 在Spring中，所有的Bean都是有BeanFactory进行管理的，而BeanFactory是一个特殊的FactoryBean * 通过getBean(&amp;factoryBeanName)会返回名为factoryBeanName的FactoryBean */ String FACTORY_BEAN_PREFIX = "&amp;"; /** * 根据名字获取指定的Bean实例，此方法使Spring BeanFactory可以当做单例或原型模式来使用 * Bean的别名会被翻译为规范的Bean名称，如果在工厂实例中找不到对应的Bean，则会询问父工厂 */ Object getBean(String name) throws BeansException; /** * 根据指定的名字获取Bean实例，并根据Class类型对Bean进行类型检查 * 当Bean的类型与requiredType不一致时会抛出BeanNotOfRequiredTypeException */ &lt;T&gt; T getBean(String name, @Nullable Class&lt;T&gt; requiredType) throws BeansException; /** * 根据指定的名字获取Bean实例，可以指定创建Bean时需要的构造参数，且会覆盖BeanDefinition * 中的默认参数，参数仅用于创建新实例 * 当给定了构造参数但Bean不是原型作用域时，会抛出BeanDefinitionStoreException * 原因是Spring中Bean默认的作用域是容器内的单例，要想在同一个容器中使用不同的Bean实例，则需要为 * Bean指定原型作用域(scope="prototype") */ Object getBean(String name, Object... args) throws BeansException; /** * 根据指定的名字获取Bean实例，可以指定创建Bean时需要的构造参数，且会覆盖BeanDefinition * 中的默认参数，参数仅用于创建新实例 */ &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException; /** * 返回与给定对象类型唯一匹配的bean实例，可指定Bean的构造参数 * 当匹配到多个Bean时会抛出NoUniqueBeanDefinitionException * 当给定了构造参数但Bean不是原型作用域时，会抛出BeanDefinitionStoreException */ &lt;T&gt; T getBean(Class&lt;T&gt; requiredType, Object... args) throws BeansException; /** * 是否存在给定名称的Bean * 注意：由于BeanDefinition的具体或抽象、懒加载或饿加载、作用域的不同，该方法返回true不代表 * getBean(String name)会获得一个Bean实例 */ boolean containsBean(String name); /** * 这个Bean是否对应于一个单例 * 注意：由于Bean的作用域有单例（singleton）、原型（prototype）、会话（session）、请求（request） * 等，该方法返回false只代表Bean是非单例的 */ boolean isSingleton(String name) throws NoSuchBeanDefinitionException; /** * 这个bean是否总是提供独立的实例 * 注意：由于Bean的作用域有单例（singleton）、原型（prototype）、会话（session）、请求（request） * 等，该方法返回false只代表Bean是非原型的 */ boolean isPrototype(String name) throws NoSuchBeanDefinitionException; /** * 检查给定名称的Bean是否与指定类型匹配 */ boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionEx-ception; boolean isTypeMatch(String name, @Nullable Class&lt;?&gt; typeToMatch) throws NoSuchBeanDefinition-Exception; /** * 获得给定名称的Bean的Class类型 */ Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException; /** * 获得给定名称的Bean的别名 */ String[] getAliases(String name);&#125; BeanFactory接口只定义了IOC容器的基本行为，忽略了IOC容器的具体实现，要知道工厂是如何生产和管理对象的，就需要深入到具体IOC容器的实现，DefaultListableBeanFactory、XmlBeanFactory等就是基本IOC容器的具体实现，下面以XmlBeanFactory为例看看IOC容器的简单实现。 XmlBeanFactory是一个简单的IOC容器的实现，它继承自DefaultListableBeanFactory。Spring中将DefaultListableBeanFactory作为一个默认的功能完整的IOC容器使用，XmlBeanFactory在DefaultListableBeanFactory的基础上扩展了读取以XML格式定义的BeanDefinition（Spring中描述Bean的类）的功能，XmlBeanFactory源码如下所示： 12345678910111213141516171819202122public class XmlBeanFactory extends DefaultListableBeanFactory &#123; /** * XmlBeanDefinitionReader用于处理以XML文件格式定义的BeanDefinition */ private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this); /** * 根据给定的Resource创建一个XmlBeanFactory * Resource是Spring用来封装I/O操作的类 */ public XmlBeanFactory(Resource resource) throws BeansException &#123; this(resource, null); &#125; /** * 根据给定的Resource和父工厂创建一个XmlBeanFactory，并使用XmlBeanDefinitionReader对象 * 加载BeanDefinitions */ public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException &#123; super(parentBeanFactory); this.reader.loadBeanDefinitions(resource); &#125;&#125; 下面尝试使用XmlBeanFactory，代码如下： 12ClassPathResource resource = new ClassPathResource("beans.xml");XmlBeanFactory factory = new XmlBeanFactory(resource); 可见XmlBeanFactory的使用是非常简单的，但这个类已经在Spring3.1中被标明废弃。XmlBeanFactory继承自DefaultListableBeanFactory，是对后者的功能扩展，我们可以通过编程直接使用后者来达到前者的功能，代码如下： 1234ClassPathResource resource = new ClassPathResource("beans.xml");DefaultListableBeanFactory factory = new DefaultListableBeanFactory();XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory);reader.loadBeanDefinitions(resource); 以上代码使用了DefaultListableBeanFactory这一功能功能完整的IOC容器，主要分为以下四个步骤： 创建IOC容器配置文件的资源，这里使用ClassPathResource，即在ClassPath中寻找资源文件。 创建一个BeanFactory，这里使用了DefaultListableBeanFactory。 创建一个BeanDefinition读取器，这里使用XmlBeanDefinitionReader，用于加载以XML文件格式定义的BeanDefinition，并回调给BeanFactory。 从资源中读取Bean的配置信息，并完成Bean的加载和注册。 ApplicationContext系列容器接口ApplicationContext作为一系列重要的容器产品，一方面继承了BeanFactory基本的IOC容器功能；另一方面，对BeanFactory进行了功能扩展。 如下图所示，ApplicationContext通过继承ApplicationEventPublisher、ResourcePatternResolver、MessageSource、EnvironmentCapable接口，为基本的IOC容器扩展了高级的容器特性，例如： ApplicationEventPublisher：支持应用事件 MessageSource：支持国际化信息源 ResourcePatternResolver： 允许以路径模式定位Resource EnvironmentCapable：应用上下文环境检查 FileSystemXmlApplicationContext和ClassPathXmlApplicationContext是常用的应用上下文，根据名字可以看出二者分别实现了从文件系统和类路径读取以XML格式定义的BeanDefinition的功能，下面以FileSystemXmlApplicationContext为例看一看应用上下文的设计原理。 FileSystemXmlApplicationContext的类继承关系如下图所示。 关于应用上下文的主要功能已经在其父类AbstractXmlApplicationContext中实现了，而FileSystemXmlApplicationContext主要进行了两方面的功能扩展： 1.构造应用上下文实例，同时启动IOC容器的refresh()过程，代码如下 12345678910/** * 创建一个应用上下文，根据应用环境解析路径，并启动refresh()过程 */public FileSystemXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125;&#125; refresh()中具体的处理过程已经定义在AbstractApplicationContext中，在子类应用上下文中只需要显式调用即可。refresh()中进行了刷新准备、创建BeanFactory、注册消息源等一系列操作。 2.定义从文件路径加载XML资源文件的方法，代码如下： 12345678910/** * 通过文件系统路径解析资源文件 */@Overrideprotected Resource getResourceByPath(String path) &#123; if (path.startsWith("/")) &#123; path = path.substring(1); &#125; return new FileSystemResource(path);&#125; FileSystemXmlApplicationContext重写了DefaultResourceLoader中的getResourceByPath(String path)方法，提供了通过文件系统路径定位资源文件的功能。在DefaultResourceLoader中，默认实现是通过ClassPath加载资源文件的，代码如下所示： 123protected Resource getResourceByPath(String path) &#123; return new ClassPathContextResource(path, getClassLoader());&#125; 参考资料：《Spring技术内幕》 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot多模块项目打包问题--存在依赖但却无法发现符号]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%2FSpringBoot%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85%E9%97%AE%E9%A2%98--%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E4%BD%86%E5%8D%B4%E6%97%A0%E6%B3%95%E5%8F%91%E7%8E%B0%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[转载自：【SpringBoot错误笔记】springboot多模块项目mvn打包遇到的问题 - 存在依赖但却无法发现符号 这是一个什么问题呢？我来阐述一下，问题大致是这么一个情况：我有一个SpringCloud项目，每个微服务都是一个SpringBoot工程，其中有一个payment项目依赖了一个公共的模块common项目。payment项目和common项目都同属一个父工程的子module 此时我想要把项目打成jar包，部署到服务器上运行 首先我肯定输入mvn clean install -DskipTests=true将common模块进行打包到本地仓库中 然后我再对payment项目进行打包mvn clean package -DskipTests=true 然后mvn命令error （找不到符号），即payment找不到common里的类，所以报错，无法打包 解决方案： 去掉common项目pom.xml中自动配置的spring-boot-maven-plugin插件，即如下的配置节点： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 通过该插件打出jar包不同于直接使用maven插件打出的jar包。当某一个项目只作为一个公共的依赖时，去掉springboot的maven插件即可。 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Maven</tag>
        <tag>打包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot项目打包--提示没有主清单文件]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%2FSpringBoot%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85--%E6%8F%90%E7%A4%BA%E6%B2%A1%E6%9C%89%E4%B8%BB%E6%B8%85%E5%8D%95%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[项目打包为Jar后，通过java -jar xxxxx.jar运行时提示xxxxx.jar中没有主清单属性，如下： 打开jar包，META-INF目录下的MANIFEST.MF，内容如下： 12345Manifest-Version: 1.0Archiver-Version: Plexus ArchiverBuilt-By: greedystarCreated-By: Apache Maven 3.2.5Build-Jdk: 1.8.0_181 我们发现这里没有主类等信息，是什么原因导致的呢？网上大多数资料指出需要在pom.xml中配置maven插件，如下： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 这种解决方案通常可以解决大部分问题，但这种方案只在使用 spring-boot-starter-parent 为 标签内容时才有效，当我们使用自定义的节点时按如上所述的方式配置maven插件则是无效的，这是为什么呢？让我们一起看一看 spring-boot-starter-parent 中的配置。 spring-boot-starter-parent 中maven插件的配置如下： 1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;mainClass&gt;$&#123;start-class&#125;&lt;/mainClass&gt; &lt;/configuration&gt;&lt;/plugin&gt; 我们可以看到这里配置了主类信息以及一个重要的标签，对repackage的描述如下： Repackages existing JAR and WAR archives so that they can be executed from the command line using java -jar. 看到这里我们就清楚了，当使用自定义的 parent 时，我们需要自行配置maven插件的属性，如下： 123456789101112131415&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; mvn clean package指令打包jar包后看一下清单文件，内容如下： 12345678910Manifest-Version: 1.0Archiver-Version: Plexus ArchiverBuilt-By: greedystarStart-Class: cn.bimart.scf.bc.tx.server.TxServerApplicationSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Spring-Boot-Version: 2.1.1.RELEASECreated-By: Apache Maven 3.2.5Build-Jdk: 1.8.0_181Main-Class: org.springframework.boot.loader.JarLauncher 这样项目就打包成功了，通过java -jar也可以正确运行了。 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Maven</tag>
        <tag>打包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记【四】多数据源配置]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%90%E5%9B%9B%E3%80%91%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置首先，在application配置文件中添加多个数据数据源，如下： 1234567891011121314server: port: 8088spring: datasource: sys: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/spring-boot-demo?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useAffectedRows=true username: root password: fin: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/spring-boot-demo-1?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useAffectedRows=true username: root password: 这里配置了sys和fin两个数据源，分别对应spring-boot-demo和spring-boot-demo-1数据库。 然后，对这两个数据源进行配置，配置类如下： 123456789101112131415161718192021222324252627282930@Configuration@MapperScan(basePackages = "com.greedystar.springbootdemo.modules.fin.dao", sqlSessionTemplateRef = "finSqlSessionTemplate")public class FinDataSourceConfig &#123; @Bean(name = "finDataSource") @ConfigurationProperties(prefix = "spring.datasource.fin") public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); return dataSource; &#125; @Bean(name = "finSqlSessionFactory") public SqlSessionFactory sqlSessionFactory(@Qualifier("finDataSource") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources("classpath:mapper/fin/*Mapper.xml")); return bean.getObject(); &#125; @Bean(name = "finTransactionManager") public DataSourceTransactionManager transactionManager(@Qualifier("finDataSource") DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = "finSqlSessionTemplate") public SqlSessionTemplate sqlSessionTemplate(@Qualifier("finSqlSessionFactory") SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435@Configuration@MapperScan(basePackages = "com.greedystar.springbootdemo.modules.sys.dao", sqlSessionTemplateRef = "sysSqlSessionTemplate")public class SysDataSourceConfig &#123; @Bean(name = "sysDataSource") @ConfigurationProperties(prefix = "spring.datasource.sys") @Primary public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); return dataSource; &#125; @Bean(name = "sysSqlSessionFactory") @Primary public SqlSessionFactory sqlSessionFactory(@Qualifier("sysDataSource") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources("classpath:mapper/sys/*Mapper.xml")); return bean.getObject(); &#125; @Bean(name = "sysTransactionManager") @Primary public DataSourceTransactionManager transactionManager(@Qualifier("sysDataSource") DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = "sysSqlSessionTemplate") @Primary public SqlSessionTemplate sqlSessionTemplate(@Qualifier("sysSqlSessionFactory") SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; &#125; 这里需要注意，在两个数据源的配置中要特别区分DAO接口的包路径和映射文件的路径，当我们使用不同的DAO对象时便会访问不同的数据源。 测试1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = SpringBootDemoApplication.class)public class SpringBootDemoApplicationTests &#123; @Autowired private UserDao userDao; // spring-boot-demo @Autowired private RoleDao roleDao; // spring-boot-demo-1 @Test public void test() &#123; System.out.println(JSON.toJSONString(userDao.findAllList())); System.out.println(JSON.toJSONString(roleDao.findAllList())); &#125; &#125; 控制台打印如下： 可以看到初始化了两个数据源，并访问不同的数据源查询了数据。 源码地址：https://github.com/GreedyStar/SpringBootDemo/tree/sample-4 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Security</tag>
        <tag>JWT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记【三】整合 Security + JWT + 异常处理]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%90%E4%B8%89%E3%80%91%E6%95%B4%E5%90%88%20Security%20%2B%20JWT%20%2B%20%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[添加依赖Spring Security是后台开发中经常使用的身份认证和访问权限控制框架，集成起来十分简单，对Restful接口的支持也比较完备，至于更多的介绍，可以参考 Spring Security 参考手册，在pom.xml中添加依赖如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; JWT（Json Web Token）定义了一种简洁的，自包含的信息传递规范，在目前前后端分离的架构环境下使用十分频繁，但JWT也存在一定的局限性，在具体的业务场景下通常无法直接代替通常意义上的session，带着学习的目的，我们可以尝试一下简单的使用，详细介绍可以参考 JWT介绍，在pom.xml中添加依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt;&lt;/dependency&gt; 配置JWTJWT的配置相对来讲是比较简单的，主要包括两个部分：1. 定义Token生成和解析的方法；2. 定义Token验证过滤器，话不多说，直接贴代码： 定义Token的生成和解析 12345678910111213141516171819202122232425262728293031323334353637383940/** * Author GreedyStar * Date 2018/7/18 */public class JwtUtil &#123; /** * 解析Token * * @param jsonWebToken Token String * @param base64Security Base64Security Key * @return */ public static Claims parseToken(String jsonWebToken, String base64Security) &#123; try &#123; Claims claims = Jwts.parser().setSigningKey(base64Security).parseClaimsJws(jsonWebToken).getBody(); return claims; &#125; catch (Exception ex) &#123; return null; &#125; &#125; /** * 生成Token * * @param username 用户名 * @param property 自定义的jwt公共属性（包括超时时长、签发者、base64Security key） * @return */ public static String createToken(String username, JwtProperty property) &#123; Calendar calendar = Calendar.getInstance(); JwtBuilder builder = Jwts.builder() .setHeaderParam("typ", "JWT").setHeaderParam("alg", "HS256") .claim("username", username) .setIssuer(property.getIssuer()) .signWith(SignatureAlgorithm.HS256, property.getBase64Security()) .setExpiration(new Date(calendar.getTimeInMillis() + property.getExpiry())).setNotBefore(calendar.getTime()); return builder.compact(); &#125;&#125; 定义Token验证过滤器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Token验证过滤器 * &lt;p&gt; * Author GreedyStar * Date 2018/7/20 */public class JwtAuthenticationFilter extends OncePerRequestFilter&#123; private JwtProperty jwtProperty; public JwtAuthenticationFilter(JwtProperty jwtProperty) &#123; this.jwtProperty = jwtProperty; &#125; @Override protected void doFilterInternal(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, FilterChain filterChain) throws ServletException, IOException &#123; httpServletResponse.setContentType("application/json"); String authorization = httpServletRequest.getHeader("Authorization"); // 放行GET请求 if (httpServletRequest.getMethod().equals(String.valueOf(RequestMethod.GET))) &#123; filterChain.doFilter(httpServletRequest, httpServletResponse); return; &#125; if (StringUtils.isEmpty(authorization)) &#123; // 未提供Token httpServletResponse.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(403).setMessage("Token not provided").build())); return; &#125; if (!authorization.startsWith("bearer ")) &#123; // Token格式错误 httpServletResponse.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(403).setMessage("Token format error").build())); return; &#125; authorization = authorization.replace("bearer ", ""); Claims claims = JwtUtil.parseToken(authorization, jwtProperty.getBase64Security()); if (null == claims) &#123; // Token不可解码 httpServletResponse.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(403).setMessage("Can't parse token").build())); return; &#125; if (claims.getExpiration().getTime() &gt;= new Date().getTime()) &#123; // Token超时 httpServletResponse.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(403).setMessage("Token expired").build())); return; &#125; // 再进行一些必要的验证 if (StringUtils.isEmpty(claims.get("username"))) &#123; httpServletResponse.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(403).setMessage("Invalid token").build())); return; &#125; filterChain.doFilter(httpServletRequest, httpServletResponse); &#125;&#125; OK，JWT的简单配置就完成了，这里只是对JWT的简单使用，在通常的开发中还需要更复杂的处理逻辑，比如通常的访问Token，刷新Token等，这里就不详细说了。 Security 修改数据库 首先，修改一下数据库表结构，修改之后共有用户表、角色表、用户角色关系表，ER图如下： 角色表里共有两条数据，这两个角色是我们后续进行访问权限控制的基础，如下所示： 修改User类，实现UserDetails接口 UserDetails是Security提供的一个接口，其中定义了一系列用于判断User状态和权限的方法，User实体如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class User extends BaseEntity implements UserDetails &#123; private static final long serialVersionUID = 1L; private String username; private String password; private List&lt;Role&gt; roles; // 从数据库查询出的Role public void setUsername(String username) &#123; this.username = username; &#125; @Override public String getUsername() &#123; return this.username; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override @JsonIgnore public String getPassword() &#123; return this.password; &#125; public List&lt;Role&gt; getRoles() &#123; return roles; &#125; public void setRoles(List&lt;Role&gt; roles) &#123; this.roles = roles; &#125; @Override @JsonIgnore public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; if (roles == null) &#123; return null; &#125; // 将自定义的Role转换为Security的GrantedAuthority List&lt;SimpleGrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); for (Role role : roles) &#123; authorities.add(new SimpleGrantedAuthority(role.getName())); &#125; return authorities; &#125; @Override @JsonIgnore public boolean isAccountNonExpired() &#123; return true; &#125; @Override @JsonIgnore public boolean isAccountNonLocked() &#123; return true; &#125; @Override @JsonIgnore public boolean isCredentialsNonExpired() &#123; return true; &#125; @Override @JsonIgnore public boolean isEnabled() &#123; return true; &#125;&#125; 修改UserService类，实现UserDetailsService接口 这里需要实现UserDetailsService中的loadUserByUsername方法，在这个方法中根据Username查询用户，然后交由Security去匹配用户名和密码（如果需要复杂的用户验证逻辑，可以重写UsernamePasswordAuthenticationFilter，然后将重写的过滤器添加到Security的过滤器链中），UserService代码如下所示： 123456789101112131415161718192021@Service@Transactional(readOnly = true)public class UserService extends BaseService&lt;UserDao, User&gt; implements UserDetailsService &#123; public List&lt;User&gt; findUserList(User user) &#123; return dao.findUserList(user); &#125; public User getUserByName(String username) &#123; return dao.getByUsername(username); &#125; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; User user = dao.getByUsername(username); if (user == null) &#123; throw new UsernameNotFoundException(username); &#125; return user; &#125;&#125; 定义Handler和EntryPoint 因为我们的种子项目是以Restful接口形式提供服务的，所以我们不需要进行页面跳转，而是需要定义一系列的处理器，共包括登录成功、登录失败、注销成功、权限认证这四个处理器，这里就不把代码全部贴出来了。 需要值得注意的是：Security是通过一系列过滤器组成的过滤器链来进行权限控制的，当未登录的用户访问了受权限保护的资源时，会抛出AuthenticationException，默认由LoginUrlAuthenticationEntryPoint处理，也就是默认跳转至登录页面，显然我们需要的是为用户返回一个合理的提示，那么就需要自定义一个处理器处理AuthenticationException，代码如下： 12345678910111213141516/** * 供 &#123;@link ExceptionTranslationFilter&#125; 使用，处理AuthenticationException异常，即：未登录状态下访问受保护资源 * Security默认实现 &#123;@link org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint&#125; * &lt;p&gt; * Author GreedyStar * Date 2018/7/23 */@Componentpublic class AuthEntryPoint implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException &#123; response.setContentType("application/json;charset=UTF-8"); response.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(401).setMessage("Please login").build())); &#125;&#125; 下面为登录失败的handler代码，在这里只简单返回了错误提示： 1234567891011121314/** * 登录失败Handler * &lt;p&gt; * Author GreedyStar * Date 2018/7/20 */@Componentpublic class LoginFailureHandler implements AuthenticationFailureHandler &#123; @Override public void onAuthenticationFailure(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException &#123; httpServletResponse.setContentType("application/json;charset=UTF-8"); httpServletResponse.getWriter().write(JSON.toJSONString(new Response.Builder().setStatus(401).setMessage("Incorrect username or password").build())); &#125;&#125; 自定义加密方式 通常用户密码是要加密存储的，因此我们需要告知Security我们使用了何种加密方式，我们可以通过实现PasswordEncoder接口来实现加密和认证，本例采用简单的MD5加密，如下所示： 12345678910111213141516171819202122232425262728293031public class CustomPasswordEncoder implements PasswordEncoder &#123; @Override public String encode(CharSequence charSequence) &#123; StringBuffer buf = new StringBuffer(""); try &#123; MessageDigest md = MessageDigest.getInstance("MD5"); md.update(charSequence.toString().getBytes()); byte b[] = md.digest(); int i; for (int offset = 0; offset &lt; b.length; offset++) &#123; i = b[offset]; if (i &lt; 0) i += 256; if (i &lt; 16) buf.append("0"); buf.append(Integer.toHexString(i)); &#125; String str = buf.toString(); return (str.substring(10, str.length()) + str.substring(0, 10)); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return buf.toString(); &#125; @Override public boolean matches(CharSequence charSequence, String s) &#123; return encode(charSequence).equals(s); &#125;&#125; Security配置类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private LoginSuccessHandler loginSuccessHandler; // 登录成功处理器 @Autowired private LoginFailureHandler loginFailureHandler; // 登录失败处理器 @Autowired private LogoutSuccessHandler logoutSuccessHandler; // 注销成功处理器 @Autowired private AuthEntryPoint authEntryPoint; // 权限认证异常处理器 @Autowired private UserService userService; @Autowired private JwtProperty jwtProperty; // jwt属性 @Bean public PasswordEncoder passwordEncoder() &#123; // 密码加密，这里采用了简单的MD5加密，可以根据需要自行配置 return new CustomPasswordEncoder(); &#125; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; // 配置UserService和密码加密服务 auth.userDetailsService(userService).passwordEncoder(passwordEncoder()); &#125; @Override protected void configure(HttpSecurity httpSecurity) throws Exception &#123; httpSecurity .csrf().disable() .authorizeRequests() /* 这里对URL添加访问权限控制时需要注意： 1. hasAuthority要以权限的全称标识，如ROLE_ADMIN，可以自定义权限标识 2. hasRole要以ROLE_开头，且配置权限控制时要省略ROLE_前缀 */ // .antMatchers("/admin/**").hasAuthority("ROLE_ADMIN") // .antMatchers("/user/**").hasAnyAuthority("ROLE_ADMIN", "ROLE_USER") .antMatchers("/admin/**").hasRole("ADMIN") .antMatchers("/user/**").hasAnyRole("ADMIN", "USER") .anyRequest().fullyAuthenticated() .and() .formLogin().loginProcessingUrl("/user/login").successHandler(loginSuccessHandler).failureHandler(loginFailureHandler) .and() .logout().logoutUrl("/user/logout").logoutSuccessHandler(logoutSuccessHandler) .and() .exceptionHandling().authenticationEntryPoint(authEntryPoint); // 配置jwt验证过滤器，位于用户名密码验证过滤器之后 httpSecurity.addFilterAfter(new JwtAuthenticationFilter(jwtProperty), UsernamePasswordAuthenticationFilter.class); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; /* 在这里配置security放行的请求 */ // 统一静态资源 web.ignoring().antMatchers("/**/*.gif", "/**/*.png", "/**/*.jpg", "/**/*.html", "/**/*.js", "/**/*.css", "/**/*.ico", "/webjars/**"); // Druid监控平台 web.ignoring().antMatchers("/druid/**"); // swagger2 web.ignoring().antMatchers("/swagger-ui.html*/**"); web.ignoring().mvcMatchers("/v2/api-docs", "/configuration/security", "swagger-resources"); // 注册请求 web.ignoring().mvcMatchers("/user/signup"); &#125;&#125; 到这里，Security就配置完了，虽然看起来配置很多，但其实使用起来是非常灵活的。 异常处理良好的错误提醒能够极大地提高用户体验，在前后端分离的架构下，前端和后端通常需要确定一套错误提示方案，这时就需要对异常进行统一的处理。 异常处理按我的理解可以分为两种：其一，业务异常处理；其二，全局异常处理。 业务异常处理 这里所说的业务异常处理是指处理在业务处理过程中抛出的异常，比如我们在Controller中抛出异常。对于这些异常，Spring为我们提供了很好的处理方式，我们可以通过@ControllerAdvice注解定义异常处理类，配合@EceptionHandler注解定义异常处理方法，来捕获在Controller中抛出的异常，代码如下： 12345678910111213/** * Author GreedyStar * Date 2018/7/23 */@RestControllerAdvicepublic class CustomExceptionHandler &#123; @ExceptionHandler(CustomException.class) public Response handleException(CustomException exception) &#123; return new Response.Builder().setStatus(500).setMessage(exception.getMessage()).build(); &#125; &#125; 在这里我们根据业务需要配置不同的异常处理方法。 全局异常处理 除了在Controller中抛出的异常，我们通常还会遇到404等异常，SpringBoot为我们提供了一个默认的异常处理方式：即将错误映射至/error路径，想进一步了解可以参考org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController。 123456789101112131415161718192021222324252627282930/** * 全局错误处理 * SpringBoot默认会将异常映射到/error路径，从而根据请求方式返回html或json * 在这个控制器中处理/error路径的请求，将所有异常的返回值进行统一处理 * &lt;p&gt; * Author GreedyStar * Date 2018/7/19 */@RestControllerpublic class GlobalErrorController implements ErrorController &#123; private final String PATH = "/error"; @Autowired private ErrorAttributes errorAttributes; @Override public String getErrorPath() &#123; return PATH; &#125; @RequestMapping(value = PATH, produces = &#123;MediaType.APPLICATION_JSON_VALUE&#125;) public Response handleError(HttpServletRequest request) &#123; Map&lt;String, Object&gt; attributesMap = getErrorAttributes(request, true); return new Response.Builder().setStatus(500).setMessage(attributesMap.get("message").toString()).build(); &#125; protected Map&lt;String, Object&gt; getErrorAttributes(HttpServletRequest request, boolean includeStackTrace) &#123; WebRequest webRequest = new ServletWebRequest(request); return this.errorAttributes.getErrorAttributes(webRequest, includeStackTrace); &#125;&#125; 总结经过以上的配置，我们就完成了简单的访问权限控制和Token认证了，并添加了简单的异常处理，让我们的应用具有更好、更完善的错误提示和更安全的访问控制。 最近在查看JWT资料的时候发现了一篇驳斥JWT自包含、无状态的文章，感觉写的很有道理，推荐给大家 讲真，别再使用JWT了！ 虽然JWT在分布式应用和客户端程序中有很大的便利条件，但也确实存在一些问题使它无法绕过后台缓存状态这一问题，当然，具体的业务场景对应不同的使用方式，最终还是取决于是否适用于业务场景。 源码地址：https://github.com/GreedyStar/SpringBootDemo/tree/sample-3 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Security</tag>
        <tag>JWT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记【二】Druid 监控记录持久化 + 数据库密码加密]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%90%E4%BA%8C%E3%80%91Druid%20%E7%9B%91%E6%8E%A7%E8%AE%B0%E5%BD%95%E6%8C%81%E4%B9%85%E5%8C%96%20%2B%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[上一篇中我们构建了SpringBoot种子项目，整合了Mybatis、Druid、Swagger2，过程中我们发现以下两个问题： application.yml配置文件中的数据库用户密码是明文的，直接将密码以明文的方式写在配置文件中显然是不合适的 Druid监控平台是基于内存的，重启则会丢失监控数据 关于以上两个问题的配置，Druid的Wiki中已经给出了解决方案，下面我们带着以上两个问题进行学习。 监控记录持久化Wiki链接：怎么保存Druid的监控记录 Druid监控记录持久需要配置 spring.datasource.druid.timeBetweenLogStatsMillis 属性，这个表示每隔多长时间将监控记录输出到日志文件中，当 timeBetweenLogStatsMillis &gt; 0 时，Druid会自动进行监控记录的日志输出。 这里的日志输出默认是在com.alibaba.druid.pool.DruidDataSourceStatLoggerImpl中实现的，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public class DruidDataSourceStatLoggerImpl extends DruidDataSourceStatLoggerAdapter &#123; private static Log LOG = LogFactory.getLog(DruidDataSourceStatLoggerImpl.class); private Log logger = LOG; public DruidDataSourceStatLoggerImpl()&#123; this.configFromProperties(System.getProperties()); &#125; /** * @since 0.2.21 */ @Override public void configFromProperties(Properties properties) &#123; String property = properties.getProperty("druid.stat.loggerName"); if (property != null &amp;&amp; property.length() &gt; 0) &#123; setLoggerName(property); &#125; &#125; public Log getLogger() &#123; return logger; &#125; @Override public void setLoggerName(String loggerName) &#123; logger = LogFactory.getLog(loggerName); &#125; @Override public void setLogger(Log logger) &#123; if (logger == null) &#123; throw new IllegalArgumentException("logger can not be null"); &#125; this.logger = logger; &#125; public boolean isLogEnable() &#123; return logger.isInfoEnabled(); &#125; public void log(String value) &#123; logger.info(value); &#125; @Override public void log(DruidDataSourceStatValue statValue) &#123; if (!isLogEnable()) &#123; return; &#125; Map&lt;String, Object&gt; map = new LinkedHashMap&lt;String, Object&gt;(); map.put("url", statValue.url); map.put("dbType", statValue.getDbType()); map.put("name", statValue.getName()); map.put("activeCount", statValue.getActiveCount()); if (statValue.getActivePeak() &gt; 0) &#123; map.put("activePeak", statValue.getActivePeak()); map.put("activePeakTime", statValue.getActivePeakTime()); &#125; map.put("poolingCount", statValue.getPoolingCount()); if (statValue.getPoolingPeak() &gt; 0) &#123; map.put("poolingPeak", statValue.getPoolingPeak()); map.put("poolingPeakTime", statValue.getPoolingPeakTime()); &#125; map.put("connectCount", statValue.getConnectCount()); map.put("closeCount", statValue.getCloseCount()); if (statValue.getWaitThreadCount() &gt; 0) &#123; map.put("waitThreadCount", statValue.getWaitThreadCount()); &#125; if (statValue.getNotEmptyWaitCount() &gt; 0) &#123; map.put("notEmptyWaitCount", statValue.getNotEmptyWaitCount()); &#125; if (statValue.getNotEmptyWaitMillis() &gt; 0) &#123; map.put("notEmptyWaitMillis", statValue.getNotEmptyWaitMillis()); &#125; if (statValue.getLogicConnectErrorCount() &gt; 0) &#123; map.put("logicConnectErrorCount", statValue.getLogicConnectErrorCount()); &#125; if (statValue.getPhysicalConnectCount() &gt; 0) &#123; map.put("physicalConnectCount", statValue.getPhysicalConnectCount()); &#125; if (statValue.getPhysicalCloseCount() &gt; 0) &#123; map.put("physicalCloseCount", statValue.getPhysicalCloseCount()); &#125; if (statValue.getPhysicalConnectErrorCount() &gt; 0) &#123; map.put("physicalConnectErrorCount", statValue.getPhysicalConnectErrorCount()); &#125; if (statValue.getExecuteCount() &gt; 0) &#123; map.put("executeCount", statValue.getExecuteCount()); &#125; if (statValue.getErrorCount() &gt; 0) &#123; map.put("errorCount", statValue.getErrorCount()); &#125; if (statValue.getCommitCount() &gt; 0) &#123; map.put("commitCount", statValue.getCommitCount()); &#125; if (statValue.getRollbackCount() &gt; 0) &#123; map.put("rollbackCount", statValue.getRollbackCount()); &#125; if (statValue.getPstmtCacheHitCount() &gt; 0) &#123; map.put("pstmtCacheHitCount", statValue.getPstmtCacheHitCount()); &#125; if (statValue.getPstmtCacheMissCount() &gt; 0) &#123; map.put("pstmtCacheMissCount", statValue.getPstmtCacheMissCount()); &#125; if (statValue.getStartTransactionCount() &gt; 0) &#123; map.put("startTransactionCount", statValue.getStartTransactionCount()); map.put("transactionHistogram", rtrim(statValue.getTransactionHistogram())); &#125; if (statValue.getConnectCount() &gt; 0) &#123; map.put("connectionHoldTimeHistogram", rtrim(statValue.getConnectionHoldTimeHistogram())); &#125; if (statValue.getClobOpenCount() &gt; 0) &#123; map.put("clobOpenCount", statValue.getClobOpenCount()); &#125; if (statValue.getBlobOpenCount() &gt; 0) &#123; map.put("blobOpenCount", statValue.getBlobOpenCount()); &#125; if (statValue.getSqlSkipCount() &gt; 0) &#123; map.put("sqlSkipCount", statValue.getSqlSkipCount()); &#125; // 省略部分代码 if (statValue.getKeepAliveCheckCount() &gt; 0) &#123; map.put("keepAliveCheckCount", statValue.getKeepAliveCheckCount()); &#125; String text = JSONUtils.toJSONString(map); log(text); &#125; &#125; 可以看到Druid是以Json形式进行日志输出的，具体的数据处理在log(DruidDataSourceStatValue)方法中进行，这个方法也是后续我们需要用到的。 Druid默认的持久化方式是进行文件记录，如果我们想要自定义监控记录的持久化方式则需要自定义StatLogger，参考以上StatLogger的默认实现，我们可以定义一个简单的StatLogger，如下所示： 12345678910public class StatLogger extends DruidDataSourceStatLoggerAdapter implements DruidDataSourceStatLogger &#123; private Logger logger = LoggerFactory.getLogger(StatLogger.class); @Override public void log(DruidDataSourceStatValue statValue) &#123; logger.info("***************************************************"); logger.info(" 监控数据持久化 "); logger.info("***************************************************"); &#125;&#125; 在这里，我们重写了log(DruidDataSourceStatValue)方法，一个简单的StatLogger就定制完成了，下面我需要在dataSource中配置这个statLogger，我们在配置文件中druid节点下加上如下配置： 12time-between-log-stats-millis: 60000stat-logger: 配置过程中发现 stat-logger 对应的是一个DruidDataSourceStatLoggerAdapter对象，而yml配置文件中仅支持基本数据类型和Map、List等类型，查看源码可以发现，在DruidAbstractDataSource类中有如下定义： 1234567891011121314151617protected long timeBetweenLogStatsMillis;protected DruidDataSourceStatLogger statLogger = new DruidDataSourceStatLoggerImpl(); public void setStatLoggerClassName(String className) &#123; Class&lt;?&gt; clazz; try &#123; clazz = Class.forName(className); DruidDataSourceStatLogger statLogger = (DruidDataSourceStatLogger) clazz.newInstance(); this.setStatLogger(statLogger); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(className, e); &#125;&#125; public void setStatLogger(DruidDataSourceStatLogger statLogger) &#123; this.statLogger = statLogger;&#125; 支持直接设置statLogger对象和通过类名设置两种方式，回到配置文件中发现没有类名的这个配置项，这就比较尴尬了，如下： 既然通过配置文件不能够直接配置，那么我们就以配置类的方式来配置Druid数据源，新建一个Druid的配置类，如下所示： 12345678910@Configurationpublic class DruidConfig &#123; @Bean @ConfigurationProperties(prefix = "spring.datasource.druid") public DataSource druidDataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setStatLogger(new StatLogger()); return dataSource; &#125;&#125; 这里用到了@Configuration和@Bean注解，@Configuration就相当于我们写在xml文件中的，@Bean则是，xml是Spring早期的配置形式，从Spring 3.0开始提出了通过Java类进行配置的形式。 其中@ConfigurationProperties表示配置的属性，这里会将配置文件中以spring.datasource.druid为前缀的值映射到DataSource对象的同名属性上，在这个方法中，我们将DatSource的statLogger设置为我们自定义的StatLogger，下面让我们来看一看效果（将时间间隔设置为了10秒）： 从图中可以看到，每隔10秒会执行一次StatLogger中的log方法。 这样，我们就可以参照Druid的默认实现来进行一系列的数据持久化操作了。 数据库密码加密参考使用ConfigFilter 2.数据库密码加密，首先对数据库密码进行加密，得到私钥、公钥和加密后的密码，如下： 123privateKey:MIIBVQIBADANBgkqhkiG9w0BAQEFAASCAT8wggE7AgEAAkEAjRDnoc5cjZnfeQ2mA7G8xtoTsFFTDSlkws9kDQ974n/pHsKr3sFQIPKCTMvt69R9CY+ms2HooppIpdXR0FWCFwIDAQABAkA0la6i5Hgf2NIzH+FY0zKZtcVNHqOk7l8/N2wGalU18wa1AGwJnPYnsHeTqqxv5AwA9ifqr/72xjmZjQXE9tRRAiEAxorHSILMWJzMwIEjOPA4RE+LfbPYotsfVAszPNR+3K0CIQC14/H89XZtBR2R9+X8kaRwK6Xh8TkSEXLyF2labXyOUwIgB+2YwZt/f3ZbcsB1YJuvE4M9pbpdxzsKyDdeR2qQ2k0CIQCuSePA7jwyLuqsygvYvn4A9fIX1JtJEus/yusquSrW/QIhAID7hqZmohMq/W75Ujkrf/YcQnGDq8e9iVpVFhiinll+publicKey:MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAI0Q56HOXI2Z33kNpgOxvMbaE7BRUw0pZMLPZA0Pe+J/6R7Cq97BUCDygkzL7evUfQmPprNh6KKaSKXV0dBVghcCAwEAAQ==password:CaYks2C7nfXL0rYtFag29XiCaG//f4A/wPjoMvYQDEeZJo/Vr3ZpFHMdeg75CeFQ5dvplmbSU0rGNn4wNGhJtw== 然后修改application.yml配置文件，来支持数据库密码的加密，如下所示： 123password: CaYks2C7nfXL0rYtFag29XiCaG//f4A/wPjoMvYQDEeZJo/Vr3ZpFHMdeg75CeFQ5dvplmbSU0rGNn4wNGhJtw==filters: stat,wall,log4j2,configconnection-properties: config.decrypt=true;config.decrypt.key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAI0Q56HOXI2Z33kNpgOxvMbaE7BRUw0pZMLPZA0Pe+J/6R7Cq97BUCDygkzL7evUfQmPprNh6KKaSKXV0dBVghcCAwEAAQ== 其中password为加密后的数据库密码，config.decrypt.key为公钥。 这里需要注意，一定要在filters中加上config的配置，用于通过别名启动插件，如下： 1filters: stat,wall,log4j2,config 这里表示启动了监控统计、SQL防火墙、日志记录和Config。 Druid的Wiki中指出：有两种配置Filter的方式，一种是配置filters属性，一种是配置proxyFilters属性，这两种配置是组合关系，不是替代关系。 但实际配置过程中发现，如果只配置proxyFilters，如下启动configFilter： 1spring.datasource.druid.filter.config.enabled=true 实际是无法启动configFilter的，需要在filters中通过Filter别名指定使用的插件。 经过以上配置，我们就已经完成了数据库密码加密的配置了，但我们发现，这样实际上是将密文和公钥都写在了配置文件中，这样的配置是否可用呢？ 带着问题回到获得密文这一步，我们使用了druid-x.x.x.jar中的ConfigTools工具进行加密，同样的，我们也可以使用这个工具进行解密，如下所示： 1String password = ConfigTools.decrypt("public key","cipher"); 这样一来，直接将公钥和密文写在配置文件中与明文就没有什么区别了，所以我们可以将公钥放在配置类中，当然也可以通过其他的方式来获取公钥和密文，如下： 1234567891011121314@Configurationpublic class DruidConfig &#123; @Bean @ConfigurationProperties(prefix = "spring.datasource.druid") public DataSource druidDataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setStatLogger(new StatLogger()); Properties properties = new Properties(); properties.setProperty("config.decrypt", "true"); properties.setProperty("config.decrypt.key", "MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAI0Q56HOXI2Z33kNpgOxvMbaE7BRUw0pZMLPZA0Pe+J/6R7Cq97BUCDygkzL7evUfQmPprNh6KKaSKXV0dBVghcCAwEAAQ=="); dataSource.setConnectProperties(properties); return dataSource; &#125;&#125; 经过以上的配置，我们就完成了数据库密码加密的配置，更具体的配置可以参照Druid的Wiki进行学习。 源码地址：https://github.com/GreedyStar/SpringBootDemo/tree/sample-2 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记【一】整合 Mybatis + Druid + Swagger2]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%90%E4%B8%80%E3%80%91%E6%95%B4%E5%90%88%20Mybatis%20%2B%20Druid%20%2B%20Swagger2%2F</url>
    <content type="text"><![CDATA[本文以Maven构建SpringBoot项目，并整合Mybatis、Druid和Swagger2，实现Druid监控和在线API文档的功能。 添加依赖pom.xml中依赖包如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 去掉Spring默认的日志插件 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 热部署 修改classpath下的文件springboot自动重启 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j2 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- api文档 swagger2 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置配置文件Druid、Mybatis和log4j2能够很好的支持SpringBoot，这里直接在配置文件application.yml中对其进行配置，配置项的描述已经在文件中进行了注释，这里就不多说了，application.yml内容如下： 我们可以看到，使用SpringBoot后，需要进行的配置的确变简单了，这就是“习惯优于配置”为我们带来的便利。 从此以后，再也不用对老板说：别急，我马上就要配置完了！ 附：DruidDataSource配置属性列表 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889server: port: 8088spring: datasource: type: com.alibaba.druid.pool.DruidDataSource druid: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/spring-boot-demo?useUnicode=true&amp;characterEncoding=utf8 username: test password: 43997k7k # 初始化时建立的连接数 initial-size: 5 # 最大连接数 max-active: 20 # 最小连接数 min-idle: 5 # 获取连接最大等待时间，单位：毫秒 max-wait: 2000 # 是否缓存preparedStatement pool-prepared-statements: false # 最大preparedStatement缓存数，当pool-prepared-statements=true时需要大于0 max-pool-prepared-statement-per-connection-size: -1 # 检测连接是否失效的sql validation-query: SELECT 'x' # 检测连接是否失效的超时时间，单位：秒 validation-query-timeout: 2 filters: stat,wall,log4j2 # Spring aop监控的包路径 aop-patterns: cn.greedystar.springbootdemo.modules.service.* filter: # 监控统计 stat: enabled: true db-type: mysql # 打印慢sql log-slow-sql: true # 超过200毫秒即为慢sql slow-sql-millis: 200 # sql防火墙 wall: enabled: true db-type: mysql # 对认定的攻击sql进行日志输出 log-violation: true # 对认定的攻击sql抛出异常 throw-exception: true config: # 是否允许下述操作 alter-table-allow: false truncate-allow: false drop-table-allow: false update-where-none-check: true # metadata会暴露数据的表结构 metadata-allow: false # 日志 log4j2: enabled: true # log4j2仅记录druid的sql执行日志 statement-log-enabled: false connection-log-enabled: false result-set-log-enabled: false statement-executable-sql-log-enable: true # 数据库连接池监控统计插件 web-stat-filter: enabled: true url-pattern: /* # 过滤掉如下请求 exclusions: '*.gif,*.png,*.jpg,*.html,*.js,*.css,*.ico,/druid/*' # 数据库连接池监控页面插件 stat-view-servlet: enabled: true url-pattern: '/druid/*' reset-enable: true login-username: admin login-password: admin allow: deny: # 设置cglib代理模式，防止非接口代理出错 aop: proxy-target-class: true # mybatis映射文件路径mybatis: mapper-locations: classpath*:mybatis/*Mapper.xml# 日志配置文件logging: config: classpath:log4j2.xml log4j2配置文件log4j2.xml参考自Druid的官方wiki：Druid中使用log4j2进行日志输出，将日志输出级别改为了INFO，这里就不贴出来了。 到这里，Druid的配置就算完成了。 Mybatis的配置除了在配置文件中指定Mapper映射文件的路径外，还要告知应用程序扫描Mapper接口，有两种方式可以实现： 其一，在应用程序入口类上加上Mapper接口的扫描@MapperScan，并指定Mapper接口的包路径，如下所示： 12345678@SpringBootApplication@MapperScan("cn.greedystar.springbootdemo.modules.dao")public class SpringBootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootDemoApplication.class, args); &#125;&#125; 其二，在Mapper接口类上加上注解@Mapper，如下所示： 1234@Mapperpublic interface UserDao extends BaseDao&lt;User&gt; &#123; List&lt;User&gt; findUserList(User user);&#125; 注意：网上很多资料将以上两种配置方式形容为必须一起使用，这种情况下还是要自己多试一试。 至此，Druid和Mybatis的配置工作就完成了。 配置类这里使用了Spring3.0引入的注解@Configuration，在@Configuration注解的类中可以定义多个由@Bean注解的方法，用于创建Bean，与在配置文件中定义的效果是一样的，本文中使用@Configuration注解配置Swagger2，如下所示： 123456789101112131415161718192021222324252627282930313233343536@Configuration@EnableSwagger2@ComponentScan(&#123;"cn.greedystar.springbootdemo.modules.web"&#125;)public class Swagger2Config &#123; /** * 创建API应用 * apiInfo() 增加API相关信息 * 通过select()函数返回一个ApiSelectorBuilder实例，指定扫描的包路径来定义要建立API的controller目录。 * * @return */ @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("cn.greedystar.springbootdemo.modules.web")) .paths(PathSelectors.any()) .build(); &#125; /** * 创建该API的基本信息（这些基本信息会展现在文档页面中） * 访问地址：http://项目实际地址/swagger-ui.html * * @return */ private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("利用swagger构建api文档") .description("更多请关注 http://blog.csdn.net/greedystar") .termsOfServiceUrl("http://blog.csdn.net/greedystar") .version("1.0") .build(); &#125;&#125; Swagger2的配置中指定了扫描controller的路径，下面我们来看一看controller中如何配置Api文档的数据，在下面这段代码中，我们使用了@ApiOperation和@ApiImplicitParam来配置Api文档的数据，具体如下所示： 123456789101112131415161718192021222324252627@RestController@RequestMapping(value = "/user/")public class UserController &#123; @Autowired private UserService userService; @ApiOperation(value = "获取所有用户列表", notes = "获取所有用户列表") @RequestMapping(value = "list", method = RequestMethod.GET) public Response getAllUser() &#123; List&lt;User&gt; userList = userService.findList(new User()); if (userList == null) &#123; return new Response.Builder().setMessage("no data found").setStatus(404).build(); &#125; return new Response.Builder().setMessage("OK").setStatus(200).setData(userList).build(); &#125; @ApiOperation(value = "获取用户详细信息", notes = "根据id来获取用户详细信息") @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "String", paramType = "path") @RequestMapping(value = "&#123;id&#125;", method = RequestMethod.GET) public Response getUserById(@PathVariable String id) &#123; User user = userService.get(id); if (user == null) &#123; return new Response.Builder().setMessage("no data found").setStatus(404).build(); &#125; return new Response.Builder().setMessage("ok").setStatus(200).setData(user).build(); &#125;&#125; 至此，Swagger2的简单配置就完成了。 测试Druid监控在Druid的监控设置中，我们将监控平台的路径设置为/druid/，下面让我们看一看监控平台的样子，访问监控页面需要输入用户名和密码，这是我们先前配置的，进入监控平台后的页面如下： 在顶级导航栏中我们看到Druid监控平台的主要功能，具体的监控功能还需要进一步学习。 需要指出的是，Druid监控平台是基于内存数据的，在我们使用的过程中需要根据需要进行监控数据的持久化。 日志记录我们在log4j2.xml中配置了日志的记录方式，将日志文件保存在./logs/下，在项目目录下会生成一个logs文件夹，其中按月份组织日志文件，如下所示： 其中druid-sql.log是我们设置的druid sql执行记录，部分内容如下： 123456789101112131415161718192021222324[2018-07-12 18:45:18] DEBUG 137 statementLog - &#123;conn-10005, pstmt-20001&#125; executed. SELECT a.id AS "id", a.name AS "name" FROM user a[2018-07-12 18:46:11] DEBUG 137 statementLog - &#123;conn-10005, pstmt-20000&#125; executed. SELECT a.id AS "id", a.name AS "name" FROM user a[2018-07-12 18:53:27] DEBUG 137 statementLog - &#123;conn-10005, pstmt-20000&#125; executed. SELECT a.id AS "id", a.name AS "name" FROM user a[2018-07-12 18:53:58] DEBUG 137 statementLog - &#123;conn-10005, pstmt-20000&#125; executed. SELECT a.id AS "id", a.name AS "name" FROM user a 在线API文档界面如下图所示： 这里不仅可以查看配置的接口信息，而且可以用于测试接口，我们以/user/list为例进行测试 测试结果如下： 这里的返回结果是进行了封装了统一相应格式，具体的实现请参考源码。 总结SpringBoot为我们提供了简洁的配置方式，可以让开发人员更注重业务的实现。 Druid由阿里开源，是非常优秀的Java数据库连接池，而且具有很强的监控功能，值得我们深入学习。 Swagger2为我们提供了一个简单的在线API文档平台，而且可以进行接口测试，是后端人员的福利工具。 经过一番配置和测试，我们最终完成了SpringBoot整合Mybatis、Druid和Swagger2，搭建了数据源监控、日志记录以及在线Api文档平台，这个项目作为学习的开端，也将会作为以后学习过程中使用的种子项目。 最后，附上源码：https://github.com/GreedyStar/SpringBootDemo/tree/sample-1 SQL就不贴出来了，user表只包含id和name。 最后的最后，安利一下自己写的一个Java代码生成工具，能够方便的生成Spring、SpringMVC、Mybatis架构下的Java代码，希望能对大家有所帮助，地址：Java代码生成器：Generator]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Mybatis</tag>
        <tag>Druid</tag>
        <tag>Swagger2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric ENCChaincode 账本数据AES256加密解密和签名验证]]></title>
    <url>%2F2019%2F08%2F24%2FFabric%2FFabric%20ENCChaincode%20%E8%B4%A6%E6%9C%AC%E6%95%B0%E6%8D%AEAES256%E5%8A%A0%E5%AF%86%E8%A7%A3%E5%AF%86%E5%92%8C%E7%AD%BE%E5%90%8D%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[加密方式AES256分组对称加密是指将明文数据分解为多个16字节的明文块，利用密钥分别对每个明文块进行加密，得到相同个数的16字节密文块，如下图所示： 如果分解后有明文块不足16字节，就需要涉及填充和链加密模式 填充方式由于对明文数据进行了分块，那么就有可能存在分解后的明文块不足128位的情况，这就需要对明文块进行填充。 AES加密支持多种填充方式：NoPadding，PKCS5Padding，ZerosPadding，PKCS7Padding。 其中NoPadding表示不进行填充，这就需要自行检测和控制数据的长度；ZerosPadding表示用0填充缺少的位数； PKCS5Padding和PKCS7Padding的填充方式在实际效果中是相同的，用缺少的位数进行填充，如块长度为11个字节，缺少5个字节，那么就填充5个字节的内容，每个字节的内容为十进制的5，如下图所示： 注意：如果块长度刚好为16字节，则需要在块后补16个字节的数据，每个字节数据为十进制的16，如下所示： ENCChaincode使用了PKCS7Padding填充方式。 加密方式ECB模式： CBC模式（密码分组连接模式）： CFB模式（密码反馈模式）： ENCChaincode使用了CBC（密码分解连接）模式。 源码解读ENCKEY和DECKEY：用于分组对称加密和解密 1命令 openssl rand -base64 32 ENCKEY=DECKEY=’hJM2KYj33vBq/+3GGybwyFB3chOkNo4lv1swAEMxC3E=’ IV：加密过程中使用的向量，ENCCC例子使用了CBC模式，IV需要提供给链码，若不提供则会随机生成，但如果背书策略指定需要由多个节点进行背书，那么就必须提供唯一的IV，否则节点在背书时会出现读写冲突。 1命令 opensslrand -base64 16 IV=’ST56TUR9CYY+NZ41sorYVg==’ SIGKEY和VERKEY：用于签名和验证 1命令 openssl ecparam -nameprime256v1 -genkey | tail -n5 | base64 -w0 SIGKEY=VERKEY=’LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUtKRzhzMnlqNzJEcGo3L0o1OHFHQzdHa1R5cXQ1REkwZWJod01GamkxMVZvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFMWlEOUlyU1Ixdi9LOVN6TzVCSjVaUUpIZVdTblIxbE00b21iRTBwZ0NpUml6ZExtZkkyVgp6VE84ZE5PTHNhYlhCZGZyNHJUWDNhSkxzeHE5azBZUm1nPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=’ 链码源文件：fabric/example/chaincode/go/enccc_example/enccc_example.go Encrypter作用：把通过AES256位密钥进行加密的value写入账本 源码分析： 创建加密实体，参数为：ID，bccp实例，加密密钥encKey，IV（可选参数，若不提供则随机创建） 1ent, err:= entities.NewAES256EncrypterEntity("ID", t.bccspInst, encKey, IV) 加密和写入数据 1err= encryptAndPutState(stub, ent, key, cleartextValue) 2.1 加密和写入数据1ciphertext, err := ent.Encrypt(cleartextValue) 2.2 将加密后的value写入账本1stub.PutState(key, ciphertext) Decrypter作用：将账本value读出并通过AES256位密钥进行解密。 源码分析： 创建加密实体，参数为：ID，bccp实例，加密密钥encKey，IV（可选参数，此处示例readme文档中描述：若不提供则随机创建，但与IV的数据结构描述不符） 1ent, err:= entities.NewAES256EncrypterEntity("ID", t.bccspInst, encKey, IV) 读取和解密 1err= getStateAndDecrypt (stub, ent, key, cleartextValue) 2.1 读出key对应的value 1ciphertext, err := stub.GetState(key) 2.2 对value进行解密 1ent.Decrypt(ciphertext) EncrypterSigner作用：对value使用AES256位密钥进行加密和prime256v1标准进行签名，并将value写入账本。 源码分析： 创建加密签名实体，参数为：ID，bccp实例，加密密钥encKey，签名密钥sigKey 1ent, err:= entities.NewAES256EncrypterECDSASignerEntity("ID", t.bccspInst,encKey, sigKey) 对签名数据加密，写入账本 1err= signEncryptAndPutState(stub, ent, key, cleartextValue) 2.1 创建一个签名消息，value作为Payload，加密签名实体的ID作为ID，签名消息数据结构如下图所示： 1msg := &amp;entities.SignedMessage&#123;Payload: value,ID: []byte(ent.ID())&#125; 2.2 利用加密签名实体对SignedMessage进行签名，签名后的信息作为签名消息的Sig字段 1err := msg.Sign(ent) 2.3 序列化SignedMessage 1b, err := msg.ToBytes() 2.4 对序列化的签名信息进行加密并写入账本 1encryptAndPutState(stub, ent, key, b) DecrypterVerify作用：从账本中读取数据，使用AES256位密钥进行解密和prime256v1标准验证签名。 源码分析： 创建加密签名实体，参数为：ID，bccp实例，加密密钥encKey，签名密钥sigKey 1ent, err:= entities.NewAES256EncrypterECDSASignerEntity("ID", t.bccspInst,encKey, sigKey) 读取数据，解密并验证签名 1cleartextValue, err :=getStateDecryptAndVerify(stub, ent, key) 2.1 读取账本数据并解密 1val, err := getStateAndDecrypt(stub, ent, key) 2.2 创建SignedMessage对象msg 1msg := &amp;entities.SignedMessage&#123;&#125; 将序列化的val解码至msg中 1err = msg.FromBytes(val) 2.3 验证签名 1ok, err := msg.Verify(ent) 链码测试使用e2e_cli示例网络结构：一个orderer节点，分属两个Org的四个peer节点。 修改了script.sh脚本，在所有peer节点安装、实例化ENCCC（ENC Chaincode） 测试过程中的ENCKEY、DECKEY、DECKEY1、IV、SIGKEY、VERKEY、VERKEY1已经设置为cli容器的环境变量 Test1：验证加密解密使用ENCKEY将value写入账本： 1peerchaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_CA -C $CHANNEL_NAME -n enccc -c'&#123;"Args":["ENCRYPT","a","100"]&#125;'--transient"&#123;\"ENCKEY\":\"$ENCKEY\",\"IV\":\"$IV\"&#125; 结果：数据可正确加密写入 使用DECKEY读取value： 1peer chaincode query -C $CHANNEL_NAME -n enccc -c '&#123;"Args":["DECRYPT","a"]&#125;' --transient "&#123;\"DECKEY\":\"$DECKEY\"&#125;" 结果：数据正确读出并解密 使用DECKEY1读取value： 1peer chaincode query -C $CHANNEL_NAME -n enccc -c '&#123;"Args":["DECRYPT","a"]&#125;' --transient "&#123;\"DECKEY\":\"$DECKEY1\"&#125;" 结果：由于DECKEY1 not equal ENCKEY，导致解密失败 Test2：验证签名验证使用ENCKEY和SIGKEY将value写入账本： 1peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_CA -C $CHANNEL_NAME -n enccc -c '&#123;"Args":["ENCRYPTSIGN","b","200"]&#125;' --transient "&#123;\"ENCKEY\":\"$ENCKEY\",\"SIGKEY\":\"$SIGKEY\"&#125;" 结果：数据正确签名加密，写入账本 使用ENCKEY和VERKEY读取value： 1peer chaincode query -C $CHANNEL_NAME -n enccc -c '&#123;"Args":["DECRYPTVERIFY","b"]&#125;' --transient "&#123;\"DECKEY\":\"$DECKEY\",\"VERKEY\":\"$VERKEY\"&#125;" 结果：数据正确读出并解密，验证签名通过 使用ENCKEY和VERKEY1读取value： 1peer chaincode query -C $CHANNEL_NAME -n enccc -c '&#123;"Args":["DECRYPTVERIFY","b"]&#125;' --transient "&#123;\"DECKEY\":\"$DECKEY\",\"VERKEY\":\"$VERKEY1\"&#125;" 结果：数据正确读出并解密，签名验证不通过 Test3：验证多节点背书情况下IV的使用测试组织结构如下： Org1：peer0，peer1 Org2：peer0，peer1 背书策略指定需要Org1和Org2各一个peer进行背书，在不提供IV的情况下，可正常运行。 示例程序enccc_example的readme文档中描述IV是AES256分组对称加密的初始化向量，在不提供时会随机创建，导致最终的加密结果不同，多节点背书验证时会无法通过验证，但源码中对IV的描述为：只有不为空时才使用IV。 总结enccc_example作为一个示例链码，为我们提供了一种对账本数据进行加密的解决方案，若要通过加密对数据进行隔离，则需要针对业务进行一定的修改，目前还在根据业务探索如何使用加密进行数据隔离，大家有好的想法阔以私信在下。 签名和验证部分采用了prime256v1标准，但通过测试发现签名和验证需要使用相同的key，具体的签名和验证处理需要进一步研读源码，目前在业务中还未找到此种方式的具体应用场景。 参考资料：对称加密和分组加密中的四种模式(ECB、CBC、CFB、OFB) 注：文中图片来源于网络，如有侵犯请联系在下删除]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric交易的共识流程]]></title>
    <url>%2F2019%2F08%2F24%2FFabric%2FFabric%E4%BA%A4%E6%98%93%E7%9A%84%E5%85%B1%E8%AF%86%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[概述Fabric中提供了Orderer排序节点，作为区块链网络的一种共识机制，提供对交易进行排序的服务。目前，Fabric已发布的版本中提供了一种基于崩溃容错（Crash Fault-Tolerant, CFT）等排序机制。这种机制是通过Kafka实现的，后续版本中会提供基于Raft共识的排序机制。本文不具体关注Orderer的实现机制，而是从整体了解一下Fabric的共识流程。 在讨论Fabric的共识流程前，首先需要对Fabric的交易流程有一定的了解。Fabric中简化的交易流程如下图所示： 具体的描述可以参考Fabric官方文档： Peers 在Fabric中，交易可以分为两类，一类是查询交易，用于账本查询，不更新账本数据；另一类是更新交易，用于修改账本中的数据。很显然，查询交易只需要单个Peer参与即可，不需要进行排序共识的，而更新交易（下文简称交易）需要通常需要多个Peer参与（同一Channel中），在这种情况下，排序共识就会起到作用。 共识流程交易的共识包括3个阶段的处理：提议阶段、打包阶段和验证阶段，下面结合交易流程，分别介绍各个阶段。 提议阶段提议阶段我们可以理解为背书阶段，这一阶段可以分为三个步骤，如下： 用户通过Application（封装了Fabric SDK的客户端应用程序）构造出交易提议，交易提议中包含欲执行的Chaincode和函数名，背书节点列表（与具体的Chaincode背书策略有关，包含在同一个Channel中）等数据，并将交易提议发送至相应的Peer。 各背书节点接收到交易提议后，首先进行一些检查和签名的验证，然后独立地模拟执行指定的Chaincode函数（不将执行结果写入本地账本），生成一个提议结果，并对结果进行背书，即在结果中添加数字签名并利用私钥对结果进行签名。 将提议结果返回至Application。 当Application收集到足够多的提议结果后，提议阶段完成。 打包阶段打包阶段也就是对交易进行排序的阶段，Orderer节点在这个阶段中起着至关重要的作用，过程如下： Orderer接收到来自于多个Application的交易提议结果 对每个Application提交的交易进行排序，这里值得注意的是排序的规则不是按照Orderer接收到交易的时间，而是按照交易的时间进行排序 将交易分批打包进区块中，形成一个统一的共识结果，这种机制保证了Fabric不会出现账本的分叉 当等待足够时间或区块满足大小后，Orderer将打包好的区块发送给特定Channel中的所有Peer 验证阶段Channel中的节点在接收到Orderer广播的区块后，每个节点都按照相同的方式独立处理接收到的区块，保证账本的一致性，步骤如下： 通过VSCC检查交易是否满足背书策略。 检查账本当前状态是否与提议结果生成时一致。 通过检查的成功交易将被更新到账本中。 构造Event消息，向注册了事件监听的Application通知Event消息。 小结至此，一个交易的三个阶段就走完了，通过这三个阶段共同组成了Fabric的共识流程，并提供了一致性的保障，值得注意的是Fabric中是通过Channel来进行数据隔离的，因此所谓的一致性也是基于Channel考量的。 本文中没有深入的讨论Orderer排序的细节，这些细节Fabric在 A Kafka-based Ordering Service for fabric 一文中进行了详细的介绍，感兴趣的同学可以更深入的学习。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric背书策略相关概念与背书验证过程]]></title>
    <url>%2F2019%2F08%2F24%2FFabric%2FFabric%E8%83%8C%E4%B9%A6%E7%AD%96%E7%95%A5%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%83%8C%E4%B9%A6%E9%AA%8C%E8%AF%81%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[背书策略节点通过背书策略来确定一个交易是否被正确背书。当一个peer接收一个交易后，就会调用与该交易Chaincode相关的VSCC（validator system chaincode实例化时指定的）作为交易验证流程的一部分来确定交易的有效性。为此，一个交易包含一个或多个来自背书节点的背书。 VSCC的任务是验证： 所有的背书是有效的（即有效证书进行的有效签名） 恰当的（满足要求的）背书数量 背书来自预期的背书节点 背书策略即是用于定义2和3的验证规则。 CLI中背书策略语法在CLI中，用一种简单的布尔表达式来表示背书策略。 Fabric使用MSP来描述主体，MSP用于验证签名者的身份和签名者在MSP中的角色、权限。目前支持：member, admin, client和peer。主体的描述形式是MSP.ROLE，其中MSP是MSP ID，ROLE是member，admin，client或peer。 比如一个有效的主体可表示为 ‘Org0.admin’（MSP Org0的管理员）或 ‘Org1.member’（MSP Org1的成员）或 ‘Org0.client（MSP Org0的客户端）或 ‘Org1.peer（MSP Org1的节点）。 CLI语法是：EXPR(E[, E…]) 其中EXPR是AND或OR，表示布尔表达式；E是上面语法所描述的主体或者是另一个嵌套进去的EXPR。 例如： AND(‘Org1.member’, ‘Org2.member’, ‘Org3.member’)表示需要三个主体共同签名背书 OR(‘Org1.member’, ‘Org2.member’)表示需要两个主体之一的签名背书 OR(‘Org1.member’,AND(‘Org2.member’, ‘Org3.member’))表示需要Org1的签名背书或者Org2和Org3共同的签名背书 为chaincode指定背书策略如果在实例化chaincode时未指定背书策略，则背书策略默为“由通道中的组织的任何一个成员进行背书”。例如，一个带有“Org1”和“Org2”的通道将有一个默认的背书策略：OR（“Org1.成员”，“Org.成员”）。 1命令：peerchaincode instantiate -C &lt;channelid&gt; -n mycc -P "AND('Org1.peer','Org2.peer')" 实例化chaincode后添加到通道中的新组织，可以查询chaincode，但将无法提交由其背书的事务。必须修改背书策略，来让由新加入的组织背书的交易得到认可。 背书策略的验证过程 客户端（SDK）把交易提议（TX Proposal）发给指定的一个或多个背书节点(endorsing peer)。 接收提议的背书节点在SDK的交易提议请求中指定，最终进行背书的节点由交易所属的ChainCode和该Chaincode所定义的背书策略（Endorsement Policy）共同决定。 例如node.js sdk的交易提议请求接口：1Channel. sendTransactionProposal(request, timeout) request是一个ChaincodeInvokeRequest对象，可以在该对象中指定目标节点，如果未指定，则会将交易提议请求发送给加入该通道的所有节点。 背书节点收到交易提议后，首先用客户端（SDK）的公钥验证它的签名、客户端是否可以在该channel进行操作、交易是否已被提交、交易提议组织是否正确。验证通过后模拟执行chaincode（不会将结果写入到账本里），将执行的结果反馈给客户端。 客户端（SDK）收到足够多的背书节点的结果后（背书策略），表示这个交易已经正确背书，然后将交易提议、模拟结果和背书信息打包发给orderer节点；如果客户端没有搜集到足够多的背书节点反馈的背书信息，这个交易就会被舍弃。 Orderer节点对来自客户端（SDK）的信息进行排序，并创建区块，然后在channel上进行广播。 channel上的peer节点接收到交易区块后，验证背书策略是否满足，然后更新账本，至此，背书策略的验证过程完成。 原文链接：Docs » Operations Guides » Endorsement policies]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务学习笔记--相关理论和经典解决方案]]></title>
    <url>%2F2019%2F08%2F24%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0--%E7%9B%B8%E5%85%B3%E7%90%86%E8%AE%BA%E5%92%8C%E7%BB%8F%E5%85%B8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言互联网数据井喷式发展使得单机数据库的性能遇到了瓶颈，这时我们通常会对数据库进行分区，即分库分表，在这种情况下，就需要解决分布式数据库的数据一致性问题，即分布式事务。长期以来，分布式事务都是分布式架构的系统中的一个技术难题，下面我们一起来学习一下分布式事务的相关知识。 相关概念ACID特性首先，让我们回忆一下数据库事务的ACID特性： 原子性（Atomicity）：一个事务中的一个或多个数据库操作，要么全部执行成功，要么全部失败，不会出现部分成功部分失败的情况 一致性（Consistency）：并发事务执行前后系统必须都处于一个稳定的状态，不会出现数据不一致的情况 隔离性（Isolation）：并发执行的事务之间不会相互影响 持久性（Durability）：事务一旦执行成功，数据便永久写入数据库 ACID特性是传统的单机数据库事务的特性，用于保证数据库的一致性。 一致性在上面我们提到了一致性问题，这里指的一致性是强一致性，相应的还有弱一致性，即： 强一致性 任何读取数据的操作都能读到最新写入的数据。 弱一致性 数据写入成功后，在后续的读取过程中可能只能读取到部分数据，甚至读取不到，但存在一种特殊情况，即最终一致性，也就是在数据写入成功后，保证在一定的事件内数据达到一致的状态。 CAP定理CAP定理起源于计算机科学家Eric Brewer在2000年的分布式计算原则研讨会（Symposium on Principles of Distributed Computing（PODC））上提出的一个猜想，他指出WEB服务无法同时满足一下3个属性： 一致性（Consistency）：分布式环境中，所有数据的副本在同一时刻是相同的 可用性（Availability）：对于非故障的节点，必须对每一个请求在有限的时间内作出响应 分区容错性（Partition tolerance）：单个节点出现故障，整个系统依然可以提供服务 既然无法同时满足以上3个属性，那么就需要进行取舍： 图表部分参考自：从分布式一致性谈到CAP理论、BASE理论 BASE理论BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的缩写，分别代表： 基本可用：指分布式系统在出现不可预知故障的时候，允许损失部分可用性，但这绝不等价于系统不可用 软状态：允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时 最终一致性：最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态 BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。 解决方案两阶段提交（Two Phase Commitment Protocol，2PC）顾名思义，两阶段提交即是将事务的提交分为两个阶段进行：准备阶段和提交阶段。这里需要引入两个概念：协调者和参与者，在跨行转账业务中，协调者为事务协调器，参与者为转账双方的数据库。 准备阶段： 协调者向所有的参与者发出预提交指令，并等待参与者回答 参与者接收到预提交指令后，执行本地事务，但不进行提交，同时锁定资源。若参与者执行成功，则向协调者反馈可提交，否则，向协调者反馈不可提交 提交阶段： 若协调者收到所有参与者可提交的反馈，则向所有参与者发出提交事务的指令 若协调者收到不可提交的反馈，则向所有参与者发出回滚事务的指令 例子：银行A向银行B转账 1.准备阶段由交易中间件向双方银行系统发出预提交指令，银行A系统执行资金转出操作，银行B系统执行资金转入操作，但均不提交，等待交易中间件的指令。 2.提交阶段分为两种情况：其一，交易中间件收到A、B的可提交反馈，则银行A和B发送提交指令；其二，交易中间件收到不可提交的反馈，则向银行A和B发送回滚指令，如下图所示。 优点：尽量保证了强一致性，但也并非完全的强一致性 缺点：预提交完成后参与者会锁定资源，直到提交或回滚才释放，对性能影响较大 补偿事务（Try Confirm Cancel，TCC）TCC 事务机制实际就是每一个业务操作都对应着一个确认和一个补偿操作，可分为三个处理阶段：Try（初始操作），Confirm（确认操作），Canel（取消操作）。 Try（初始操作） 检测业务资源是否能够满足业务需求 预留业务资源，即对所需的资源加锁 Confirm（确认操作） Try阶段成功后执行Confirm阶段。 Canel（取消操作） Cancel 阶段主要进行数据回滚和资源释放。 例子：银行A向银行B转账 Try阶段：协调者向转账双方银行系统发出预留业务资源的请求，双方系统分别对业务资源进行检查和锁定。 Commit阶段：Try阶段预留操作均成功，则向转账双方系统发出提交请求，双方系统使用Try阶段预留的业务资源执行资金转入和转出操作，若Commit失败则需要重试。 Cancel阶段：Try阶段预留操作出现失败情况，则向转账双方系统发出回滚请求，双方系统取消业务的执行，释放预留的业务资源，若Cancel失败则需要重试。 优点：按业务逻辑锁定部分资源，相比较2PC，能在一定程度上缓解性能问题 缺点：TCC与2PC有着类似的处理流程，是一种位于应用层的处理，需要业务逻辑支持，实现成本高 本地消息表本地消息表的解决方案最早在eBay的论文《Base: An Acid Alternative》提出，主要思想是将分布式事务通过本地消息的方式拆分成本地事务进行处理，即： 在进行业务操作的同时记录消息，并通过本地事务保证业务操作和消息记录的一致性，然后根据本地的消息表来保证分布式事务的BASE理论。 例子：银行A向银行B转账 银行A记录转账消息，并执行资金转出操作（这两个操作需要在同一个本地事务中执行）。 银行A定时扫描本地消息表，将未完成的消息发往银行B。 银行B接收消息后，首先，记录消息；其次，执行资金转入操作；最后，更新消息状态（这三个操作需要在同一个本地事务中执行）。 银行B通知银行A系统更新消息状态。 在这个例子中，还需要注意消息超时重试、幂等性等问题，这就需要在具体的业务场景中不同的实现方式来实现了。 优点：通过本地事务间接实现了最终一致性，实现相对简单 缺点：事务管理与业务处理耦合程度较高 消息队列事务RocketMQ支持事务消息，下面直接以银行A向银行B转账为例说明大致处理过程： 银行A向消息队列发送转账消息，消息状态为Prepared，此消息对消费者（银行B）不可见 消息发送成功后，银行A执行资金转出操作 银行A向消息队列发送确认消息 消息队列根据确认消息将转账消息状态设置为Commited，对消费者可见 银行B取出转账消息 银行B执行资金转入操作 注意： 步骤3操作失败，消息队列会定时扫描队列中的Prepared消息，询问消息发送方，由发送方决定重试或是回滚。 步骤5操作失败意味着消费者没有拿到队列中的消息，这种情况通常由网络超时引起，在这种情况下，消费者会不断尝试从队列取出消息。 步骤6操作失败意味着银行B的处理出现了异常，这时会根据RocketMQ的默认重试策略（重试16次，且重试间隔不断变长，最长为2H）或用户的设置进行重试，这里当然会存在一个问题，比如银行B账户被冻结，这时就需要通知银行A回滚数据，这个功能RocketMQ没有提供，这就需要自行实现了。 优点：不需依赖本地事务，RocketMQ给出了实现 缺点：数据回滚功能需要自行实现，实现难度大，其他主流消息队列不支持事务消息 Sagas事务Sagas事务的基本思想是将分布式系统中的事务分解为多个子事务和与子事务对应的补偿事务，当且仅当所有的子事务都进行了提交，Sagas事务才完成；如果其中一部分子事务执行失败，则必须对已提交的子事务进行补偿。 Sagas事务比较简单的一种形式是通过一个协调者协调各个子事务的执行和回滚， 例子：银行A向银行B转账 事务协调器按子事务顺序，分别向银行A和银行B发送业务处理请求 银行A执行资金转出事务，失败则按子事务执行顺序逆序执行补偿事务 银行B执行资金转入事务，失败则按子事务执行顺序逆序执行补偿事务 总结通过本篇的学习，我们对分布式事务中的CAP定理、BASE理论以及经典的解决方案有了一定的了解。直到今天，分布式事务仍然是一个技术难题，没有任何一种解决方案能够完美解决所有分布式环境中的一致性问题，我们需要具体问题具体分析，根据业务场景和业务需要，选择和设计最适合的解决方案。 参考资料本篇文章参考了多篇前人的优秀博客，一部分概念的介绍直接照搬来了，在此特别感谢博主的分享，参考资料链接如下： 从分布式一致性谈到CAP理论、BASE理论](https://www.cnblogs.com/szlbm/p/5588543.html)聊聊分布式事务，再说说解决方案分布式系统中数据库的事务如何处理？分布式事务：不过是在一致性、吞吐量和复杂度之间，做一个选择]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统：矩阵分解（Matrix factorization）]]></title>
    <url>%2F2019%2F08%2F24%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%EF%BC%88Matrix%20factorization%EF%BC%89%2F</url>
    <content type="text"><![CDATA[问题描述给定用户 - 物品评分矩阵（下文简称评分矩阵） 如下表所示： 这是一个极其稀疏的矩阵，表格中的空白项表示用户未进行评分，我们的任务就是对空白项进行评分预测。 算法概述矩阵分解算法由奇异值分解算法（Singular Value Decomposition, SVD）演变而来，传统的奇异值分解算法只能对数据稠密的矩阵进行分解，而评分矩阵是极度稀疏的，因此，若要使用SVD对评分矩阵进行分解，首先要对矩阵的缺失值进行填充，这样便造成了以下两个问题： 填充缺失数据会极大的增加数据量，导致算法复杂度上升。 填充方法不当会导致数据失真。 由于SVD算法在评分矩阵中不能发挥良好的作用，人们转而研究是否能只考虑已有评分对矩阵进行分解，于是便有了BasicSVD、FunkSVD、SVD++等矩阵分解方法。 BasicSVDBasicSVD是最简单的矩阵分解方法，它将评分矩阵分解为两个低阶矩阵，分别代表用户的隐含特征和物品的隐含特征，如下所示： u 为用户数，i 为物品数，k 为隐含特征数。 通过最小化误差平方和（SSE）得到隐含特征矩阵 p、q，进而通过隐含特征矩阵进行评分预测。 优化目标为最小化SSE，参数为矩阵p、q： FunkSVDFunkSVD（又称RSVD，正则化SVD）在BasicSVD的基础上添加了正则化项，防止过拟合。优化目标为最小化SSE和正则化项之和，参数为矩阵p、q： Baseline estimates &amp; Matrix factorizationBaseline estimates是一种考虑用户评分倾向和物品评分倾向的方法，用户u 对物品i 的预测评分表示如下： 其中， rui 表示用户u 对物品i 的评分预测值，μ 表示已有评分数据的总体平均值，bu 代表用户的评分倾向（偏好），bi 表示物品的评分倾向（偏好）。 例如预测用户u 对物品i 的评分，假设当前已有评分数据的总体平均值为3.5。一方面，u 是一个严苛的用户，他倾向于低于平均值0.3的评分，另一方面，i 是一个热门的物品，它的评分基本高于平均水平0.5分。因此，用户u 对物品i 的预测评分为：3.5 - 0.3 + 0.5 = 3.7。 优化目标为最小化SSE，参数为向量bu 和bi ，表示如下： FunkSVD结合Baseline estimates方法，在用户历史评分的基础上加入对用户、物品偏好的考虑，提高模型预测的精度，此种方法中用户u 对物品i 的预测评分表示为： 优化目标为最小化SSE，参数为向量bu、 bi和矩阵p、q，表示如下： Asymmetric-SVDAsymmetric-SVD（非对称SVD）是对Baseline estimates的改进，该方法引入了用户显式反馈和隐式反馈对预测的影响。在评分数据集中，用户的评分值代表了用户的显式反馈，而用户评分和未评分的操作代表了用户的隐式反馈。Asymmetric-SVD方法将用户的潜在特征替换为用户对感兴趣的物品的显式和隐式反馈，预测评分表示如下： 其中 R(u) 为用户u 的显式反馈（评分）集合，x 为显式反馈物品的权重（相关性），比如预测用户对物品i 的评分，而用户对物品i 的相关物品j 的评分较高，那么认为用户对i 的评分也会比较高，这种方式不会因为考虑物品j 而导致误差增大，因为当物品i、j 较为相似时，rui - buj 接近于0，i 和j 不相似时，xj 接近于0，这样就惩罚了其他预测不准确的情况。 N(u) 为用户u 的隐式反馈集合，y 为隐式反馈物品的权重，u 对j 的隐式偏好将通过y 反应到对i 的预测中，如果j 可以预测i ，那么y 将较大（可通过0或1表示）。 这种方法的用意是：用户的兴趣不仅和评分物品有关，而且和未评分物品有关。 优化目标为最小化SSE，参数为向量bu、bi和矩阵q、x、y，表示如下： SVD++SVD++是对Asymmetric-SVD的改进，进一步简化了Asymmetric-SVD方法，更加直观、高效，预测评分表达为： 优化目标为最小化SSE，参数为向量bu、bi 和矩阵p、q、y，表示如下： 总结矩阵分解是协同过滤算法中应用十分广泛的算法之一，适合用于评分预测推荐领域，这种通过机器学习方法进行评分推荐的算法能够在海量数据中挖掘出用户和物品的潜在特征，是协同过滤推荐算法的热门研究方向。 在设计实验时，矩阵分解算法通常会采用随机梯度下降法来训练模型，需要将损失函数对各个参数求偏导得到参数的更新式，迭代更新参数，直到算法收敛。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>矩阵分解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java开发工具】Generator：Java代码生成工具]]></title>
    <url>%2F2019%2F08%2F24%2FJava%E5%B7%A5%E5%85%B7%2F%E3%80%90Java%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E3%80%91Generator%EF%BC%9AJava%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[欢迎来到 Generator写这个代码生成器工具的想法源自2018年3月份，当时项目组刚完成一个Java Web项目的研发工作，在整个项目过程中耗费了不少的时间来构建SpringMVC的重复性代码和Mybatis的映射文件，同时我也越来越觉得这些重复且难度不大的工作不应当充斥于整个项目周期中，于是开始在网上搜寻Java代码生成器，但看了许多都不太满意于是决定自己写一个出来。 最初的工具是带有简单UI的，虽然使用比较直观，但不易于集成到项目中，往往需要生成代码后再自行复制到项目目录下，这样用起来也比较繁琐，这时大概已经临近5月份了。 后续参与的项目不再是传统的企业软件，于是耽搁了一阵子，工具也没有再使用，直到8月底的时候，突然想重构一下，于是便有了现在这个工具，希望能帮助到一些同学，抱拳.jpg。 Generator 是一款基于数据库表生成相应Java代码的工具，代码模板使用当前主流Java框架： Spring, SpringMVC, Mybatis 组织，能够减少繁琐的重复性工作，让开发人员更专注于技术和性能，提高工作效率和编码热情。 你可以使用Generator： 根据数据库业务表生成实体类 生成包含简单的增、删、查、改操作的Mapper文件 生成Controller、Service、Dao代码 具体请参考使用手册：Generator-Wiki 项目地址：Generator：Java代码生成工具，走过路过的同学给个start吧，抱拳.jpg。]]></content>
      <categories>
        <category>Java - 开发工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>开发工具</tag>
        <tag>代码生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程学习笔记（三）锁]]></title>
    <url>%2F2019%2F04%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E9%94%81%2F</url>
    <content type="text"><![CDATA[分类内部锁 / 显式锁内部锁通常指Synchronized锁。 显式锁通常指Lock接口实现的锁，如ReentrantLock。 公平锁 / 非公平锁一种获取锁的策略。 公平锁指按照线程申请锁的顺序获取锁。 非公平锁指不严格按照申请锁的顺序获取锁，如可按优先级获取锁，可能造成饥饿。 Synchronized 是一个典型的非公平锁。 ReentrantLock 可通过构造方法指定是否为公平锁，默认为非公平锁。 可重入锁 / 不可重入锁可重入锁指线程可以进入它已经获取的锁守护的其他代码块。 不可重入锁指当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会因获取不到而被阻塞。 Synchronized和ReentrantLock都是可重入锁。 互斥锁 / 读写锁互斥锁指一次最多只有一个线程能够占有锁，如Synchronized、ReentrantLock。 读写锁指一个资源可以能够被多个读取线程访问，或被一个写入线程访问，二者不能同时进行，如ReentrantReadWriteLock。 乐观锁 / 悲观锁非具体类型的锁，而是理解并发操作的两个角度。 乐观锁认为不加锁的并发操作是可以容忍的，比如原子类，通过CAS实现原子操作。 悲观锁认为不加锁的并发操作一定是不安全的，如使用内部锁或显示锁。 分拆锁 / 分离锁非具体类型的锁，而是一种对于锁的设计。 分拆锁指当一个锁对应多个独立的的独占资源时，可以考虑为每个独占资源分配一个锁。 分离锁指将一个独占资源分为N份，每份分别对应一个独占锁，如JDK1.7中ConcurrentHashMap的锁分离实现，使用了一个包含16个锁的Array，每个锁对应HashMap的1/16。 偏向锁 / 轻量级锁 / 重量级锁表示内部锁的三种状态，JDK1.6为Synchronized锁引入了锁升级策略，提高了Synchronized锁的性能，这三种锁的状态是通过对象监视器在对象头中的Mark Word字段来表明的。 偏向锁：当一个线程访问同步代码块获取锁时，首先判断MarkWord字段重的偏向线程ID是否为空，为空则表示锁未被访问过，那么就通过CAS操作将自己的ID写入MarkWord中，如果不为空，那么就去判断是否和自己的ID相同，如果相同的话就直接进入同步代码块中，这就是偏向锁和可重入的体现，否则的话则表示这个锁被其他线程访问过，就需要检查持有锁的线程是否存活，如果线程已经终止的话，那么就可以重置偏向，否则的话锁就升级为轻量级锁。 轻量级锁：当一个线程申请的锁为轻量级锁时，线程不会立即阻塞，而是通过自旋和CAS操作尝试获取锁，线程首先会在自己的栈帧中创建一个锁记录，然后，通过CAS操作尝试将MarkWord字段中的锁记录指针指向自己栈帧中的锁记录，如果CAS操作失败，那么需要判断此时锁记录指针是否已经指向自己的锁记录，是的话表示该线程已经持有锁，这也是可重入的表现，否则的话则表示锁由其他线程持有，该线程开始自旋。如果自旋达到一定次数，或者又有其他线程来竞争锁，那么就会升级为重量级锁，所有未获得锁的线程进入阻塞状态。 重量级锁：重量级锁会让其他申请锁的线程进入阻塞，性能降低。 自旋锁自旋锁指申请获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 JDK1.6中引入了自适应自旋锁，它会根据前一次在同一个锁上的自旋时间和锁的拥有者的状态来决定自旋的时间和是否自旋。 内部锁内部锁是由JVM管理的，我们可以通过Synchronized关键字使用内部锁。Synchronized关键字可以用来同步方法或代码块，这也分别代表着不同的同步行为。 同步一个对象 同步一个对象分为两种情况： 其一，类中创建一个对象作为锁对象，如下： 123456Object lock = new Object();public void f1() &#123; synchronized (lock) &#123; &#125;&#125; 其二，使用this指代当前对象，如下： 12345public void f1() &#123; synchronized (this) &#123; &#125;&#125; 在这两种情况下，当多个线程访问同一个对象的f1()方法时锁才会生效。 同步一个方法 123public synchronized void f2() &#123; // Do something&#125; 与同步一个对象作用相同。 同步一个类 12345public void f3() &#123; synchronized (Sync.class) &#123; &#125;&#125; 作用于整个类，当多个线程调用该类的不同对象的f3() 方法时也会进行同步。 同步一个静态方法 123public synchronized static void f4() &#123; &#125; 静态方法为类所属，因此与同步一个类相同。 显示锁java.util.concurrent.locks包中的Lock接口定义了一系列显式锁操作，如下： 1234567891011121314public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 内部锁虽然使用简单，但锁的获取和释放由JVM实现，在无法获得锁时会无限等待，不能进行中断，而显式锁提供了更加灵活的方法，如可响应中断的锁获取方法，可设定超时的锁获取方法等。 显式锁在使用上更加灵活，能够减小锁的粒度，但也特别需要注意将业务处理放在try代码块中，并在finally代码块中释放锁，如下： 1234567891011121314151617181920public void f1() &#123; lock.lock(); try &#123; // Do something &#125; finally &#123; lock.unlock(); &#125;&#125; public void f2() &#123; if (lock.tryLock()) &#123; try &#123; // Do something &#125; finally &#123; lock.unlock(); &#125; &#125; else &#123; &#125;&#125; 减少锁的竞争缩小锁的范围（减少锁持有的时间） 尽可能将与锁无关的代码移出synchronized块，尤其是可能存在阻塞的操作。 减小锁的粒度（减少请求锁的频率） 通常采用分拆锁和锁分离来实现。 分拆锁：当一个锁对应多个独立的的独占资源时，可以考虑为每个独占资源分配一个锁。 锁分离：将一个独占资源分为N份，分别对应一个独占锁。 如ConcurrentHashMap的锁分离实现，使用了一个包含16个锁的Array，每个锁对应HashMap的1/16，虽然锁分离能够提供更好的并发性能，但同时也使得对整个容器的独占访问变得困难，比如需要对Map中的数据进行重排。 使用协调机制代替独占锁，从而允许更强的并发性 条件队列wait()、notify()、notifyAll()都是Object类的本地final方法，构成了条件队列的API。 wait()使当前线程阻塞，前提是必须先获得锁，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll()方法。 notify/notifyAll() 的执行只是唤醒沉睡的线程，而不会立即释放锁，锁的释放要看代码块的具体执行情况。在编程中，尽量在使用了notify/notifyAll()后立即退出临界区，以唤醒其他线程。 notify()方法只唤醒一个等待（对象的）线程并使该线程开始执行。notifyAll()会唤醒所有等待(对象的)线程。 通常用while循环探测某个条件的变化，并根据状态阻塞或唤醒线程。 典型例子生产者–消费者模型如下： 123456789101112131415161718192021222324252627282930313233public class Resources &#123; final int LENGTH = 10; private List&lt;Integer&gt; resources = new LinkedList&lt;&gt;(); public void produce(int product) &#123; synchronized (resources) &#123; while (resources.size() &gt;= LENGTH) &#123; try &#123; resources.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; resources.add(product); System.out.println(Thread.currentThread().getId() + " 生产:" + product); resources.notifyAll(); &#125; &#125; public void consume() &#123; synchronized (resources) &#123; while (resources.size() &lt;= 0) &#123; try &#123; resources.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getId() + " 消费:" + resources.remove(0)); resources.notifyAll(); &#125; &#125; &#125; AbstractQueuedSynchronizerAQS是JDK1.5提供的一个基于FIFO双端队列实现的一个抽象队列式同步器，它定义了一套多线程访问共享资源的同步器框架，许多同步类的实现都依赖于它，比如ReentrantLock、Semaphore、ReentrantReadWriteLock、CountDownLatch、SynchronousQueue、FutureTask。 AQS的核心属性如下： 123private transient volatile Node head; private transient volatile Node tail; private volatile int state; head和tail构成了FIFO的双端阻塞队列，这个队列通过节点间的前后关系构成。 state为同步状态变量，== 0表示没有线程持有该锁，!= 0表示有线程已经持有了该锁 AQS通过基于CAS的Lock-Free算法设置核心属性的值，下面通过ReentrantLock非公平锁来学习一下AQS的实现。 ReentrantLock把所有Lock接口的操作都委派到一个Sync类上，该类继承了AbstractQueuedSynchronizer： 1static abstract class Sync extends AbstractQueuedSynchronizer Sync又有两个子类：NonFairSync和FairSync，分别代表非公平锁（默认）和公平锁。 关注一下NonFairSync的lock()方法，代码如下： 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; 首先通过CAS操作尝试将state从0置为1，若成功则将持有锁的线程设为当前线程，表示当前线程持有了锁；若失败则表示有其他线程已占有锁，调用父类AQS的acquire()方法，代码如下： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; // 尝试获得锁 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 构造Node加到队列并阻塞线程 selfInterrupt(); &#125; 上面的代码中，首先调用tryAcquire()方法尝试获得锁，这个方法的在NonFairSync类中进行了覆盖，调用了nonfairTryAcquire()方法，代码如下： 1234567891011121314151617final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 获得锁的状态 if (c == 0) &#123; // 没有线程持有锁 if (compareAndSetState(0, acquires)) &#123; // 尝试设置锁的状态 setExclusiveOwnerThread(current); // 当前线程作为锁的持有者 return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 已有线程持有锁，且是当前线程 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); // 不通过CAS，直接设置状态，这是偏向锁的体现 return true; &#125; return false; &#125; 在尝试获得锁失败后，AQS会通过addWaiter()方法将Node添加到队列末尾，代码如下： 12345678910111213141516171819202122232425262728private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 获得队列尾节点 if (pred != null) &#123; // 尾节点不空 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; // 把当前节点设为尾节点 pred.next = node; return node; &#125; &#125; enq(node); // 如果设置失败则自旋直到设置成功 return node; &#125; private Node enq(final Node node) &#123; for (;;) &#123; // 一直尝试直到设置成功 Node t = tail; if (t == null) &#123; // 尾节点为空说明头结点也为空，需要初始化头结点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 不空则直接将该节点设置为尾节点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 将Node添加到队列末尾后，AQS会调用acquireQueued()方法将线程阻塞，如下： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 一直尝试 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 当前节点的前驱为头结点，尝试获得锁 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 检查线程（Node）状态 parkAndCheckInterrupt()) // 调用LockSupport.park()阻塞线程 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 到此，加锁的过程就完成了，下面分析解锁的过程： 解锁是通过调用ReentrantLock.unlock()方法触发的，最终调用了AQS的release()方法，如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 尝试释放锁 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); // 唤醒队列中的下一个线程 return true; &#125; return false; &#125; tryRelease()方法在Sync类中进行了覆盖，代码如下： 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; // 计算释放后的state值，由于锁是可重入的，线程多次lock后state的值会&gt;1，需要多次unlock if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // 只有state为0才表示锁释放了 free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; 释放锁成功后，会调用unparkSuccessor()来找到阻塞队列中第一个可以唤醒的线程，通常为head.next。 总结锁是Java并发编程的基础内容，对锁有一定的了解能够构建更好的并发程序，在权衡使用内部锁或显式锁时，要充分考虑使用锁的场景，内部锁由JVM实现，能满足绝大多数使用场景，但如果需要使用可中断、可定时的特性时可以考虑使用显式锁代替内部锁。 参考资料《Java并发编程实战》]]></content>
      <categories>
        <category>Java - 并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程学习笔记（一）基础知识]]></title>
    <url>%2F2019%2F04%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[基本概念并发和并行并发：多个计算任务在同一个CPU内核上进行时间片轮转，从宏观角度来看任务是同时进行的，而实际上多个任务是交替执行的。 并行：多个计算任务在不同的CPU内核上执行，是真正的同时执行。 进程和线程进程：具有一定独立功能的程序关于一个数据集合的一次运行活动，是一个动态概念。进程是并发执行的程序在执行过程中资源分配的基本单位。 线程：线程是进程的一部分，在一个进程中可以同时运行着多个线程，线程是CPU调度的基本单位。 线程状态转换 （1）新建状态（New）：新创建了一个线程对象，尚未启动。 （2）就绪状态（Runnable）：调用了start()方法。该状态的线程位于可运行线程池中，等待获取CPU的使用权。 （3）运行状态（Running）：获取了CPU，执行程序代码。 （4）同步阻塞状态（Blocked）：运行中的线程请求一个由其他线程占有的排他锁，则当前线程进入同步阻塞状态 （5）无限等待阻塞状态（Waiting）：运行中的线程调用wait()方法，进入无限等待阻塞状态。 （6）有限等待阻塞状态（Timed Waiting）：运行中的线程调用sleep()或join()方法，或者发出了I/O请求时，则线程进入有限等待阻塞状态。 （7）死亡状态（Terminated）：线程执行完毕或者因产生异常而结束。 线程的使用继承Thread类123456789public class CustomThread extends Thread &#123; @Override public void run() &#123; // so something &#125;&#125;CustomThread thread = new CustomThread();thread.start(); 实现Runnable接口123456789public class CustomRunnable implements Runnable &#123; @Override public void run() &#123; // so something &#125;&#125;Thread thread = new Thread(new CustomRunnable());thread.start(); 实现Callable接口12345678910111213141516public class CustomCallable implements Callable &#123; @Override public Object call() throws Exception &#123; return null; &#125;&#125;ExecutorService executorService = Executors.newCachedThreadPool();Future future = executorService.submit(new CustomCallable());try &#123; Object o = future.get();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125; 线程池java.util.concurrent包中为我们提供了多钟内置线程池，我们可以通过Executors的静态工厂方法创建线程池，下面一起来看看Java内置的线程池。 FixedThreadPool1ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5); 创建一个定长的线程池，每当提交一个任务就会创建一个线程，直到线程数量达到池的上限。当池中所有线程都处于工作状态，此时提交一个新的任务，则该任务会添加到任务队列中，等待池中的线程可用。 池中的线程会一直存在，如果某一线程由于出现异常而结束，则线程池会补充一个新的线程。 适用于负载较重或可预知工作线程数量的场景。 CachedThreadPool1ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); 创建一个可缓存的线程池，不对池的长度进行任何限制。 线程默认60s未使用则被回收，当提交新任务时首先考虑复用未被回收的空闲线程，其次考虑新增线程。 适用于负载较轻或短耗时异步任务的场景。 SingleThreadPool1ExecutorService singleThreadPool = Executors.newSingleThreadExecutor(); 创建一个单线程化的线程池，池中仅有一个的工作线程来执行任务，如果该线程由于出现异常而结束，则会创建一个新的线程。 工作线程根据任务队列规定的顺序（FIFO，LIFO，Priority）来执行任务。 适用于需要严格保证任务执行顺序的场景。 ScheduledThreadPool1ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); 创建一个定长的线程池，可以设定任务执行的延迟时间，周期性执行任务。 适用于线程周期性执行任务的场景。 WorkStealingPool1ExecutorService workStealingPool = Executors.newWorkStealingPool(); WorkStealingPool底层使用了ForkJoinPool，默认使用当前可以用CPU数，可将大任务分解为多个小任务，提高CPU的利用率。 适用于耗时较长的计算任务，可将任务进行分解，并行计算。 任务队列回到Executors的工厂方法中，我们可以看到线程池的构造方法，例如： 12345678910111213141516171819202122public class Executors &#123; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; &#125; FixedThreadPool和SingleThreadPool默认使用的是一个无限的LinkedBlockingQueue，当频繁提交任务时，任务数大于工作线程数，这时任务就会进入任务队列中，无限的任务队列会跟随任务的提交而增长，这样就有可能导致资源耗尽，可以使用ArrayBockingQueue、有限LinkedBlockingQueue、PriorityBlockingQueue防止资源耗尽。 对于CachedThreadPool，使用了SynchronousQueue绕开队列，将任务直接交给工作线程，SynchronousQueue不是一个队列，而是一种在线程之间交换信息的机制，由于CachedThreadPool是一个无限的线程池，每提交一个任务都会复用或新建一个线程来执行任务，因此使用SynchronousQueue可以减少任务在队列中维护时放入和取出的性能消耗。 饱和策略使用有界阻塞任务队列可能会出现任务队列满的情况，当新提交的任务不能进入任务队列时就需要一种饱和策略对任务进行管理，如下： 12ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(11));threadPoolExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy()); 可以通过ThreadPoolExecutor的setRejectedExecutionHandler接口设置饱和策略。Java中提供了四种饱和策略: （1）AbortPolicy：当新任务不能进入等待队列时，会抛出RejectedExecutionExecption异常，可由调用者捕获，进行相应的处理。 （2）DiscardPolicy：当新任务不能进入等待队列时，会放弃这个任务。 （3）DiscardOldestPolicy：当新任务不能进入等待队列时，会放弃接下来将要执行的任务，如果队列通过优先级排序，则会放弃优先级最高的任务，因此该策略不能同优先级队列同时使用。 （4）CallerRunsPolicy：当新任务不能进入等待队列时，会将一些任务推回给调用者，也就是让调用者线程来执行新任务，这样就使得池线程能够追赶进度，调用者线程在执行新任务时便不会再接受其他的新任务，防止过载时急剧劣化。 ThreadPoolExecutor的默认饱和策略为AbortPolicy。 总结并发编程是Java中经常使用的关键技术，其中，线程池的使用尤为重要，线程池的使用也有一些需要特别注意的问题，如： （1）只有当任务彼此相互独立时，使用有限线程池或有限任务队列才是合理的；当任务相互依赖时，可以使用无限的线程池来防止线程饥饿和死锁。 （2）需要特别注意在线程池中使用ThreadLocal管理数据，因为可能存在线程的复用。 参考资料《Java并发编程实战》 五种线程池的对比与使用]]></content>
      <categories>
        <category>Java - 并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程学习笔记（二）活跃度问题]]></title>
    <url>%2F2019%2F04%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E6%B4%BB%E8%B7%83%E5%BA%A6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在并发编程中，我们经常通过锁来保证线程安全，但使用锁也可能会带来一系列其他的问题，如死锁等问题。我们知道Java虚拟机无法从死锁中恢复，因此了解死锁的发生场景能够让我们在编程过程中尽可能避免死锁的发生。 死锁定义死锁指一组线程中的每个线程都在等待由其他线程占有的因而无法获得的资源，导致线程无法继续推进执行，这里的资源可能是锁，也可能是其他计算机资源，如数据库连接等。 从上面的定义中，我们可以看出死锁的发生有几个必要的条件： 资源独占 不可剥夺 保持申请 循环等待 锁顺序死锁当多个线程试图以不同的顺序获取多个相同的锁时，就可能发生死锁。 考虑A向B转账的业务： 这种是一种很常见的危险情况，比如我们声明如下的一个方法： 1234567public void transfer(Object accountA, Object accountB) &#123; synchronized (accountA) &#123; synchronized (accountB) &#123; // doSomeThing &#125; &#125;&#125; 看起来我们似乎控制了锁的获取顺序，但是由于转账的双方是不确定的，因此依然可能会出现锁顺序引起的死锁，这种情况，可以根据一定策略，动态改变锁的获取顺序，从而保证所有线程获取锁的顺序是一致的，如通过比较对象哈希值，规定加锁顺序，如下： 123456789101112131415public void transfer(Object fromAccount, Object toAccount) &#123; if (fromAccount.hashCode() &gt; toAccount.hashCode()) &#123; synchronized (fromAccount) &#123; synchronized (toAccount) &#123; // doSomeThing &#125; &#125; &#125; else &#123; synchronized (toAccount) &#123; synchronized (fromAccount) &#123; // doSomeThing &#125; &#125; &#125;&#125; 协作对象间的死锁如果一个操作会涉及到多个协作对象，且均需要获取锁，这时就可能导致协作对象间的死锁，一种比较简单的情况即是协作对象间发生锁顺序死锁。 这里指的协作对象可能是不同的功能模块，也有可能是外部方法，当我们持有锁时调用协作对象，就有可能发生死锁。 资源死锁即线程等待的是资源而不是锁，这种情况与获取锁的情况类似，比如申请数据库连接造成死锁。 避免和诊断死锁使用显式锁java.util.concurrent.locks 包中定义了显式锁的接口，提供了比内部锁更灵活的机制，显式锁的接口定义如下： 1234567891011121314public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 通过显式锁，我们能够实现带有定时的锁，在请求一个锁时，如果在一定时间内没有获得到锁则返回获取失败，这样可以避免死锁的发生，具体可参考 ReentrantLock 。 通过线程转储分析死锁我们可以通过良好的程序设计来预防死锁的发生，同时也可以通过 线程转储 来分析运行中的程序是否发生了死锁，以简单的锁顺序死锁为例： 1234567891011121314151617181920212223242526272829303132public class SimpleOrderLockDeadLock &#123; private final Object right = new Object(); private final Object left = new Object(); public void leftRight() &#123; synchronized (left) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (right) &#123; &#125; &#125; &#125; public void rightLeft() &#123; synchronized (right) &#123; synchronized (left) &#123; &#125; &#125; &#125; public static void main(String[] args) &#123; SimpleOrderLockDeadLock deadLock = new SimpleOrderLockDeadLock(); new Thread(() -&gt; deadLock.leftRight()).start(); new Thread(() -&gt; deadLock.rightLeft()).start(); &#125;&#125; 利用编译器的线程转储我们可以看到： Thread-1@625处于阻塞状态，持有对象锁，并等待Thread-0@622释放对象锁 Thread-0@622处于阻塞状态，持有对象锁，并等待Thread-0@622释放对象锁 其他活跃度问题饥饿当线程申请的资源被其他线程永久占用时发生饥饿，比较常见的情况如下： 低优先级线程被饿死，抵制使用线程优先级可以尽可能少的引起饥饿问题 使用SingleThreadExecutor，工作线程执行的任务进入无限期等待，其他的任务永远无法提交到工作线程中而导致被饿死 弱响应性客户端程序通常会在后台线程中处理耗时操作，但后台线程和主线程竞争CPU资源也会影响到程序的响应性。通常情况下，后台线程的优先级要低于主线程。 活锁活锁的情况经常出现在存在重试机制的系统中，当一个任务出现错误时，系统无限进行重试，导致工作线程无法向前推进，可以通过一些策略避免活锁，例如RocketMQ的重试机制。 参考资料《Java并发编程实战》]]></content>
      <categories>
        <category>Java - 并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>活跃度问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于用户的协同过滤算法在显式、隐式反馈数据中的评估比较]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%E5%9C%A8%E6%98%BE%E5%BC%8F%E3%80%81%E9%9A%90%E5%BC%8F%E5%8F%8D%E9%A6%88%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[问题描述实现基于用户的协同过滤（UserCF）算法，以TopN的推荐方式，分别在显式和隐式反馈数据集中进行评估和比较。 实验采用Grouplens团队提供的公开数据集Movielens-latest-small，包括671个用户对9125部电影的100004条评分，并将数据以6比2的比例随机分为训练集和测试集。 隐式反馈只考虑用户是否看过电影，显式反馈考虑用户对电影的评分。 算法描述UserCF算法是一种基于统计学的方法，目标是通过分析用户的历史行为，为用户推荐和他相似的用户喜欢的物品，因此算法中的一个重要内容便是计算用户的相似度。 UserCF算法中相似度的计算是一种近邻模型，中心思想是通过寻找k个近邻用户来模拟主体的行为（KNN），寻找近邻用户需要一个指标来衡量用户间近邻程度，简易的计算方法如下（给定用户u和用户v，N(u)表示用户u喜欢的物品集合，N(v)表示用户v喜欢的物品集合）： 杰卡德相似度 余弦相似度 算法步骤： 1.读取数据，建立用户 – 物品数据结构，如下图所示： 用户A喜欢物品a、b、c，用户B喜欢物品a、c，以此类推。 2.建立物品 – 用户倒排表，如下图所示。目的是在计算相似度时排除那些 |N(u) ∩ N(v)|= 0的数据，只需要扫描倒排表就可以计算出|N(u) ∩ N(v)|≠ 0的用户组合。 3.利用余弦相似度构建相似度矩阵，如用户A和用户B的相似度计算如下： 4.寻找K近邻相似用户。 5.计算用户评分，w表示用户相似度，r表示用户的反馈评分。 6.得出TopN推荐列表。 评价指标通过计算选取不同近邻用户K值时的准确率、召回率和F1值对算法进行评估。 准确率、召回率和F1值的定义请参考 推荐系统发展综述 - 4.推荐方式和效果评估 实验结果实验结果中TopN的N值为选取的用户相似度较大的N个用户作为近邻用户，非最终推荐列表的TopN。 1.隐式反馈 从图中可以看到，当N取18时，F1值最大为0.15，此时召回率为0.23，准确率为0.1，可以看出仅考虑隐式反馈时，通过UserCF算法得到的推荐列表结果并不是很理想。 2.显式反馈 当N取16时，F1值最大为0.2，此时召回率为0.27，准确率为0.17，相比较隐式反馈结果有所提升。 随着N的增大，显式和隐式反馈数据推荐结果的召回率逐渐上升，这是因为所选择的近邻用户越多，为用户推荐的物品就越多，因此召回率会大大增加，而相反，准确率则会逐渐下降。 总结UserCF算法是通过统计学的方法来挖掘用户历史行为数据的规律，隐式反馈数据中所体现的用户行为规律较为粗糙，不利于发现和挖掘，而显示反馈数据能够对用户的行为进行一定的偏好划分，更具有代表性。 因此协同过滤算法通常考虑显式反馈数据，最直观的显式反馈数据是评分数据，常用在音乐、视频服务推荐中。电商平台中的浏览、收藏、加入购物车、购买等行为也可以体现出不同层面的用户偏好，比如购买代表的偏好程度最高，浏览代表的最低，以此分级也可作为显式反馈数据。 参考：项亮. 推荐系统实践[M]. 北京: 人民邮电出版社, 2012.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>协同过滤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统综述：初识推荐系统]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0%EF%BC%9A%E5%88%9D%E8%AF%86%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[引言随着信息技术和互联网技术的发展，人们从信息匮乏时代步入了信息过载时代，在这种时代背景下，人们越来越难从大量的信息中找到自身感兴趣的信息，信息也越来越难展示给可能对它感兴趣的用户，而推荐系统的任务就是连接用户和信息，创造价值。 设想用户想买一本《Recommender Systems An Introduction》，用户只需要走进一家书店，寻找这本书即可。通过互联网，用户可以打开当当，在搜索框中输入书名，然后就可以找到用户想要购买的书籍，这两种方式都需要用户有明确的目的，如购买《Recommender Systems An Introduction》或某一类别的书籍。 但是，当用户没有明确目标时，比如寻找感兴趣的音乐，用户只能通过一些预先设定的类别或标签去寻找他可能感兴趣的音乐，但面对如此之多音乐，用户很难在短时间内找出真正感兴趣的音乐。这时就需要一个自动化的工具，来分析用户曾经收听的音乐，进而寻找出用户可能感兴趣的音乐推荐给用户，这就是个性化推荐系统的工作。 作为一种信息过滤系统，推荐系统具有以下两个最显著的特性： （1）主动化。从用户角度考虑，门户网站和搜索引擎都是解决信息过载的有效方式，但它们都需要用户提供明确需求，当用户无法准确描述自己的需求时，这两种方式就无法为用户提供精确的服务了。而推荐系统不需要用户提供明确的需求，而是通过分析用户和物品的数据，对用户和物品进行建模，从而主动为用户推荐他们感兴趣的信息。 （2）个性化。推荐系统能够更好的发掘长尾信息，即将冷门物品推荐给用户。热门物品通常代表绝大多数用户的兴趣，而冷门物品往往代表一小部分用户的个性化需求，在电商平台火热的时代，由冷门物品带来的营业额甚至超过热门物品，发掘长尾信息是推荐系统的重要研究方向。 目前，推荐系统已广泛应用于诸多领域，其中最典型的便是电子商务领域。同时，伴随着机器学习、深度学习的发展，工业界和学术界对推荐系统的研究热情更加高涨，形成了一门独立的学科。 发展历史推荐系统是互联网时代的一种信息检索工具，自上世纪90年代起，人们便认识到了推荐系统的价值，经过了二十多年的积累和沉淀，推荐系统逐渐成为一门独立的学科在学术研究和业界应用中都取得了很多成果。 1994 年明尼苏达大学GroupLens研究组推出第一个自动化推荐系统 GroupLens[1]。提出了将协同过滤作为推荐系统的重要技术，这也是最早的自动化协同过滤推荐系统之一。 1997 年 Resnick 等人[2]首次提出推荐系统（recommendersystem，RS）一词，自此，推荐系统一词被广泛引用，并且推荐系统开始成为一个重要的研究领域。 1998年亚马逊（Amazon.com）上线了基于物品的协同过滤算法，将推荐系统推向服务千万级用户和处理百万级商品的规模，并能产生质量良好的推荐。 2003年亚马逊的Linden等人发表论文，公布了基于物品的协同过滤算法[3]，据统计推荐系统的贡献率在20%~30%之间[4]。 2005年Adomavicius 等人的综述论文[5] 将推荐系统分为3个主要类别，即基于内容的推荐、基于协同过滤的推荐和混合推荐的方法，并提出了未来可能的主要研究方向。 2006 年10月，北美在线视频服务提供商 Netflix 宣布了一项竞赛，任何人只要能够将它现有电影推荐算法 Cinematch 的预测准确度提高10%，就能获得100万美元的奖金。该比赛在学术界和工业界引起了较大的关注，参赛者提出了若干推荐算法，提高推荐准确度，极大地推动了推荐系统的发展。 2007年第一届ACM 推荐系统大会在美国举行，到2017年已经是第11届。这是推荐系统领域的顶级会议，提供了一个重要的国际论坛来展示推荐系统在不同领域的最近研究成果、系统和方法。 2016年，YouTube发表论文[6]，将深度神经网络应用推荐系统中，实现了从大规模可选的推荐内容中找到最有可能的推荐结果。 近年来，推荐系统被广泛的应用于电子商务推荐、个性化广告推荐、新闻推荐等诸多领域，如人们经常使用的淘宝、今日头条、豆瓣影评等产品。 研究现状经过二十多年的积累和沉淀，推荐系统成功应用到了诸多领域，RecSys会议上最常提及的应用落地场景为：在线视频、社交网络、在线音乐、电子商务、互联网广告等，这些领域是推荐系统大展身手的舞台，也是近年来业界研究和应用推荐系统的重要实验场景。 伴随着推荐系统的发展，人们不仅仅满足于分析用户的历史行为对用户进行建模，转而研究混合推荐模型，致力于通过不同的推荐方法来解决冷启动、数据极度稀疏等问题，国内知名新闻客户端今日头条采用了内容分析、用户标签、评估分析等方法打造了拥有上亿用户的推荐引擎。 移动互联网的崛起为推荐系统提供了更多的数据，如移动电商数据[6]、移动社交数据、地理数据[7]等，成为了社交推荐的新的尝试。 随着推荐系统的成功应用，人们越来越多的关注推荐系统的效果评估和算法的健壮性、安全性等问题。2015年，Alan Said 等人在RecSys会议上发表论[8]，阐述了一种清晰明了的推荐结果评价方式，同年，FrankHopfgartner等人发表论文[9]，讨论了基于流式数据的离线评价方式和对照试验，掀起了推荐算法评估的研究热潮。 近年来，机器学习和深度学习等领域的发展，为推荐系统提供了方法指导。RecSys会议自2016年起开始举办定期的推荐系统深度学习研讨会，旨在促进研究和鼓励基于深度学习的推荐系统的应用。 2017年AlexandrosKaratzoglou等人在论文[10]中介绍了深度学习在推荐系统中的应用，描述了基于深度学习的内容推荐和协同过滤推荐方法，深度学习成为当前推荐系统研究的热点。 推荐方式和效果评估推荐系统在为用户推荐物品时通常有两种方式： 评分预测此方法一般通过学习用户对物品的历史评分，预测用户可能会为他没有进行评分的物品打多少分，通常用于在线视频、音乐等服务的推荐。 评分预测的效果评估一般通过均方根误差（RMSE）和平均绝对误差（MAE）计算。对于测试集T中的一个用户u和物品i，令rui是用户u对物品i的实际评分，而ȓui是推荐系统给出的预测评分，则RMSE定义为： MAE定义为： TopN推荐此方法一般不考虑评分，而是为用户提供一个个性化推荐列表，通过预测用户对物品的兴趣度对列表进行排序，选取其中前N个物品推荐给用户，通常用于电子商务、社交网络、互联网广告推荐。 TopN推荐一般通过准确率（precision）、召回率（recall）和F1值（平衡分数）度量。令R(u)是为用户推荐的物品列表，T(u)是用户在测试集上的行为列表。 召回率定义为： 准确率定义为： F1值定义为： 推荐算法根据推荐系统使用数据的不同，推荐算法可分为基于用户行为推荐、基于内容推荐、基于社交网络推荐等。 主流的推荐系统算法可以分为协同过滤推荐（Collaborative Filtering Recommendation）、基于内容推荐（Content-basedRecommendation）和混合推荐三种。 基于用户行为推荐用户行为蕴藏着很多模式，著名的“啤酒和尿布”的故事就是用户行为模式的良好体现。基于用户行为推荐的主要思想是利用已有用户的历史行为数据（显式反馈或隐式反馈），预测当前用户可能感兴趣的物品，其中显式反馈主要为用户评分，隐式反馈主要包括浏览、搜索等。 基于用户行为的推荐算法也称为协同过滤算法（Collaborative Filtering Recommendation），是推荐领域应用最广泛的算法，该算法不需要预先获得用户或物品的特征数据，仅依赖于用户的历史行为数据对用户进行建模，从而为用户进行推荐。协同过滤算法主要包括基于用户的协同过滤（User-Based CF）、基于物品的协同过滤（Item-Based CF）、隐语义模型（Latent Factor Model）等。其中基于用户和物品的协同过滤是通过统计学方法对数据进行分析的，因此也称为基于内存的协同过滤或基于邻域的协同过滤；隐语义模型是采用机器学习等算法，通过学习数据得出模型，然后根据模型进行预测和推荐，是基于模型的协同过滤。 基于用户的协同过滤（User-Based CF）基于用户的协同过滤（下文简称UserCF）的基本思想为：给用户推荐和他兴趣相似的用户感兴趣的物品。当需要为一个用户A（下文称A）进行推荐时，首先，找到和A兴趣相似的用户集合（用U表示），然后，把集合U中用户感兴趣而A没有听说过（未进行过操作）的物品推荐给A。算法分为两个步骤：首先，计算用户之间的相似度，选取最相似的N个用户，然后，根据相似度计算用户评分。 （1）用户相似度 用户相似度计算基于用户的协同过滤算法的重要内容，主要可以通过余弦相似度、杰卡德系数等方式进行计算。 假设：给定用户u和v，令N(u)表示用户u有过正反馈的物品集合，令N(v)为用户v有过正反馈的物品集合，则用户u和v之间的相似度可以通过如下方式计算： 余弦相似度： 杰卡德系数： （2）用户评分 得到用户相似度后，可以根据如下公式计算用户评分： 其中r(u, i)代表用户u对物品i的评分，S(u)为与用户u最相似的N个用户，N(i)为对物品i进行过操作的用户集合， 为用户u与用户v的相似度， 为用户v对物品i的评分。 UserCF的推荐结果反映了用户所在的一个兴趣群体中的热门物品，更加社会化但缺乏个性化， 能够满足物品的时效性，在新闻推荐领域能够发挥很大的作用。用户的兴趣在一段时间内是相对固定的，因此用户相似度矩阵不会实时进行更新，存在新用户的冷启动问题。 基于物品的协同过滤（Item-Based CF）基于物品的协同过滤（下文简称ItemCF）是目前应用最为广泛的算法，该算法的基本思想为：给用户推荐和他们以前喜欢的物品相似的物品，这里所说的相似并非从物品的内容角度出发，而是基于一种假设：喜欢物品A的用户大多也喜欢物品B代表着物品A和物品B相似。基于物品的协同过滤算法能够为推荐结果做出合理的解释，比如电子商务网站中的“购买该物品的用户还购买了…”。ItemCF的计算步骤和UserCF大致相同：首先，计算物品相似度，选出最相似的N个物品，然后根据相似度计算用户评分。 （1）物品相似度 假设：N(i)为喜欢物品i的用户结合，N(j)为喜欢物品j的用户集合，则物品相似度计算公式可以定义为： 上述公式将物品i和物品j的相似度定义为：同时喜欢物品i、j的用户数占只喜欢物品i用户数的比例，但如果物品j十分热门，大部分用户都很喜欢，那么就会造成所有物品都和j有较高的相似度，因此可以对计算公式进行如下改进： 改进后的相似度计算公式惩罚了物品j的热门度，在一定程度上减少了热门物品为相似度带来的影响。 （2）用户评分 得到物品相似度后，可以根据如下公式计算用户评分： 其中r(u, i)代表用户u对物品i的评分，S(i)代表和物品i最相似的N个物品，N(u)为用户u曾经感兴趣的物品集合， 为物品i和物品j的相似度， 为用户u对物品i的评分。 ItemCF的推荐结果更加个性化，反映了用户的个人兴趣，对挖掘长尾物品有很大帮助，被广泛应用于电子商务系统。在物品数较多时，物品相似度计算效率较差，因此通常以一定的时间间隔离线进行计算，然后将物品相似度数据缓存在内存中，这样一来，便可以根据用户的新行为实时向用户做出推荐。ItemCF同样存在新用户冷启动问题。 隐语义模型（Latent Factor Model）隐语义模型方法是目前应用最为广泛的协同过滤算法之一，在显式反馈（如评分）推荐系统中，能够达到很好的精度。它的基本思想是通过机器学习方法从用户-物品评分矩阵中分解为两个低阶矩阵，表示对用户兴趣和物品的隐含分类特征，通过隐含特征预测用户评分。训练过程中通常采用随机梯度下降（SGD）算法最小化损失函数，最后通过模型预测用户评分。矩阵分解（Matrix Factorization）是隐语义模型最成功的一种实现，假设训练数据为M个用户对N个物品的评分矩阵Rm,n，早期矩阵分解算法BasicSvd步骤如下： （1）给定假设函数 其中k表示矩阵分解的隐含特征数，p和q是两个矩阵，作为模型的参数，分别表示用户、物品与k个隐含特征之间的关系。 （2）最小化损失函数 其中u为用户，i为物品，R为训练数据评分矩阵，H为预测评分矩阵，通过随机梯度下降最小化cost函数，得到矩阵p和q。在最小化的过程中，还需要添加正则项防止过度拟合。 （3）通过用户、物品和隐含特征的关系矩阵p、q预测用户评分 在算法的演进过程中，还出现了FunkSVD[11]、SVD++等矩阵分解算法，它们在隐含特征的基础上考虑了用户评分习惯、历史访问等多种因素，在一些场景中取得了更为精确的结果。 矩阵分解算法采用机器学习的最优化方法训练模型，计算的空间复杂度较小，在评分预测推荐中的精度较高，能够自动挖掘用户和物品的特征，有非常好的扩展性，可以灵活地考虑额外因素。矩阵分解的训练过程需要扫描整个评分矩阵，在用户量和物品数很大的情况下比较费时，但可以离线进行训练，在线进行评分预测，达到推荐的实时性。 基于内容推荐基于内容推荐的基本思想是为用户推荐与他感兴趣的内容相似的物品，比如用户喜欢励志类电影，那么系统会直接为他推荐《阿甘正传》这部电影，这个过程综合考虑了用户兴趣和电影内容，因此不需要提供用户的历史行为数据，这能够很好地解决新用户的冷启动问题。基于内容推荐的关键问题是对用户兴趣特征和物品特征进行建模，主要方法由向量空间模型、线性分类、线性回归等。 基于内容推荐需要预先提供用户和物品的特征数据，比如电影推荐系统，需要提供用户感兴趣的电影类别、演员、导演等数据作为用户特征，还需要提供电影的内容属性、演员、导演、时长等数据作为电影的特征，这些需要进行预处理的数据在实际应用中往往有很大的困难，尤其是多媒体数据（视频、音频、图像等），在预处理过程中很难对物品的内容进行准确的分类和描述，且在数据量很大的情况下，预处理效率会很低下。针对以上不足，[25]提出了基于标签的推荐方法，可以由专家或用户为物品打标签，实现对物品的分类。 基于内容产生的推荐往往和用户已经处理的物品具有很大的相似度，不利于用户在推荐系统中获得惊喜，这也是推荐系统的一个重要研究方向。 混合推荐推荐算法虽然都可以为用户进行推荐，但每一种算法在应用中都有不同的效果。UserCF的推荐结果能够很好的在广泛的兴趣范围中推荐出热门的物品，但却缺少个性化；ItemCF能够在用户个人的兴趣领域发掘出长尾物品，但却缺乏多样性；基于内容推荐依赖于用户特征和物品特征，但能够很好的解决用户行为数据稀疏和新用户的冷启动问题；矩阵分解能够自动挖掘用户特征和物品特征，但却缺乏对推荐结果的解释，因此，每种推荐方法都各有利弊，相辅相成。 实际应用的推荐系统通常都会使用多种推荐算法，比如使用基于内容或标签的推荐算法来解决新用户的冷启动问题和行为数据稀疏问题，在拥有了一定的用户行为数据后，根据业务场景的需要综合使用UserCF、ItemCF、矩阵分解或其他推荐算法进行离线计算和模型训练，通过采集用户的社交网络数据、时间相关数据、地理数据等综合考虑进行推荐，保证推荐引擎的个性化，提高推荐引擎的健壮性、实时性、多样性和新颖性。让推荐系统更好地为用户服务。 总结和展望本文首先回顾了推荐系统发展的历史，并分析了当前推荐系统的研究现状，其次阐述了主要的推荐方式和推荐结果的评估指标，最后分析了主流的推荐算法以及它们各自的优缺点。 推荐系统的发展一方面精确的匹配了用户与信息，降低了人们在信息过载时代获取信息的成本，但由推荐系统主导的内容分发，如新闻推荐等，也为用户带来了消极影响。2017年9月19日，人民日报点名批评国内知名内容分发平台今日头条，强调别以技术之名糊弄网民和群众，可见推荐系统的发展不仅需要满足用户多元化、个性化的需求，而且需要对信息进行严格的监管和过滤，提高推荐系统的健壮性。近年来，RecSys会议上越来越多地收录了关于用户隐私、推荐引擎健壮性、信息过滤等方面的论文，这是未来推荐系统发展的一个重要研究方向。 目前，深度神经网络发展迅速，为推荐系统提供了新的特征提取、排序方法，越来越多的推荐引擎将深度神经网络与传统的推荐算法进行了结合，用于解决数据稀疏、推荐排序等问题，深度神经网络和推荐系统的结合将是推荐系统未来的主要研究方向。 综上所述，推荐系统是一个庞大的信息系统，它不仅仅只依赖于推荐引擎的工作，而且依赖于业务系统、日志系统等诸多方面，并结合了网络安全、数据挖掘等多个研究领域，能够为企业和用户带来价值，是一个值得深入研究的领域。 参考文献[1] Resnick P,Iacovou N, Suchak M, et al. GroupLens: an open architecture for collaborativefiltering of netnews[C] Proceedings of the 1994 ACM Conference on ComputerSupported Cooperative Work, Oct 22-26, 1994. New York, NY, USA: ACM, 1994:175-186. [2] Resnick P, Varian H R. Recommender systems[J].Communications of the ACM, 1997, 40(3): 56-58. [3] G. Linden, B. Smith, and J. York, “Amazon.comRecommendations: Item-to-Item Collaborative Filtering,” IEEE InternetComputing, vol. 7, no. 1, 2003, pp. 76–80. [4] Linden G, Smith B, York J. Amazon.comrecommendations: item-to-item collaborative filtering[J]. IEEE Internet Computing,2003, 7(1): 76-80. [5] Adomavicius G, Tuzhilin A. Toward the nextgeneration of recommender systems: a survey of the state-of-the-art and possibleextensions[J]. IEEE Transactions on Knowledge and Data Engineering, 2005,17(6): 734-749. [6] Cremonesi P, Tripodi A, Turrin R. Cross-DomainRecommender Systems.[C] IEEE, International Conference on Data MiningWorkshops. IEEE, 2012:496-503. [7] Huiji Gao, Jiliang Tang, Huan Liu. Personalizedlocation recommendation on location-based social networks[J]. 2014:399-400. [8] Said A. Replicable Evaluation of RecommenderSystems[C] ACM Conference on Recommender Systems. ACM, 2015:363-364. [9] Hopfgartner F, Kille B, Heintz T, et al.Real-time Recommendation of Streamed Data[C] ACM Conference on RecommenderSystems. ACM, 2015:361-362. [10] Karatzoglou A, Hidasi B. Deep Learning forRecommender Systems[C] the Eleventh ACM Conference. ACM, 2017:396-397. [11] Simon Funk. Funk-SVD [EB/OL]. http://sifter.org/~simon/journal/20061211.html,2006-12-11 [12] 朱扬勇, 孙婧. 推荐系统研究进展[J]. 计算机科学与探索, 2015, 9(5):513-525. [13] 杨阳, 向阳, 熊磊. 基于矩阵分解与用户近邻模型的协同过滤推荐算法[J]. 计算机应用, 2012,32(2):395-398. [14] 项亮. 推荐系统实践[M]. 北京: 人民邮电出版社, 2012.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>综述</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow卷积神经网络（CNN）手写数字识别示例学习]]></title>
    <url>%2F2019%2F04%2F10%2F%E7%AE%97%E6%B3%95%2FTensorflow%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[问题描述利用卷积神经网络将MNIST数据集的28×28像素的灰度手写数字图片识别为相应的数字。 数据描述MNIST数据集是28×28像素的灰度手写数字图片，其中数字的范围从0到9 具体如下所示（参考自Tensorflow官方文档）： 文件 内容 train-images-idx3-ubyte.gz 训练集图片，55000张训练图片, 5000张验证图片 train-labels-idx1-ubyte.gz 训练集图片对应的数字标签 t10k-images-idx3-ubyte.gz 测试集图片，10000张图片 t10k-labels-idx1-ubyte.gz 测试集图片对应的数字标签 网络结构卷积神经网络一般包含以下几层： 输入层：用于将数据输入到神经网络中 卷积层：使用卷积核提取特征 激励层：对卷积操作的线性运算进行非线性映射 池化层：卷积得到的特征图进行稀疏处理，减少数据量 全连接层：在网络的末端进行重新拟合，恢复特征，减少特征的损失 输出层：输出结果 输入层卷积神经网络中输入层的结构可以是多维的，例如MNIST数据集中是28×28像素的灰度图片，因此输入为28×28的的二维矩阵。 卷积层卷积层是使用卷积核提取特征，在卷积层中需要理解局部感受野和共享权值。 局部感受野：类似于一个滑动窗口，以窗口的范围去提取对应范围的神经元携带的特征。 共享权值：根据局部感受野提取特征，原始数据中的一部分神经元与卷积层中的一个神经元相连接，每一条线对应一个权重，而在卷积层中，对于同一个卷积核，权重是相同的。 上图为卷积操作示意图（图片来源于网络，侵删），其中Image表示图片数据矩阵，游走的窗口为卷积核矩阵，x0、x1表示的是权重，一个N×N的图像经过M×M的卷积核卷积后将得到（N-M+1）×（N-M+1）的输出。 卷积后输出的矩阵数据成为特征映射图，一个卷积核输出一个特征映射图，卷积操作是一种线性计算，因此通常在卷积后进行一次非线性映射。 池化层池化层是将卷积得到的特征映射图进行稀疏处理，减少数据量，操作与卷积基本相似，不同的是卷积操作是一种线性计算，而池化的计算方法更多样化，一般有如下计算方式： 最大池化：取样池中的最大值作为池化结果 均值池化：取样池中的平均值作为池化结果 还有重叠池化、均方池化、归一化池化等方法。 全连接层在网络的末端对提取后的特征进行恢复，重新拟合，减少因为特征提取而造成的特征丢失。全连接层的神经元数需要根据经验和实验结果进行反复调参。 输出层输出层用于将最终的结果输出，针对不同的问题，输出层的结构也不相同，例如MNIST数据集识别问题中，输出层为有10个神经元的向量。 示例网络结构示例模型包括输入层、两个卷积层、两个池化层、全连接层和输出层，其中卷积和池化操作的特征图输出大小计算公式为： ImageWidth：图片宽度 Padding：边缘补齐像素数 KernelSize：卷积核宽度 Stride：移动步长 具体模型结构如下所示： 程序解读Tensorflow中使用图来表示计算任务，在会话(Session)中执行图，使用 tensor 表示数据.通过变量(Variable)维护状态，使用 feed 和 fetch 可以为任意的操作赋值或者从其中获取数据. 加载MNIST数据集1mnist =input_data.read_data_sets("MNIST_data", one_hot=True) 命令会自动下载MNIST数据集，存放在”MNIST_data”目录下，也可以手动下载数据集后放入此目录下。执行read_data_sets()函数后将会返回一个DataSet实例，其中包含训练数据、验证数据和测试数据。 创建Session和占位符123sess =tf.InteractiveSession()x =tf.placeholder("float", shape=[None, 784])y_ =tf.placeholder("float", shape=[None, 10]) x和y_都是tensor，其中x表示输入数据，由于是28×28像素的灰度图片，因此输入为784维的向量。y_表示模型输出，为0-9的数字，因此是10维的向量。 定义卷积层1的权重和偏置量12w_conv1 = tf.Variable(tf.truncated_normal([5,5, 1, 32], stddev=0.1))b_conv1 =tf.Variable(tf.constant(0.1, shape=[32])) 卷积操作的计算公式为：W × X + b [5, 5, 1,32]表示卷积核的大小为5×5，输出为32，即共有32个卷积核，卷积操作会产生32个特征映射图。 其中w_conv1表示权重W，由正太分布截取得出。b_conv1表示偏置量，初始值均为0.1，由于卷积操作会输出32个特征图，因此偏置量的维度为32。 卷积层11x_image =tf.reshape(x, [-1,28,28,1]) 将输入tensor x 调整成为28×28矩阵形式。 12r_conv1 = tf.nn.conv2d(x_image,w_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1h_conv1 = tf.nn.relu(r_conv1) 进行卷积操作W × X + b，得到线性变化的结果r_conv1，再利用Tensorflow的relu规则进行非线性映射，出的卷积的结果h_conv1。 池化层11h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') 采用了最大池化方法，其中ksize表示取样池的大小，strides表示步长，padding表示边缘补齐方法，SAME方式会在图片边缘补0，补齐边缘像素为1，最终得出池化结果h_pool1。 定义卷积层2的权重和偏置量12w_conv2 =tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))b_conv2 =tf.Variable(tf.constant(0.1, shape=[64])) 卷积层2的输入为32张特征映射图，有64个卷积核，最终将输出64个特征映射图。 卷积层2和池化层2123r_conv2 = tf.nn.conv2d(h_pool1,w_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv1h_conv2 =tf.nn.relu(r_conv2)h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') 经过卷积层2和池化层2后，得到64张7×7的特征映射图。 全连接层12W_fc1 =tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))b_fc1 =tf.Variable(tf.constant(0.1, shape=[1024])) 全连接层设有1024个神经元，本层的神经元数需要根据经验和实验结果进行反复调参确定。 12h_pool2_flat= tf.reshape(h_pool2, [-1, 7*7*64])h_fc1 =tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) 将第二层池化后的数据调整为7×7×64的向量，与全连接层的权重进行矩阵相乘，然后进行非线性映射得到1024维的向量。 输出层123W_fc2 = tf.Variable(tf.truncated_normal([1024,10], stddev=0.1))b_fc2 = tf.Variable(tf.constant(0.1,shape=[10]))y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2) 输出层为10维的向量，通过softmax函数输出。 参考资料深度学习（四）卷积神经网络入门学习(1)深度学习之卷积神经网络CNN及tensorflow代码实现示例TensorFlow 官方文档 源码地址：Tensorflow卷积神经网络（CNN）手写数字识别]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>卷积神经网络</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遗传算法求解TSP问题]]></title>
    <url>%2F2019%2F04%2F10%2F%E7%AE%97%E6%B3%95%2F%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E6%B1%82%E8%A7%A3TSP%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述旅行商问题是图论中的一个经典问题。 假设有一个旅行商人要拜访N个城市，要求他从一个城市出发，每个城市最多拜访一次，最后要回到出发的城市，保证所选择的路径长度最短。 算法描述算法简介遗传算法（GeneticAlgorithm）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，通过模拟自然进化过程搜索最优解。遗传算法是从代表问题可能潜在的解集的一个种群（population）开始的，初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。这个过程将导致种群像自然进化一样的后生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解。（摘自百度百科）。 遗传算子遗传算法中有选择算子、交叉算子和变异算子。 选择算子用于在父代种群中选择进入下一代的个体。 交叉算子用于对种群中的个体两两进行交叉，有Partial-Mapped Crossover、Order Crossover、Position-based Crossover等交叉算子。 变异算子用于对种群中的个体进行突变。 算法步骤遗传算法的基本运算过程如下： 初始化：设置进化代数计数器t=0、设置最大进化代数T、交叉概率、变异概率、随机生成M个个体作为初始种群P 个体评价：计算种群P中各个个体的适应度 选择运算：将选择算子作用于群体。以个体适应度为基础，选择最优个体直接遗传到下一代或通过配对交叉产生新的个体再遗传到下一代 交叉运算：在交叉概率的控制下，对群体中的个体两两进行交叉 变异运算：在变异概率的控制下，对群体中的个体两两进行变异，即对某一个体的基因进行随机调整 经过选择、交叉、变异运算之后得到下一代群体P1。 重复以上1-6，直到遗传代数为T，以进化过程中所得到的具有最大适应度个体作为最优解输出，终止计算。 求解说明优化目标给定二维数据int[][]pos用于存储各个城市的坐标，采用欧式距离代表城市之间的距离。利用遗传算法，找到不重复遍历所有城市的路径中，所走距离最短的路径。 选择算子选择算子采用轮盘赌选择，以每个个体的适应度为基础，为每个个体计算累积概率。 个体1、2、3、4的个体适应度如上图所示。 适应度计算规则：染色体代表的路径实际距离作为个体的适应度，如下（distence[x][y]表示城市x到y的距离） 染色体 0 2 1 3，适应度为distence[0][2] + distence[2][1] + distence[1][3] + distence[3][0] qa 表示个体a的累积概率，如上图所示个体1、2、3、4的累积概率分别为0.14、0.53、0.69、1 随机生成一个0到1的浮点数f，若 qa &lt; f &lt;= qb，则个体b被选中。 交叉算子Partial-Mapped Crossover（部分映射交叉）Order Crossover（顺序交叉）Position-based Crossover（基于位置的交叉） 变异算子变异算子随机进行多次，每次在个体基因序列中选择两个位置的基因进行交换。 参考资料用遗传算法求解TSP问题 源码地址：遗传算法求解TSP问题（参考自 基于遗传算法求解TSP问题（JAVA））]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>遗传算法</tag>
        <tag>TSP问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用极小极大搜索和alpha-beta剪枝算法预测五子棋对弈落子]]></title>
    <url>%2F2019%2F04%2F10%2F%E7%AE%97%E6%B3%95%2F%E5%88%A9%E7%94%A8%E6%9E%81%E5%B0%8F%E6%9E%81%E5%A4%A7%E6%90%9C%E7%B4%A2%E5%92%8Calpha-beta%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%95%E9%A2%84%E6%B5%8B%E4%BA%94%E5%AD%90%E6%A3%8B%E5%AF%B9%E5%BC%88%E8%90%BD%E5%AD%90%2F</url>
    <content type="text"><![CDATA[问题描述利用极小极大搜索和alpha-beta剪枝算法预测五子棋落子问题，初始棋局如图所示，AI为白子，玩家为黑子，当前由AI落子。 算法描述极小化极大算法极小化极大搜索是一种在有限的深度范围内搜索博弈树的求解方法，程序代表AI方MAX节点，目的是打败玩家，基本原理为： （1）轮到MIN落子时，MAX节点考虑最坏的情况，即评估函数取极小值。 （2）轮到MAX落子时，MAX节点考虑最好的情况，即评估函数取极大值。 （3）搜索到叶子节点进行回溯，代表双方的对抗策略，交替使用（1）（2）规则回溯到root节点即可得到评估值。 123456789101112function minimax(node, depth) // 给定初始状态和搜索深度 if node is a terminal node or depth = 0 return the evaluate value of the node //使用评估函数返回局面得分 if player’s turn // 玩家走棋，是极小节点，选择一个得分最小的走法 let val := +∞ foreach child of node val := min(val, minimax(child, depth-1) else AI’s turn //AI走棋，是极大节点，选择一个得分最大的走法 let val := -∞ foreach child of node val := max(val, minimax(child, depth-1)) return val; Alpha-beta算法极小化极大算法的搜索效率非常低下，而Alpha-beta剪枝算法能够提高搜索效率，基本原理为： （1）alpha剪枝：任何极小层（由MIN落子）的节点的beta值都不大于其前驱节点（MAX节点）的alpha值，即搜索过程中，只要找到一个MIN节点的评估值不大于其前驱MAX节点的评估值，则可舍弃后续的搜索，这表示当前MIN节点落子对MAX是有利的。 （2）beta剪枝：任何极大层（由MAX落子）的节点的alpha值都不小于其前驱节点（MIN节点）的beta值。即搜索过程中，只要找到一个MAX节点的评估值不小于其前驱MIN节点的评估值，则可舍弃后续的搜索，这表示当前MAX节点落子对MAX是有利的。 12345678910111213141516function alphaBeta(node, alpha, beta , depth) if node is a terminal node or depth = 0 return the evaluate value of node //使用评估函数返回局面得分 else if AI’s turn foreach child of node val := alphaBeta(child, alpha, beta, depth-1) if(val &gt; alpha) alpha:= val if(alpha &gt;= beta) break return alpha else player’s turn foreach child of node val := alphaBeta(child, alpha, beta, depth-1) if(val &lt; beta) beta:= val if(alpha &gt;= beta) break return beta 评估函数评估函数用于对博弈树中的叶子节点的状态进行评估，需要考虑五子棋中的基本棋型和特点，对叶子节点的棋局进行评估，给出评估值。 五子棋中的基本棋型（1代表AI落子，2代表玩家落子，0代表空位）： （1）连五：五颗同色棋子连在一起，如11111，22222 （2）活四：有两个点可以形成连五，如011110，022220 （3）冲四：有一个点可以形成连五，如011112，122220 （4）活三：可以形成活四的三点，如001110，002220 （5）眠三：只能形成冲四的三点，如001112，002221 （6）活二：能够形成活三的二点，如000110，000220 （7）眠二：能够形成眠三的二点，如000112，000221 在程序中可以某一坐标为中心，将改坐标点横竖撇捺四个方向的状态拼接为字符串，判断字符串是否包含上述的某种棋型作为判断标准。 由于算法是针对AI而言，因此在评估函数中，对玩家方赋予负值，AI方赋予正值。对于棋盘中的落子，从横竖撇捺四个方向判断形成的基本棋型，对不同的棋型赋予不同的权重，如连五代表一方胜利，赋予最大值代表AI胜利，赋予最小值代表玩家胜利。 根据棋型的重要性，划分权重如下（AI权重为正，玩家权重为负）： 棋型 权重 连五 100000000 活四 10000000 冲四 1000000 活三 100000 眠三 10000 活二 1000 眠二 1000 活二 100 仅一 10 无 1 （一）评估函数v1 在评估过程中，计算AI所有落子位置横竖撇捺四个方向形成的棋型，得出评估值作为叶子节点的评估值。 效果：此种评估方式效果很差，仅对AI落子点进行判断过于片面，且会造成急于进攻疏于防守的局面。 （二）评估函数v2 在评估过程中，将棋盘中的所有落子的评估值相加得出最后的评估值。最终得到的评估值实际为AI落子形成的棋局评估值减玩家落子形成的棋局评估值。按此计算的目的是平衡进攻和防守。以叶子节点的评估值进行回溯，进而选择初始状态的下一步落子。 效果：评估结果较好，能够平衡进攻和防守。 参考资料五子棋基本棋型及其特点Alpha-beta剪枝极小极大搜索方法、负值最大算法和Alpha-Beta搜索方法五子棋的核心算法Alpha-Beta搜索最小-最大搜索五子棋AI算法第四篇-启发式搜索函数 源码地址：利用极小极大搜索和alpha-beta剪枝算法预测五子棋对弈落子]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>极小极大搜索</tag>
        <tag>alpha-beta剪枝</tag>
        <tag>博弈树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A*算法求解15数码问题]]></title>
    <url>%2F2019%2F04%2F10%2F%E7%AE%97%E6%B3%95%2FA%E6%98%9F%E7%AE%97%E6%B3%95%E6%B1%82%E8%A7%A315%E6%95%B0%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述利用A*算法进行表1到表2的转换，要求空白块移动次数最少。 转换规则为：空白块只可以与上下左右四个方向的相邻数字交换。 算法简介A*算法是一种在图形平面上，有多个节点的路径，求出最低通过成本的算法。该算法综合了Best-First Search和Dijkstra算法的优点：在进行启发式搜索提高算法效率的同时，基于评估函数计算损失，保证找到一条最优路径。 算法能否找到最优解的关键在于评估函数的选择，A*算法的评估函数表示为：f(n) = g(n) + h(n) f(n) 是从初始状态经由状态n到目标状态的代价估计 g(n) 是在状态空间中从初始状态到状态n的实际代价 h(n) 是从状态n到目标状态的最佳路径的估计代价 例如在8数码问题中，g(n) 表示状态空间树中搜索的层数，h(n) 表示状态n与目标状态中元素位置不同的元素个数。 算法步骤设定两个集合，open集，close集 将起始点加入open集（设置父亲节点为空） 在open集中选着一个f(n)值最小的节点作为当前节点 2.1. 将当前节点从open集中移除，添加到close集 2.2. 如果当前节点为终点节点，那么结束搜索 2.3. 处理当前节点的所有邻接节点，规则如下： 如果不在open集中，那么就将其添加到open集，并将该节点的父节点为当前节点 如果已经添加到open集中，重新计算f(n)值，如果f(n)值小于先前的f(n)值，那么就更新open集中相应节点的f(n) 如果该节点不可通过或者已经被添加到close集，那么不予处理 如果open集不为空，那么转到步骤2继续执行。 评估函数f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态不同的元素个数 效果：与8数码问题使用了相同的评估函数，大概跑了30W步无法求出解 评价：效果极差，15数码问题的状态空间树要远复杂于8 数码问题，且15数码问题中空白块的移动更为复杂，此评估函数不适用。 f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态各个位置数字偏差的绝对值 效果：随着搜索的进行，空白块的移动集中在表格上部，表格下部几乎不移动 ，无法求出解 评价：因为下部数字较大，移动后差值较大造成评估值较大，因此搜索集中在了数值较小的部分，效果很差。 f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态各个元素的路径差值（一维数组各元素的距离差之和） 效果：空白块最终移动55步得到目标状态。 评价：效果比较理想，但h(n)还可继续优化。 f(n) = 状态n状态空间树中的搜索深度 + 状态n与目标状态各个元素的曼哈顿距离 效果：空白块最终移动41步得到目标状态。 评价：效果理想。 实际上，1和2的评估函数效果大致相同，都将搜索局限在了一部分导致无法计算出问题的解。3实际是以一维数组各元素的距离差之和估计状态n到目标状态的曼哈顿距离，但此估计方式和计算平面两点的曼哈顿距离存在较大误差，因此只求解出可行解。 参考资料A*算法详解，看完后全懂了启发式搜索浅谈，解决八数码问题 源码地址：A*算法求解15数码问题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>15数码</tag>
        <tag>A*算法</tag>
      </tags>
  </entry>
</search>
